---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "README-"
)
# Please put your title here to include it in the file below.
Title <- "Spotting Fake News and Doubting True News: A Meta-Analysis of News judgements"
Authors <- "XX and XX"
Year <- "2023"
```

# `r Title`

---

[![OSF Registration](https://img.shields.io/badge/OSF_Registration-10.17605%2FOSF.IO%2FSVC7U-blue
)](https://doi.org/10.17605/OSF.IO/SVC7U) [![OSF Project](https://img.shields.io/badge/OSF_Project-10.17605/OSF.IO/96ZBP-blue
)](https://osf.io/96zbp/) 


**All this project's materials are free and open**.

- [Replicate the findings](#replicate)
- [Check out the files glossary for this repository](#glossary)

![Open data](images/data_large_color.png) &emsp; ![Open materials](images/materials_large_color.png) &emsp; ![Preregistration](images/preregistered_large_color.png)

---

## Abstract

How good are people at judging the veracity of news? We conducted a systematic literature review and pre-registered meta-analysis of 173 effect sizes from 48 experimental papers evaluating accuracy ratings of true and false news ($N_{participants}$ = 100777 from 30 countries across 6 continents). We found that people rated true news as much more accurate than false news (d = 1.01 [0.9, 1.12]) and were slightly better at rating false news as false than at rating true news as true (d = 0.28 [0.2, 0.35]). In other words, participants were able to discern true from false news, and were slightly more skeptical than gullible. The political concordance of the news had no effect on discernment, but participants were more skeptical of politically discordant news. These findings lend support to crowdsourced fact-checking initiatives, and suggest that, to improve discernment, there is more room to increase the acceptance of true news than to reduce the acceptance of false news.

---

This repository contains the code for our paper. 

Our pre-print is online here:

> `r Authors`. `r Year`. "`r Title`"". Accessed `r format(Sys.time(), '%B %e, %Y')`. Online at <https://osf.io/96zbp/?view_only=d2f3147f652e44e2a0414d7d6d9a6c29>

## How to download and replicate {#replicate}

To reproduce the findings and re-run the analysis, do the following:

1. Download and install this repository. You can use GitHub to clone or fork the repository (see the green "Clone or download" button at the top of the GitHub page).
2. Open `meta_news_judgement.Rproj` to open an [RStudio Project](https://r4ds.had.co.nz/workflow-projects.html).
3. Within the RStudio Project, open the `anonymized.Rmd` file and run it. 

For inspecting scripts directly on github, use the `.md` files. The source code can be found in the `.Rmd` and `.R` files. 

Please find the [session info below](#session-info).

*Estimated installation time* : If you have R and Rstudio installed, then adding additional packages required in our R scripts is quick (a couple of minutes)

*Estimated run time*: Rendering the `anonymized.Rmd` document takes about 5mins on our machine (see [session info](#session-info))

## Files glossary {#glossary}

The `codebook.csv` contains all variables of our data set.

The `data/` folder contains the main data sets.

- `data/data.csv` is the raw, hand-coded data that we extracted from the original papers (which is not yet accessible since it contains data not only for control, but also treatment conditions, which are relevant for another, unfinished project.)
- `data/cleaned.csv` is a cleaned version of that raw data, where we change some variable names, recode values, and remove treatment conditions. The cleaning process is documented in the `cleaning.Rmd` file (but cannot be replicated at the moment since `data.csv` is not yet public). 
- `data/individual_level_subset.csv` and `data/correlations_by_sample.csv` are generated by the `compute_correlation.R` script. The first contains individual level data from a subset of studies for which we calculated the summary statistics ourselves. The second contains the correlation values for true and false news ratings by samples for that subset. We use these values to obtain the average by-sample correlation to calculate our effect sizes. 
- `data/ne_110m_admin_0_countries/` contains shape files from the Natural Earth project. We use the ["Admin 0 - Countries" 1:110m cultural shapefiles](https://www.naturalearthdata.com/downloads/110m-cultural-vectors/) for maps.

The `functions/` folder contains functions that we rely upon in our analysis scripts. To keep the `anonymized.Rmd` document neat and readable, we wrote all lengthy code bits as external functions. 

The `literature_search/` folder documents our literature review
- `scopus.csv` and `google.csv` contain all results that popped up in our two literature searches. 
- `inclusion_criteria.csv` contains a list of our inclusion criteria
- `prisma.csv` is generated by `prisma.Rmd` and contains all the relevant information for filling out the PRISMA flowchart (which we did by hand in a [template dowloaded here](http://www.prisma-statement.org/PRISMAStatement/FlowDiagram))

The `data_extraction.R` file contains the code to obtain summary statistics from raw data studies. Once we calculated these summary statistics, we entered them by hand into the the raw data spreadsheet (`data/data.csv`). We do not publish the raw data from those studies here, since they are already publicly available.

Files preceded by `appendix_*` contain appendices to the `anonymized.Rmd`. We stored them in separate documents to keep the `anonymized.Rmd` document as short as possible.

Files preceded by `simulation_*` contain data scripts for generating and analyzing simulated data. We simulated data to help us clarify our estimands and choose estimators before writing our pre-registration. 

`preregistration.Rmd` contians the source file for our pre-registration which can be found on the [OSF](https://doi.org/10.17605/OSF.IO/SVC7U).

`bibliography.bib` contains all references and `nature.csl` the citation formatting.

`images/` contains images used for this README file.

## Session info {#session-info}

```{r, echo=FALSE}
sessionInfo()
```


