---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "README-"
)

yaml_metadata <- rmarkdown::yaml_front_matter(here::here("preprint.Rmd"))
title <- yaml_metadata$title
abstract <- yaml_metadata$abstract
authors <- "Jan PfÃ¤nder and Sacha Altay"
year <- "2025"
```

# `r title`

---

[![OSF Registration](https://img.shields.io/badge/OSF_Registration-10.17605%2FOSF.IO%2FSVC7U-blue
)](https://doi.org/10.17605/OSF.IO/SVC7U) [![OSF Project](https://img.shields.io/badge/OSF_Project-10.17605/OSF.IO/96ZBP-blue
)](https://osf.io/96zbp/) 


**All this project's materials are free and open**.

- [Replicate the findings](#replicate)
- [Check out the files glossary for this repository](#glossary)

![Open data](images/data_large_color.png) &emsp; ![Open materials](images/materials_large_color.png) &emsp; ![Preregistration](images/preregistered_large_color.png)

---

## Abstract

`r abstract`

---

This repository contains the code and data for our paper. 

> `r authors`. `r year`. "`r title`"". *Nature Human Behaviour* (forthcoming). Pre-print at <https://doi.org/10.31219/osf.io/n9h4y>

## Replicate {#replicate}

To maximize applicability, we wrote our manuscript using in RMarkdown, allowing us to mix code, figures, text, and tables with the actual prose of the manuscript. All results are programmatically included when rendering the document. This allows to clearly see which code and data generated which result. 

To reproduce the findings and re-run the analysis, do the following:

1. Download this repository. You can use GitHub to clone or fork the repository (see the green "Clone or download" button at the top of the GitHub page).
2. Open `meta_news_judgement.Rproj` to open an [RStudio Project](https://r4ds.had.co.nz/workflow-projects.html).
3. Within the RStudio Project, open the `preprint.Rmd` file and run it

For inspecting scripts directly on github, use the `.md` files. The source code can be found in the `.Rmd` and `.R` files. 

Please find the [session info below](#session-info).

*Estimated installation time* : If you have R and Rstudio installed, then adding additional packages required in our R scripts is quick (a couple of minutes)

*Estimated run time*: Rendering the `anonymized.Rmd` document takes about 5mins on our machine (see [session info](#session-info))

## Files glossary {#glossary}

- The `manuscript.Rmd` and the `preprint.Rmd` generate the paper. The difference is that the `manuscript.Rmd` produces a version for submission, with a separate figure section, while the other generates the preprint version. 

- The `codebook.csv` contains all variables of our data set.

- The `data/` folder contains the main data sets.

  - `data/data.csv` is the raw, hand-coded data that we extracted from the original papers (which is not yet accessible since it contains data not only for control, but also treatment conditions, which are relevant for another, unfinished project.)
  - `data/cleaned.csv` is a cleaned version of that raw data, where we change some variable names, recode values, and remove treatment conditions. The cleaning process is documented in the `cleaning.Rmd` file (but cannot be replicated at the moment since `data.csv` is not yet public). 
  - `data/individual_level_subset.csv` and `data/correlations_by_sample.csv` are generated by the `compute_correlation.R` script. The first contains individual level data from a subset of studies for which we calculated the summary statistics ourselves. The second contains the correlation values for true and false news ratings by samples for that subset. We use these values to obtain the average by-sample correlation to calculate our effect sizes. 
  - `data/ne_110m_admin_0_countries/` contains shape files from the Natural Earth project. We use the ["Admin 0 - Countries" 1:110m cultural shapefiles](https://www.naturalearthdata.com/downloads/110m-cultural-vectors/) for maps.

- The `functions/` folder contains functions that we rely upon in our analysis scripts. To keep the `anonymized.Rmd` document neat and readable, we wrote all lengthy code bits as external functions. 

- The `literature_search/` folder documents our systematic literature reviews
  - `scopus.csv` and `google.csv` contain all results that popped up in our two literature searches. 
  - `inclusion_criteria.csv` contains a list of our inclusion criteria
  - `prisma.csv` is generated by `prisma.Rmd` and contains all the relevant information for filling out the PRISMA flowchart (which we did by hand in a [template dowloaded here](http://www.prisma-statement.org/PRISMAStatement/FlowDiagram))
  - files preceded by `revisions_` are related to the second systematic review during the revisions process of the paper. They include search results, search strings, screening decisions of the two authors. The screening process is document in `revisions_screening_process.Rmd`


- The `data_extraction.R` file contains the code to obtain summary statistics from raw data studies. Once we calculated these summary statistics, we entered them by hand into the the raw data spreadsheet (`data/data.csv`). We do not publish the raw data from those studies here, since they are already publicly available.

- Files preceded by `appendix_*` contain appendices to the `anonymized.Rmd`. We stored them in separate documents to keep the `anonymized.Rmd` document as short as possible.

- Files preceded by `simulation_*` contain data scripts for generating and analyzing simulated data. We simulated data to help us clarify our estimands and choose estimators before writing our pre-registration. 

- `preregistration.Rmd` contains the source file for our pre-registration which can be found on the [OSF](https://doi.org/10.17605/OSF.IO/SVC7U).

- `bibliography.bib` contains all references and `nature.csl` the citation formatting.

- `images/` contains images used for this README file.

## Session info {#session-info}

```{r, echo=FALSE}
sessionInfo()
```


