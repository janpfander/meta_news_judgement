DOI,Title,Abstract,include
10.1145/3555096,understanding effects of algorithmic vs. community label on perceived accuracy of hyper-partisan misinformation,… more effective in reducing the perceived accuracy and believability of fake conservative … belief in liberal posts. Our results shed light on the differing effects of various misinformation …,no
10.1002/wcs.1573,the effects of repeating false and misleading information on belief,"… We can also see the direct impact of misinformation on the January 6th insurrection at the US Capitol (Williamson, 2021), an event that led to numerous injuries and deaths. Thus, there …",no
10.1007/978-3-030-77626-8_23,"effects of conspiracy thinking style, framing and political interest on accuracy of fake news recognition by social media users: evidence from russia, kazakhstan and …",… fake news … ’ accuracy in detecting fake news. The results of the study confirm the important role of conspiracy thinking style in false news recognition (leading to a decrease in accuracy) …,yes
10.1145/3555611,who's in the crowd matters: cognitive factors and beliefs predict misinformation assessment accuracy,… that predict worker accuracy in misinformation judgments: … We find the same factors predict accuracy on the evaluation … to more accurately predict crowd worker accuracy on both metrics. …,no
10.1080/0144929X.2020.1829708,the effect of web add-on correction and narrative correction on belief in misinformation depending on motivations for using social media,"… have grappled with misinformation-related issues and investigated what reinforces belief in misinformation, all in an effort to combat the spread of misinformation. Much research has …",no
10.1186/s12889-022-14431-y,what predicts people's belief in covid-19 misinformation? a retrospective study using a nationwide online survey among adults residing in the united states,… We created binary variables to represent four misinformation categories related to COVID-19… identified the important predictors of belief in each type of misinformation. Nested vector …,no
10.1080/10810730.2022.2130479,a comprehensive examination of association between belief in vaccine misinformation and vaccination intention in the covid-19 context,"… In our model, misinformation belief had significant but distant relationships with intention … Namely, our model suggested that misinformation belief was not a primary determinant of …",no
10.1080/10447318.2022.2158263,reducing younger and older adults' engagement with covid-19 misinformation: the effects of accuracy nudge and exogenous cues,"… Therefore, this study designed an accuracy nudge intervention to induce people to discern misinformation and adopted exogenous cues to reinforce their discernment ability. The two …",yes
10.1002/wmh3.544,public trust in sources and channels on judgment accuracy in food safety misinformation with the moderation effect of self‐affirmation: evidence from the hints‐china …,"This paper describes the developmentand introduction of an important new international health survey research program, HINTS‐China, which builds upon HINTS, the established …",yes
10.1177/20563051231179694,"studying the downstream effects of fact-checking on social media: experiments on correction formats, belief accuracy, and media trust","… Repeated exposure to misinformation not only reduces the accuracy of people’s beliefs, but it also decreases confidence in institutions such as the news media. Can fact-checking—…",yes
10.1111/pops.12494,political attitudes and the processing of misinformation corrections,"… social norm belief, then a compromise between a person’s true belief and the norm belief may no longer be possible. If a person then decides postcorrection to express their true belief—…",no
10.1002/gch2.201600008,inoculating the public against misinformation about climate change,"… climate change through organized “disinformation campaigns,” … the spread of influential misinformation about climate change. … about climate change against real‐world misinformation. …",yes
10.3758/mc.38.8.1087,explicit warnings reduce but do not eliminate the continued influence of misinformation,"… event model and do not replace the misinformation with alternative information, even when … the source of the misinformation. In the WMD studies discussed earlier, belief in the existence …",yes
10.1145/3313831.3376232,will the crowd game the algorithm? using layperson judgments to combat misinformation on social media by downranking distrusted sources,"… Critically, in this work we find that layperson discernment is unaffected by informing participants that their responses will influence ranking algorithms: While this knowledge does indeed …",yes
10.1186/s41235-020-00241-6,can corrections spread misinformation to new audiences? testing for the elusive familiarity backfire effect,"… in belief. They, too, failed to observe any familiarity backfire effects: post-correction belief in misinformation was always lower than pre-correction belief. This reduction in false-claim …",yes
10.1080/21645515.2021.1950504,covid-19 vaccine hesitancy: misinformation and perceptions of vaccine safety,… had a significant association with belief in COVID-19 vaccine … Belief in COVID-19 vaccine safety was also associated with … it becomes available by belief in COVID-19 vaccine safety. …,no
10.1007/s10339-019-00919-w,parents' beliefs in misinformation about vaccines are strengthened by pro-vaccine campaigns,… facts” format can be considered an effective tool to counter vaccines misinformation. Sixty … Efforts to counter vaccine misinformation should take into account the many variables that …,no
10.1093/joc/jqae007/7625162,empowering social media users: nudge toward self-engaged verification for improved truth and sharing discernment,"… discernment improved with higher factual accuracy ratings for true news, lower accuracy ratings for false news, and a greater likelihood to share true news compared to false news. …",yes
10.1145/3544549.3585719,investigating perceived message credibility and detection accuracy of fake and real information across information types and modalities.,"… With respect to the modality, another one-way repeated-measure ANOVA was performed to compare the efect of modality on the detection accuracy of fake news. The result showed that …",yes
10.1007/s10584-018-2192-4,correcting misinformation about climate change: the impact of partisanship in an experimental setting,… The Republican-sourced correction raises responses by 1.15 points on the belief question (… among Democrats to less than .25 points for the belief question (1.15–.97) and seriousness …,yes
10.1108/OIR-02-2021-0101,information discernment and online reading behaviour: an experiment,"… low-levels of information discernment especially when they encounter misinformation. In turn, … ways of identifying those particularly susceptible to the seductive nature of misinformation. …",yes
10.1057/s41304-024-00471-y,"adam berinsky: political rumors: why we accept political misinformation and how to fight it, princeton university press, 2023","… He shows that rumor belief is a function of conspiratorial … Thus, patterns in mass rumor belief that scholars previously … menu of potential methods of correction misinformation” (161) and …",no
10.1038/s41598-024-54030-y,the persuasive effects of social cues and source effects on misinformation susceptibility,"Although misinformation exposure takes place within a social context, significant conclusions have been drawn about misinformation susceptibility through studies that largely examine judgements in a social vacuum. Bridging the gap between social influence research and the cognitive science of misinformation, we examine the mechanisms through which social context impacts misinformation susceptibility across 5 experiments (N = 20,477). We find that social cues only impact individual judgements when they influence perceptions of wider social consensus, and that source similarity only biases news consumers when the source is high in credibility. Specifically, high and low engagement cues (‘likes’) reduced misinformation susceptibility relative to a control, and endorsement cues increased susceptibility, but discrediting cues had no impact. Furthermore, political ingroup sources increased susceptibility if the source was high in credibility, but political outgroup sources had no effect relative to a control. This work highlights the importance of studying cognitive processes within a social context, as judgements of (mis)information change when embedded in the social world. These findings further underscore the need for multifaceted interventions that take account of the social context in which false information is processed to effectively mitigate the impact of misinformation on the public. © The Author(s) 2024.",yes
10.1111/polp.12577,"to vote or not to vote? fake news, voter fraud, and support for postponing the 2020 u.s. presidential election","Prior to the 2020 election President Trump suggested the election should be postponed “until the country can make sure that only eligible American citizens can vote.” With the COVID-19 pandemic leading many states to take steps that made it easier for citizens to vote safely, the president and his allies made numerous false claims about voter fraud; others argued that voter fraud is not common and is unlikely to appreciably increase with greater reliance on mail balloting. We rely on a national Internet-based survey experiment conducted prior to the 2020 election to assess the effectiveness of both messages on citizens' support for a hypothetical proposal to postpone the presidential election. The results suggest that respondents were more likely to support postponement if they received a fake news message that fraud is common. The results also suggest that these effects are conditional; both political party and knowledge moderate the relationship. Related Articles: Aguado, N. Alexander. 2022. “When Charismatic Leadership Trumps Social Networking: Searching for the Effects of Social Media on Beliefs of Electoral Legitimacy.” Politics & Policy 50(5): 942–51. https://doi.org/10.1111/polp.12494. Fisher, Patrick. 2020. “Generational Replacement and the Impending Transformation of the American Electorate.” Politics & Policy 48(1): 38–68. https://doi.org/10.1111/polp.12340. Stockemer, Daniel. 2013. “Corruption and Turnout in Presidential Elections: A Macro-Level Quantitative Analysis.” Politics & Policy 41(2): 189–212. https://doi.org/10.1111/polp.12012. © 2024 Policy Studies Organization.",no
10.1002/acp.4187,argument-based intervention as a way to reduce covid-19 unfounded beliefs and vaccination hesitancy,"The aim of the experimental study was to verify the reduction of Covid-19 unfounded beliefs through arguments in favor of vaccination. The sample includes 720 participants recruited by Qualtrics (50% women, age: M = 38.8, SD = 10.90). The participants were equally and randomly divided into three groups. The control group was given the task of reading a neutral text about Norway. The first experimental group was provided with a debunking text that corrected popular misinformation and unfounded beliefs about vaccination against polio and vaccination against Covid-19. The second experimental group read the same text as the first, with two additional paragraphs addressing the motives and errors in the thinking of unfounded belief spreaders. The results confirmed that exposing the participants to arguments for vaccination reduces the endorsement of Covid-19 unfounded beliefs and increases the willingness to be vaccinated against Covid-19 disease. © 2024 John Wiley & Sons Ltd.",no
10.1177/17456916231190388,crowds can effectively identify misinformation at scale,"Identifying successful approaches for reducing the belief and spread of online misinformation is of great importance. Social media companies currently rely largely on professional fact-checking as their primary mechanism for identifying falsehoods. However, professional fact-checking has notable limitations regarding coverage and speed. In this article, we summarize research suggesting that the “wisdom of crowds” can be harnessed successfully to help identify misinformation at scale. Despite potential concerns about the abilities of laypeople to assess information quality, recent evidence demonstrates that aggregating judgments of groups of laypeople, or crowds, can effectively identify low-quality news sources and inaccurate news posts: Crowd ratings are strongly correlated with fact-checker ratings across a variety of studies using different designs, stimulus sets, and subject pools. We connect these experimental findings with recent attempts to deploy crowdsourced fact-checking in the field, and we close with recommendations and future directions for translating crowdsourced ratings into effective interventions. © The Author(s) 2023.",yes
10.37016/mr-2020-132,correcting campaign misinformation: experimental evidence from a two-wave panel study,"In this study, we used a two-wave panel and a real-world intervention during the 2017 UK general election to investigate whether fact-checking can reduce beliefs in an incorrect campaign claim, source effects, the duration of source effects, and how predispositions including political orientations and prior exposure condition them. We find correction effects in the short term only, but across different political divisions and various prior exposure levels. We discuss the significance of independent fact-checking sources and the UK partisan press in facilitating effects. © 2024, Harvard Kennedy School. All rights reserved.",yes
10.1007/s12144-024-05668-4,fighting fake news on social media: a comparative evaluation of digital literacy interventions,"Effective digital literacy interventions can positively influence social media users’ ability to identify fake news content. This research aimed to (a) introduce a new experiential training digital literacy intervention strategy, (b) evaluate the effect of different digital literacy interventions (i.e., priming critical thinking and an experiential training exercise) on the perceived accuracy of fake news and individuals’ subsequent online behavioral intentions, and (c) explore the underlying mechanisms that link various digital literacy interventions with the perceived accuracy of fake news and online behavioral intentions. The authors conducted a study, leveraging online experimental data from 609 participants. Participants were randomly assigned to different digital literacy interventions. Next, participants were shown a Tweeter tweet containing fake news story about the housing crisis and asked to evaluate the tweet in terms of its accuracy and self-report their intentions to engage in online activities related to it. They also reported their perceptions of skepticism and content diagnosticity. Both interventions were more effective than a control condition in improving participants’ ability to identify fake news messages. The findings suggest that the digital literacy interventions are associated with intentions to engage in online activities through a serial mediation model with three mediators, namely, skepticism, perceived accuracy and content diagnosticity. The results point to a need for broader application of experiential interventions on social media platforms to promote news consumers’ ability to identify fake news content. © 2024, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",no
10.1111/bjso.12732,intellectual humility as a tool to combat false beliefs: an individual-based approach to belief revision,"False beliefs pose significant societal threats, including health risks, political polarization and even violence. In two studies (N = 884) we explored the efficacy of an individual-based approach to correcting false beliefs. We examined whether the character virtue of intellectual humility (IH)—an appreciation of one's intellectual boundaries—encourages revising one's false beliefs in response to counter-information. Our research produced encouraging but also mixed findings. Among participants who held false beliefs about the risks of vaccines (Study 1) and the 2020 US Election being rigged (Study 2), those with higher IH explored more information opposing these false beliefs. This exploration of opposing information, in turn, predicted updating away from these inaccurate health and political beliefs. IH did not directly predict updating away from false beliefs, however, suggesting that this effect—if it exists—may not be particularly powerful. Taken together, these results provide moderate support for IH as a character trait that can foster belief revision but, simultaneously, suggest that alternate pathways to combat false beliefs and misinformation may be preferred. © 2024 The Authors. British Journal of Social Psychology published by John Wiley & Sons Ltd on behalf of British Psychological Society.",yes
10.3758/s13421-024-01520-z,how do forewarnings and post-warnings affect misinformation reliance? the impact of warnings on the continued influence effect and belief regression,"People often continue to rely on certain information in their reasoning, even if this information has been retracted; this is called the continued influence effect (CIE) of misinformation. One technique for reducing this effect involves explicitly warning people that there is a possibility that they might have been misled. The present study aimed to investigate these warnings’ effectiveness, depending on when they were given (either before or after misinformation). In two experiments (N = 337), we found that while a forewarning did reduce reliance on misinformation, retrospectively warned participants (when the warning was placed either between the misinformation and the retraction or just before testing) relied on the misinformation to a similar degree as unwarned participants. However, the protective effect of the forewarning was not durable, as shown by the fact that reliance on the misinformation increased for over 7 days following the first testing, despite continued memory of the retraction. © 2024, The Psychonomic Society, Inc.",no
10.1177/19401612231158770,"“i don’t think that’s true, bro!” social corrections of misinformation in india","Fact-checks and corrections of falsehoods have emerged as effective ways to counter misinformation online. But in contexts with encrypted messaging applications (EMAs), corrections must necessarily emanate from peers. Are such social corrections effective? If so, how substantiated do corrective messages need to be? To answer these questions, we evaluate the effect of different types of social corrections on the persistence of misinformation in India ((Formula presented.) 5,100). Using an online experiment, we show that social corrections substantially reduce beliefs in misinformation, including in beliefs deeply anchored in salient group identities. Importantly, these positive effects are not systematically attenuated by partisan motivated reasoning, highlighting a striking difference from Western contexts. We also find that the presence of a correction matters more relative to how sophisticated this correction is: substantiating a correction with a source only improves its effect in a minority of cases; besides, when social corrections are effective, citing a source does not drastically improve the size of their effect. These results have implications for both users and platforms and speak to countering misinformation in developing countries that rely on private messaging apps. © The Author(s) 2023.",yes
10.1017/XPS.2022.33,the big lie: expressive responding and misperceptions in the united states,"Misinformation about events surrounding the 2020 election and the COVID-19 pandemic pose an existential threat to American democracy and public health. Public opinion surveys reveal that high percentages of Republicans indicate that they endorse some aspects of mistaken beliefs surrounding election fraud in the 2020 election. Still, understanding how to measure the endorsement of misperceptions is critical for understanding the threat at hand. Are high levels of mistaken beliefs genuinely held, or are they partially a function of expressive responding? I address this question through a set of survey experiments encouraging accuracy-oriented processing among the general public. Using well-powered surveys of Republicans and Independents, I find that treatments designed to encourage more accurate responses are ineffective in reducing the endorsement of partisan electoral and public health misperceptions and can in some cases even backfire. These findings suggest that support for these misperceptions is genuinely held.  © The Author(s), 2022. Published by Cambridge University Press on behalf of American Political Science Association.",yes
10.1371/journal.pone.0296752,endorsement of covid-19 misinformation among criminal legal involved individuals in the united states: prevalence and relationship with information sources,"Criminal legal system involvement (CLI) is a critical social determinant of health that lies at the intersection of multiple sources of health disparities. The COVID-19 pandemic exacerbates many of these disparities, and specific vulnerabilities faced by the CLI population. This study investigated the prevalence of COVID-19-related misinformation, as well as its relationship with COVID-19 information sources used among Americans experiencing CLI. A nationally representative sample of American adults aged 18+ (N = 1,161), including a subsample of CLI individuals (n = 168), were surveyed in February-March 2021. On a 10-item test, CLI participants endorsed a greater number of misinformation statements (M = 1.88 vs. 1.27) than non-CLI participants, p .001. CLI participants reported less use of government and scientific sources (p = .017) and less use of personal sources (p = .003) for COVID-19 information than non-CLI participants. Poisson models showed that use of government and scientific sources was negatively associated with misinformation endorsement for non-CLI participants (IRR = .841, p .001), but not for CLI participants (IRR = .957, p = .619). These findings suggest that building and leveraging trust in important information sources are critical to the containment and mitigation of COVID-19-related misinformation in the CLI population. © 2024 Public Library of Science. All rights reserved.",no
10.1080/10584609.2023.2257618,fake news for all: how citizens discern disinformation in autocracies,"Research on autocracies often posits that propaganda can manipulate citizens’ beliefs, but existing work does not systematically investigate how well individuals recognize misinformation in authoritarian environments and whether susceptibility to propaganda is related to vulnerability to false news. I present the results of four surveys in Russia, in which more than 60,000 participants evaluated 74 true and false news headlines. I find that Russians’ capacity to discern falsehoods is comparable to discernment found in other political contexts, and they could often detect false news stories. However, consumers of state media gave less accurate evaluations than consumers of independent media, and government supporters were substantially more susceptible to pro-regime misinformation than opposition-minded citizens. Supporters also strongly rejected true messages inconsistent with their political dispositions. These results help understand why in environments dominated by propaganda individuals can be quite vulnerable to information manipulation. At the same time, regime critics in my study often fell for propaganda-inconsistent falsehoods. These results highlight the broader challenge of fighting misinformation and propaganda in a situation when many citizens exhibit political biases. © 2023 Taylor & Francis Group, LLC.",yes
10.1177/19401612241233533,why do citizens choose to read fact-checks in the context of the russian war in ukraine? the role of directional and accuracy motivations in nineteen democracies,"The recent surge of false information accompanying the Russian invasion of Ukraine has re-emphasized the need for interventions to counteract disinformation. While fact-checking is a widely used intervention, we know little about citizen motivations to read fact-checks. We tested theoretical predictions related to accuracy-motivated goals (i.e., seeking to know the truth) versus directionally-motivated goals (i.e., seeking to confirm existing beliefs) by analyzing original survey data (n = 19,037) collected in early April to late May 2022 in nineteen countries, namely Austria, Belgium, Brazil, Czech Republic, Denmark, France, Germany, Greece, Hungary, Italy, Netherlands, Poland, Romania, Serbia, Spain, Sweden, Switzerland, UK, and USA. Survey participants read ten statements about the Russian war in Ukraine and could opt to see fact-checks for each of these statements. Results of mixed models for three-level hierarchical data (level 1: statements, level 2: individuals, and level 3: countries) showed that accuracy motivations were better explanations than directional motivations for the decision to read fact-checks about the Russian war in Ukraine. © The Author(s) 2024.",yes
10.1371/journal.pone.0294471,you must be myths-taken: examining belief in falsehoods during the covid-19 health crisis,"The prevalence of health myths is increasing with the rise of Internet use. Left unaddressed, online falsehoods can lead to harmful behaviours. In times of crisis, such as the recent COVID-19 pandemic, the circulation of many myths is exacerbated, often to varying degrees among different cultures. Singapore is a multicultural hub in Asia with Western and Asian influences. Although several studies have examined health myths from a Western or Eastern perspective, little research has investigated online health falsehoods in a population that is culturally exposed to both. Furthermore, most studies examined myths cross-section-ally instead of capturing trends in myth prevalence over time, particularly during crisis situations. Given these literature gaps, we investigated popular myths surrounding the recent COVID-19 pandemic within the multicultural setting of Singapore, by examining its general population. We further examined changes in myth beliefs over the two-year period during the pandemic, and population demographic differences in myth beliefs. Using randomised sampling, two online surveys of nationally representative samples of adults (aged 21–70 years) residing in Singapore were conducted, the first between October 2020 and February 2021 (N = 949), and the second between March and April 2022 (N = 1084). Results showed that 12.7% to 57.5% of the population were unable to identify various myths, such as COVID-19 was manmade, and that three of these myths persisted significantly over time (increases ranging from 3.9% to 9.8%). However, belief in myths varied across population demographics, with ethnic minorities (Indians and Malays), females, young adults and those with lower education levels being more susceptible to myths than their counterparts (p < 0.05). Our findings suggest that current debunking efforts are insufficient to effectively counter misinformation beliefs during health crises. Instead, a post-COVID-19 landscape will require targeted approaches aimed at vulnerable population sub-groups, that also focus on the erroneous beliefs with long staying power. Copyright: © 2024 Lwin et al.",no
10.1038/s41562-023-01736-0,psychological inoculation strategies to fight climate disinformation across 12 countries,"Decades after the scientific debate about the anthropogenic causes of climate change was settled, climate disinformation still challenges the scientific evidence in public discourse. Here we present a comprehensive theoretical framework of (anti)science belief formation and updating to account for the psychological factors that influence the acceptance or rejection of scientific messages. We experimentally investigated, across 12 countries (N = 6,816), the effectiveness of six inoculation strategies targeting these factors—scientific consensus, trust in scientists, transparent communication, moralization of climate action, accuracy and positive emotions—to fight real-world disinformation about climate science and mitigation actions. While exposure to disinformation had strong detrimental effects on participants’ climate change beliefs (δ = −0.16), affect towards climate mitigation action (δ = −0.33), ability to detect disinformation (δ = −0.14) and pro-environmental behaviour (δ = −0.24), we found almost no evidence for protective effects of the inoculations (all δ < 0.20). We discuss the implications of these findings and propose ways forward to fight climate disinformation. © The Author(s) 2023.",yes
10.1111/ssqu.13298,(mis)informing the public? the public's responsiveness to reliable and unreliable information in illiberal information environments,"Background: Public opinion has a dynamic relationship with policy and real-world outcomes in liberal settings where reliable information is abundant. In these settings, the public continuously updates its opinions with reliable policy-relevant information, and the changes in public opinion go on to affect policy and outcomes. It is unknown whether this dynamic exists in illiberal settings where the public's access to reliable information is heavily restricted. Objectives: This article advances a theory of public opinion's dynamic relationship with policy and outcomes that applies to illiberal settings. Methods: Our study examines a vital public good in one of the world's most restrictive information environments and estimates a dynamic model of relationships among three variables—public opinion, policy, and outcomes—with a focus on public opinion and outcomes as the key dependent variables. The analysis looks at air pollution remediation in 274 Chinese localities. Results: We find that public opinion reacts to objective air pollution outcomes and not to misleading information that downplays air pollution severity, which suggests the public can accurately evaluate the reliability of available information. We also find that local public opinion's impact on local air pollution is substantively meaningful on timescales as short as 1 to 2 years, indicating that the additional policy effort prompted by public opinion change is sufficient to yield tangible real-world outcomes even in the short term. Conclusion: Public opinion has a dynamic relationship with policy and real-world outcomes even in highly illiberal settings. We argue that these findings are likely to generalize across issue domains with outcomes that can be directly observed by the public. © 2023 by the Southwestern Social Science Association.",yes
10.1177/00178969231210215,the effects of authoritative source cue and argument strength of correction tweets on mmr vaccine-related misinformation credibility,"Objectives: This study aimed to examine the joint effect of two core message elements – authoritative source and argument strength – in correction tweets to counter conspiratorial misinformation about the measles, mumps and rubella (MMR) vaccine. Design/Method: An online experiment with US residents (N = 404) was conducted in a 2 (authoritative correction sources: layperson vs US Centres for Disease Prevention and Control [CDC]) × 2 (correction argument strength: weak vs strong) design. Results: The results indicate that the correction employing strong arguments and a correction provided by the CDC heightened heuristic processing of the corrective information, which in turn increased the perceived credibility of the conspiratorial misinformation. The effect of the CDC correction on heuristic processing was heightened when it contained weak arguments. Notably, user-generated corrections with weak arguments reduced heuristic processing of the information and contributed to reducing the perceived credibility of the misinformation. Conclusion: Based on the findings, we argue that both communicator- and content-related cues jointly influence how audiences process corrective information. The current study discusses the potency of user-generated social media corrections to counter vaccine misinformation and provides practical implications for how user-generated social media correction can be utilised by health practitioners. Public health organisations should prioritise presenting corrective information in an easily understandable manner, using user-generated content that fosters a sense of connection and engagement with individuals. © The Author(s) 2023.",no
10.3390/journalmedia4030052,russo-ukrainian war and trust or mistrust in information: a snapshot of individuals’ perceptions in greece,"The purpose of this study was to assess the Greek public’s perceptions of the reliability of information received about the Russo-Ukrainian war in the spring of 2022. The study was conducted through an online questionnaire survey consisting of closed-ended statements on a five-point Likert scale. Principal components analysis was performed on the collected data. The retained principal components (PCs) were subjected to non-hierarchical k-means cluster analysis to group respondents into clusters based on the similarity of perceived outcomes. A total of 840 responses were obtained. Twenty-eight original variables from the questionnaire were summarised into five PCs, explaining 63.0% of the total variance. The majority of respondents felt that the information they had received about the Russo-Ukrainian war was unreliable. Older, educated, professional people with exposure to fake news were sceptical about the reliability of information related to the war. Young adults who were active on social networks and had no detailed knowledge of the events considered information about the war to be reliable. The study found that the greater an individual’s ability to spot fake news, the lower their trust in social media and their information habits on social networks. © 2023 by the authors.",no
10.1038/s41562-023-01641-6,understanding and combatting misinformation across 16 countries on six continents,"The spread of misinformation online is a global problem that requires global solutions. To that end, we conducted an experiment in 16 countries across 6 continents (N = 34,286; 676,605 observations) to investigate predictors of susceptibility to misinformation about COVID-19, and interventions to combat the spread of this misinformation. In every country, participants with a more analytic cognitive style and stronger accuracy-related motivations were better at discerning truth from falsehood; valuing democracy was also associated with greater truth discernment, whereas endorsement of individual responsibility over government support was negatively associated with truth discernment in most countries. Subtly prompting people to think about accuracy had a generally positive effect on the veracity of news that people were willing to share across countries, as did minimal digital literacy tips. Finally, aggregating the ratings of our non-expert participants was able to differentiate true from false headlines with high accuracy in all countries via the ‘wisdom of crowds’. The consistent patterns we observe suggest that the psychological factors underlying the misinformation challenge are similar across different regional settings, and that similar solutions may be broadly effective. © 2023, The Author(s), under exclusive licence to Springer Nature Limited.",yes
10.1186/s41235-023-00492-z,examining the replicability of backfire effects after standalone corrections,"Corrections are a frequently used and effective tool for countering misinformation. However, concerns have been raised that corrections may introduce false claims to new audiences when the misinformation is novel. This is because boosting the familiarity of a claim can increase belief in that claim, and thus exposing new audiences to novel misinformation—even as part of a correction—may inadvertently increase misinformation belief. Such an outcome could be conceptualized as a familiarity backfire effect, whereby a familiarity boost increases false-claim endorsement above a control-condition or pre-correction baseline. Here, we examined whether standalone corrections—that is, corrections presented without initial misinformation exposure—can backfire and increase participants’ reliance on the misinformation in their subsequent inferential reasoning, relative to a no-misinformation, no-correction control condition. Across three experiments (total N = 1156) we found that standalone corrections did not backfire immediately (Experiment 1) or after a one-week delay (Experiment 2). However, there was some mixed evidence suggesting corrections may backfire when there is skepticism regarding the correction (Experiment 3). Specifically, in Experiment 3, we found the standalone correction to backfire in open-ended responses, but only when there was skepticism towards the correction. However, this did not replicate with the rating scales measure. Future research should further examine whether skepticism towards the correction is the first replicable mechanism for backfire effects to occur. © 2023, The Author(s).",no
10.1186/s41235-023-00488-9,"multiple-choice quizzes improve memory for misinformation debunks, but do not reduce belief in misinformation","Fact-checkers want people to both read and remember their misinformation debunks. Retrieval practice is one way to increase memory, thus multiple-choice quizzes may be a useful tool for fact-checkers. We tested whether exposure to quizzes improved people’s accuracy ratings for fact-checked claims and their memory for specific information within a fact check. Across three experiments, 1551 US-based online participants viewed fact checks (either health- or politics-related) with or without a quiz. Overall, the fact checks were effective, and participants were more accurate in rating the claims after exposure. In addition, quizzes improved participants’ memory for the details of the fact checks, even 1 week later. However, that increased memory did not lead to more accurate beliefs. Participants’ accuracy ratings were similar in the quiz and no-quiz conditions. Multiple-choice quizzes can be a useful tool for increasing memory, but there is a disconnect between memory and belief. © 2023, The Author(s).",yes
10.1186/s41235-023-00505-x,game-based inoculation versus graphic-based inoculation to combat misinformation: a randomized controlled trial,"Misinformation affects various aspects of people’s lives, such as politics, entertainment, and social interactions. However, effective intervention measures to combat misinformation are lacking. The inoculation theory has become a prevalent measure of misinformation. This study employed inoculation theory and developed an interactive game to help the public counter misinformation. In this game, players take on the role of the misinformation spreader, intending to add more followers to their virtual accounts using different strategies. A total of 180 Chinese participants were randomly assigned to game-based inoculation, graphic-based inoculation, and control groups. The results indicated that both types of inoculation interventions significantly decreased the perceived credibility and sharing intention of misinformation. Game-based inoculation was more effective than graphic-based inoculation in terms of misinformation perceived credibility, and the intervention effects were stable after 2 weeks. The graphic-based inoculation contained the sleeper effect, which interventions required a period of time to take effect. Neither inoculation produced countereffects on perceived credibility and nor sharing intention of accurate information. © 2023, The Author(s).",yes
10.1016/j.jrp.2023.104394,misperceptions in a post-truth world: effects of subjectivism and cultural relativism on bullshit receptivity and conspiracist ideation,"This research investigated whether belief in truth relativism yields higher receptivity to misinformation. Two studies with representative samples from Sweden (Study 1, N = 1005) and the UK (Study 2, N = 417) disentangled two forms of truth relativism: subjectivism (truth is relative to subjective intuitions) and cultural relativism (truth is relative to cultural context). In Study 1, subjectivism was more strongly associated with receptivity to pseudo-profound bullshit and conspiracy theories than cultural relativism was. In Study 2 (preregistered), subjectivism predicted higher receptivity to both forms of misinformation over and above effects of analytical and actively open-minded thinking, profoundness receptivity, ideology, and demographics; the unique effects of cultural relativism were in the opposite direction (Study 1) or non-significant (Study 2). © 2023 The Authors",no
10.1038/s41598-023-43885-2,how to “inoculate” against multimodal misinformation: a conceptual replication of roozenbeek and van der linden (2020),"Building misinformation resilience at scale continues to pose a challenge. Gamified “inoculation” interventions have shown promise in improving people’s ability to recognize manipulation techniques commonly used in misinformation, but so far few interventions exist that tackle multimodal misinformation (e.g., videos, images). We developed a game called Cat Park, in which players learn about five manipulation techniques (trolling, emotional manipulation, amplification, polarization, and conspiracism), and how misinformation can spread through images. To test the game’s efficacy, we conducted a conceptual replication (N = 380) of Roozenbeek and van der Linden’s 2020 study about Harmony Square, with the same study design, item set, and hypotheses. Like the original study, we find that people who play Cat Park find misinformation significantly less reliable post-gameplay (d = 0.95, p < 0.001) compared to a control group, and are significantly less willing to share misinformation with people in their network (d = 0.54, p < 0.001). These effects are robust across different covariates. However, unlike the original study, Cat Park players do not become significantly more confident in their ability to identify misinformation (p = 0.204, d = − 0.13). We did not find that the game increases people’s self-reported motivation and confidence to counter misinformation online. © 2023, Springer Nature Limited.",yes
10.1017/S0007123422000631,conceptual replication of four key findings about factual corrections and misinformation during the 2020 us election: evidence from panel-survey experiments,"In the final two months of the 2020 US election, we conducted eight panel experiments to evaluate the immediate and medium-term effects of misinformation and factual corrections. Our results corroborate four sets of existing findings: fact-checks reliably improve factual accuracy, while misinformation degrades it; effects of fact-checks on belief accuracy endure, though they fade with time; effects on attitudes are minuscule; and there are important partisan asymmetries. We also offer one new empirical finding suggesting that effect heterogeneities by personality type and cognitive style may reflect attention paid to treatments. Our study confirms that the fundamental push and pull of misinformation and factual corrections on political beliefs holds even in electoral settings as saturated with mistruths as the 2020 US election.  Copyright © The Author(s), 2023. Published by Cambridge University Press.",no
10.1002/acp.4136,"to believe or not to believe: personality, cognitive, and emotional factors involving fake news perceived accuracy","What are the factors that influence individuals' belief in fake news? A structured survey was conducted to examine the impact of cognitive, emotional, and personality factors on the perceived accuracy of fake news. This study utilizes certain facets of the Personality Inventory of the Diagnostic and Statistical Manual of Mental Disorders (PID-5-Adult trait) to investigate the phenomenon of fake news. Using actual fake news headlines encountered on Facebook, the study revealed that individuals with high levels of psychoticism, impulsivity, suspiciousness, and low analytical reasoning abilities are more likely to believe fake news. Furthermore, the study found that fear induced by news content significantly influences by impeding rational, factual analysis. These findings suggest that while social media platforms contribute to the dissemination of fake news, individual vulnerabilities also play a crucial role. These findings could be useful for the development of digital literacy programs. © 2023 John Wiley & Sons Ltd.",no
10.1111/bjhp.12670,how to debunk misinformation? an experimental online study investigating text structures and headline formats,"Objectives: Misinformation is a crucial problem, particularly online, and the success of debunking messages has so far been limited. In this study, we experimentally test how debunking text structure (truth sandwich vs. bottom-heavy) and headline format (statement vs. questions) affect the belief in misinformation across topics of the safety of COVID vaccines and GMO foods. Design: Experimental online study. Methods: A representative German sample of 4906 participants were randomly assigned to reading one of eight debunking messages in the experimentally varied formats and subsequently rated the acceptance of this message and the agreement to misinformation statements about the mentioned topics and an unrefuted control myth. Results: While the debunking messages specifically decreased the belief in the targeted myth, these beliefs and the acceptance of the debunking message were unaffected by the text structures and headline formats. Yet, they were less successful when addressing individuals with strong pre-existing, incongruent attitudes and distrust in science. Conclusions: The risk of backfire effects in debunking misinformation is low. Text structure and headline format are of relatively little importance for the effectiveness of debunking messages. Instead, writers may need to pay attention to the text being comprehensive, trustworthy and persuasive to maximize effectiveness. © 2023 The Authors. British Journal of Health Psychology published by John Wiley & Sons Ltd on behalf of British Psychological Society.",no
10.1177/10755470231207611,"exploring covid-19 vaccine misinformation exposure, beliefs, fear, and information avoidance via the stimulus–organism–response framework","Empirical evidence generated from theory-driven research addressing the relationship between misinformation and vaccine information avoidance during a pandemic remains lacking. Using the Stimulus-Organism-Response (S-O-R) framework, this study examined the influence of vaccine misinformation exposure and information overload on cognitive and affective responses as well as vaccine information avoidance behaviors. Findings showed that misinformation exposure predicted cognitive health beliefs (perceived vaccination barriers and benefits) and negative emotions (fear) toward the vaccines; health beliefs in turn predicted information avoidance. Information overload moderated (a) the relationship between misinformation exposure and health beliefs and (b) the relation between misinformation exposure and fear. © The Author(s) 2023.",no
10.1038/s41598-023-39807-x,the relation between authoritarian leadership and belief in fake news,"Individual factors such as cognitive capacities matter when one is requested to spot fake news. We suggest, however, that social influence—specifically as exercised by an authoritarian leader—might matter more if one is expected to agree with the fake news. We developed a single-item prototype measure of leadership styles and recruited participants from four Western democratic countries (Australia, Canada, United Kingdom, United States, N = 501) who identified their immediate boss as an autonomous, paternalistic, or authoritarian leader. Then they were asked to evaluate the accuracy of several fake news articles and their expectations to agree with their boss when asked about these articles. People with authoritarian bosses were less accurate in spotting fake news (Cohen’s d = 0.32) compared to employees with autonomous bosses. The bigger effect, however, was that they would agree with their boss about the fake news article when it was shared by their authoritarian boss compared to employees with autonomous (Cohen’s d = 1.30) or paternalistic bosses (Cohen’s d = 0.70). We argue that in addition to effects on the perceived accuracy of information, social influence, conformity, and obedience are crucial and unacknowledged factors of how misinformation may be maintained and propagated by authoritarian leaders. © 2023, Springer Nature Limited.",no
10.1098/rsos.221097,correcting covid-19 vaccine misinformation in 10 countries,"What can be done to reduce misperceptions about COVID-19 vaccines? We present results from experiments conducted simultaneously on YouGov samples in 10 countries (N = 10 600), which reveal that factual corrections consistently reduce false beliefs about vaccines. With results from these 10 countries, we find that exposure to corrections increases belief accuracy by 0.16 on a 4-point scale, while exposure to misinformation decreases belief accuracy by 0.09 on the same scale. We are unable to find evidence that either misinformation or factual corrections affect intent to vaccinate or vaccine attitudes. Our findings on effect duration are less conclusive; when we recontacted participants two weeks later, we observed 39% of the initial accuracy increase, yet this result narrowly misses conventional thresholds of statistical significance (p = 0.06). Taken together, our results illustrate both the possibilities and limitations of factual corrections. Evidence from 10 highly diverse populations shows that exposure to factual information reduces belief in falsehoods about vaccines, but has minimal influence on subsequent behaviours and attitudes. © 2023 The Authors.",yes
10.1037/xge0001395,gamified inoculation interventions do not improve discrimination between true and fake news: reanalyzing existing research with receiver operating characteristic analysis,"Gamified inoculation interventions designed to improve the detection of online misinformation are becoming increasingly prevalent. Two of the most notable interventions of this kind are Bad News and Go Viral!. To assess their efficacy, prior research has typically used pre–post designs in which participants rated the reliability or manipulativeness of true and fake news items before and after playing these games, while most of the time also including a control group who played an irrelevant game (Tetris) or did nothing at all. Mean ratings were then compared between pre-tests and post-tests and/or between the control and experimental conditions. Critically, these prior studies have not separated response bias effects (overall tendency to respond “true” or “fake”) from discrimination (ability to distinguish between true and fake news, commonly dubbed discernment).We reanalyzed the results from five prior studies using receiver operating characteristic (ROC) curves, a method common to signal detection theory that allows for discrimination to be measured free from response bias. Across the studies, when comparable true and fake news items were used, Bad News and Go Viral! did not improve discrimination, but rather elicited more “false” responses to all news items (more conservative responding). These novel findings suggest that the current gamified inoculation interventions designed to improve fake news detection are not as effective as previously thought and may even be counterproductive. They also demonstrate the usefulness of ROC analysis, a largely unexploited method in this setting, for assessing the effectiveness of any intervention designed to improve fake news detection. © 2023 American Psychological Association",yes
10.1371/journal.pone.0282308,information battleground: conflict perceptions motivate the belief in and sharing of misinformation about the adversary,"Misinformation has emerged as a major societal concern. But why do citizens contribute to the dissemination of falsehoods online? This article investigates this question by focusing on the role of motivated reasoning and, in particular, perceptions of group-based conflict. It examines the effect of perceived conflict on the endorsement of false news in the context of a regional conflict between Russia and the West as experienced by Ukrainian citizens. In our survey experiment, a sample of Ukrainians (N = 1,615) was randomly assigned to read negative false news stories about Russia, the European Union or Tanzania–a country with no stakes in the conflict. The results show that higher perceived conflict between Ukraine and Russia makes Ukrainians less likely to endorse false news targeting the European Union, but more likely to endorse false news that paint a negative picture of Russia. This finding extends the support for motivated reasoning theory beyond Western contexts investigated so far. Importantly, the effects of conflict perceptions remain strong after controlling for group identity and political knowledge of participants. These results advance our understanding of why false information is disseminated and point to the importance of conflict deescalation to prevent the diffusion of falsehoods. © 2023 Mazepus et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",no
10.1371/journal.pone.0283238,learning about informal fallacies and the detection of fake news: an experimental intervention,"The philosophical concept of informal fallacies–arguments that fail to provide sufficient support for a claim–is introduced and connected to the topic of fake news detection. We assumed that the ability to identify informal fallacies can be trained and that this ability enables individuals to better distinguish between fake news and real news. We tested these assumptions in a two-group between-participants experiment (N = 116). The two groups participated in a 30-minute-long text-based learning intervention: either about informal fallacies or about fake news. Learning about informal fallacies enhanced participants’ ability to identify fallacious arguments one week later. Furthermore, the ability to identify fallacious arguments was associated with a better discernment between real news and fake news. Participants in the informal fallacy intervention group and the fake news intervention group performed equally well on the news discernment task. The contribution of (identifying) informal fallacies for research and practice is discussed. Copyright: © 2023 Hruschka, Appel. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",yes
10.1037/xap0000458,effects of inductive learning and gamification on news veracity discernment,"This preregistered study tests a novel psychological intervention to improve news veracity discernment. The main intervention involved inductive learning (IL) training (i.e., practice discriminating between multiple true and fake news exemplars with feedback) with or without gamification. Participants (N = 282 Prolific users) were randomly assigned to either a gamified IL intervention, a nongamified version of the same IL intervention, a no-treatment control group, or a Bad News intervention, a notable web-based game designed to tackle online misinformation. Following the intervention (if applicable), all participants rated the veracity of a novel set of news headlines. We hypothesized that the gamified intervention would be the most effective for improving news veracity discernment, followed by its nongamified equivalent, then Bad News, and finally the control group. The results were analyzed with receiver-operating characteristic curve analyses, which have previously never been applied to news veracity discernment. The analyses indicated that there were no significant differences between conditions and the Bayes factor indicated very strong evidence for the null. This finding raises questions about the effectiveness of current psychological interventions and contradicts prior research that has supported the efficacy of Bad News. Age, gender, and political leaning all predicted news veracity discernment. © 2023 American Psychological Association",yes
10.1016/j.actpsy.2023.103930,is the covid-19 bad news game good news? testing whether creating and disseminating fake news about vaccines in a computer game reduces people's belief in anti-vaccine arguments,"Improving vaccination eagerness is crucial, especially during the ongoing COVID-19 pandemic and establishing new procedures to achieve that goal is highly important. Previous research (Roozenbeek & van der Linden, 2019a, 2019b) has indicated that playing the “Bad News” game, in which a player spreads fake news to gain followers, reduces people's belief in fake news. The goal of the present paper was to test an analogous new game called “COVID-19 Bad News (CBN)” to improve one's eagerness to vaccinate against coronavirus. CBN was constructed to examine whether creating and disseminating fake news focused on vaccinations and the COVID-19 pandemic has a similar effect and improves people's attitudes toward vaccination. Two experiments were conducted where participants played CBN or Tetris and afterwards evaluated the credibility of statements about vaccines against COVID-19 and finally filled out a questionnaire concerning their attitudes toward vaccination. The results show that playing CBN does not reduce evaluations of the credibility of all statements that are unfavorable to vaccines (false as well as true). Additionally, it does not enhance readiness to vaccinate. Future research and limitations are discussed. © 2023",yes
10.1086/722345,latino-targeted misinformation and the power of factual corrections,"Do individual, interpersonal, or institutional factors condition the effects ofmisinformation on beliefs? Can interventions such as fact checks stem the tide of the “infodemic” within marginalized communities? We explore the sudden flood of misinformation and disinformation targeting Latinos during the 2020 election and global COVID-19 pandemic to answer these questions. In a preregistered experiment, we find that exposure to misinformation can decrease factual accuracy, and neither trust in nor consumption of media, including ethnic media, serves as a buffer against these misinformation effects. However, fact checks eliminate the effects of misinformation on false beliefs without “backfiring” and reducing accuracy. Fact checks improve factual accuracy among subgroups varying in levels of political knowledge, trust, and acculturation. These findings provide crucial support for recent investments into fact checking by Latino-oriented media outlets and address gaps within the literature over whether such interventions are also effective within marginalized groups. © 2023 Southern Political Science Association. All rights reserved. Published by The University of Chicago Press for the Southern Political Science Association.",no
10.1126/sciadv.adg8333,social media: why sharing interferes with telling true from false,Sharing on social media decreases true-false discrimination but focusing on accuracy helps people recognize what they already know. Process-oriented research offers hope in combatting misinformation. © 2023 American Association for the Advancement of Science. All rights reserved.,yes
10.1177/09636625231215979,credibility of misinformation source moderates the effectiveness of corrective messages on social media,"To examine how different features of corrective messages moderate individuals’ attitudes toward misinformation on social media, a 2 (misinformation source credibility: high vs low) × 2 (corrective message source: algorithmic vs peer correction) × 2 (correction type: factual elaboration vs simple rebuttal) between-subjects experiment was conducted. To reduce perceived credibility and respondents’ attitudes toward the misinformation, peer corrections were more effective than algorithmic corrections for misinformation from a source with lower credibility; for misinformation from a highly credible source, the superiority effect of peer corrections was still significant on perceived credibility but not on respondents’ attitudes toward the misinformation. For the fact-checking tendency, we did not find a robust effect about how different features of corrective messages interacted. Our findings provide important insights into message design in combatting misinformation on social media. © The Author(s) 2023.",no
10.1371/journal.pone.0281140,correcting vaccine misinformation: a failure to replicate familiarity or fear-driven backfire effects,"Individuals often continue to rely on misinformation in their reasoning and decision making even after it has been corrected. This is known as the continued influence effect, and one of its presumed drivers is misinformation familiarity. As continued influence can promote misguided or unsafe behaviours, it is important to find ways to minimize the effect by designing more effective corrections. It has been argued that correction effectiveness is reduced if the correction repeats the to-be-debunked misinformation, thereby boosting its familiarity. Some have even suggested that this familiarity boost may cause a correction to inadvertently increase subsequent misinformation reliance; a phenomenon termed the familiarity backfire effect. A study by Pluviano et al. (2017) found evidence for this phenomenon using vaccine-related stimuli. The authors found that repeating vaccine “myths” and contrasting them with corresponding facts backfired relative to a control condition, ironically increasing false vaccine beliefs. The present study sought to replicate and extend this study. We included four conditions from the original Pluviano et al. study: the myths vs. facts, a visual infographic, a fear appeal, and a control condition. The present study also added a “myths-only” condition, which simply repeated false claims and labelled them as false; theoretically, this condition should be most likely to produce familiarity backfire. Participants received vaccine-myth corrections and were tested immediately post-correction, and again after a seven-day delay. We found that the myths vs. facts condition reduced vaccine misconceptions. None of the conditions increased vaccine misconceptions relative to control at either timepoint, or relative to a pre-intervention baseline; thus, no backfire effects were observed. This failure to replicate adds to the mounting evidence against familiarity backfire effects and has implications for vaccination communications and the design of debunking interventions. © 2023 Ecker et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",no
10.37016/mr-2020-123,assessing misinformation recall and accuracy perceptions: evidence from the covid-19 pandemic,"Misinformation is ubiquitous; however, the extent and heterogeneity in public uptake of it remains a matter of debate. We address these questions by exploring Americans’ ability to recall prominent misinformation during the COVID-19 pandemic and the factors associated with accuracy perceptions of these claims. Comparing reported recall rates of real and “placebo” headlines, we estimate “true” recall of misinformation is lower than self-reporting suggests but still troubling. Supporters of President Trump, particularly strong news consumers, were most likely to believe misinformation, including ideologically dissonant claims. These findings point to the importance of tailoring corrections to address key correlates of misinformation uptake. © 2023, Harvard Kennedy School. All rights reserved.",yes
10.1177/09636625231217081,institutional and non-institutional news trust as predictors of covid-19 beliefs: evidence from three european countries,"The COVID-19 pandemic was accompanied by an infodemic in which trust in news played an essential role. This article analyzes how this trust can be divided into two components, institutional and non-institutional, which are differentially related to beliefs about COVID-19 and perceptions of receiving misinformation and disinformation. Based on a survey conducted in three European countries (Germany, Spain, and the United Kingdom), the study confirms that higher levels of institutional news trust (the trust dimension correlated more with trust in the news media, government, politicians, national and global health organizations, and scientists) are a good predictor of both better knowledge of COVID-19 myths and misstatements, and lower perceptions of being surrounded by false and misleading information about the virus. The research also highlights the special role of media and political sources in strengthening the institutional dimension of news trust. © The Author(s) 2023.",no
10.5334/joc.324,mixed news about the bad news game,"Basol et al. (2020) tested the ""the Bad News Game""(BNG), an app designed to improve ability to spot false claims on social media. Participants rated simulated Tweets, then played either the BNG or an unrelated game, then re-rated the Tweets. Playing the BNG lowered rated belief in false Tweets. Here, four teams of undergraduate psychology students each attempted an extended replication of Basol et al., using updated versions of the original Bad News game. The most important extension was that the replications included a larger number of true Tweets than the original study and planned analyses of responses to true Tweets. The four replications were loosely coordinated, with each team independently working out how to implement the agreed plan. Despite many departures from the Basol et al. method, all four teams replicated their key finding: Playing the BNG reduced belief in false Tweets. But playing the BNG also reduced belief in true Tweets to the same or almost the same extent. Exploratory signal detection theory analyses indicated that the BNG increased response bias but did not improve discrimination. This converges with findings reported by Modirrousta- Galian and Higham (2023).  © 2023 The Author(s).",yes
10.17645/mac.v11i4.7090,overcoming the age barrier: improving older adults’ detection of political disinformation with media literacy,"This experimental study analyzes the effect of media literacy on the ability of Spanish seniors over 50 years of age to identify fake news. The experiment measures the improvement achieved by older adults in the detection of political disinformation thanks to a digital competence course offered through WhatsApp. The study comprises a total sample of 1,029 individu-als, subdivided into a control group (n = 531) and an experimental group (n = 498), from which a qualified experimental subsample (n = 87) was extracted. Results reveal that participants’ political beliefs, ranging from left to right positions, influence their ability to detect misinformation. A progressive political position is associated with higher accuracy in identifying right-biased news headlines and lower accuracy for left-biased headlines. A conservative position is associated with higher accuracy when the news headline has a progressive bias, but lower accuracy when the headline is right-wing. Users are more critical when the headline has a bias against theirs, while they are more likely to believe news that confirms their own beliefs. The study adds evidence on the relevance of cognitive biases in disinformation and supports the convenience of designing specific media literacy actions aimed at older adults. © 2023 by the author(s); licensee Cogitatio Press (Lisbon, Portugal).",yes
10.1177/00104140231193008,online disinformation predicts inaccurate beliefs about election fairness among both winners and losers,"Electoral disinformation is feared to variously undermine democratic trust by inflaming incorrect negative beliefs about the fairness of elections, or to shore up dictators by creating falsely positive ones. Recent studies of political misperceptions, however, suggest that disinformation has at best minimal effects on beliefs. In this article, we investigate the drivers of public perceptions and misperceptions of election fairness. We build on theories of rational belief updating and motivated reasoning, and link public opinion data from 82 national elections with expert survey data on disinformation and de facto electoral integrity. We show that, overall, people arrive at largely accurate perceptions, but that disinformation campaigns are indeed associated with less accurate and more polarized beliefs about election fairness. This contributes a cross-nationally comparative perspective to studies of (dis)information processing and belief updating, as well as attitude formation and trust surrounding highly salient political institutions such as elections. © The Author(s) 2023.",yes
10.23860/JMLE-2023-15-2-5,filipino students' competency in evaluating digital media content credibility: 'beginning' to 'emerging' levels,"This study investigates Filipino students' reasoning competency levels in evaluating the credibility of digital media content and whether significant statistical differences exist in their competency by education status, sex, age group, Internet use, or geographical location. Four hundred twenty-four students representing the senior high school, undergraduate, and postgraduate levels responded to four modified versions of the Stanford History Education Group's civic online reasoning tasks. The study found that most students have 'beginning' competency levels in author-checking, fact-checking, and biaschecking but 'emerging' competency levels for image-checking. Younger students and those who spend more hours online have higher mean competency levels for verifying the authenticity of a social media page. Postgraduate students fared better in distinguishing facts from opinions in arguments, while students residing in the Masbate province consistently registered lower mean scores for author- and fact-checking. This study indicates the need to strengthen Filipino students' information/media literacy across educational levels. Copyright:  © 2023 Author(s).",yes
10.3389/fpsyg.2023.1242865,"true, justified, belief? partisanship weakens the positive effect of news media literacy on fake news detection","To investigate how people assess whether politically consistent news is real or fake, two studies (N = 1,008; N = 1,397) with adult American participants conducted in 2020 and 2022 utilized a within-subjects experimental design to investigate perceptions of news accuracy. When a mock Facebook post with either fake (Study 1) or real (Study 2) news content was attributed to an alternative (vs. a mainstream) news outlet, it was, on average, perceived to be less accurate. Those with beliefs reflecting News Media Literacy demonstrated greater sensitivity to the outlet’s status. This relationship was itself contingent on the strength of the participant’s partisan identity. Strong partisans high in News Media Literacy defended the accuracy of politically consistent content, even while recognizing that an outlet was unfamiliar. These results highlight the fundamental importance of looking at the interaction between user-traits and features of social media news posts when examining learning from political news on social media. Copyright © 2023 Sude, Sharon and Dvir-Gvirsman.",no
10.1080/03055698.2023.2296345,helping young students cope with the threat of fake news: efficacy of news literacy training for junior-secondary school students in hong kong,"As fake news proliferates, to the urgency to educate young students in news literacy grows. Research indicates that while young adolescent students recognize the detrimental impact that fake news has on society, they lack the knowledge and motivation to combat it. We conducted news literacy training with 101 Hong Kong students (aged 11 to 14) evaluating their news literacy, susceptibility to fake news, perceived responsibility, as well as motivation to engage in protective behaviours. The training significantly enhanced participants’ news media knowledge, perceived control, and reduced their vulnerability to fake news. Participants became more motivated to report fake news, warn others, suggest alternative sources, and manage preferences to filter our problematic news sources. Participants also demonstrated an improved ability to evaluate the credibility of a real-world news article. These findings demonstrate the effectiveness of the training for this age group and suggest its potential for implementation in junior secondary-school classrooms. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",yes
10.1080/0965254X.2023.2253819,"i think, therefore i ignore: a study on disinformation’s credibility perceptions and sharing intentions over social media","This paper evaluates the influence that bandwagon heuristics (conceptualized as the number of likes and comments’ valence) and actively open-minded thinking (AOT) have on the credibility and sharing of disinformation over social media. Across two experimental studies, Study 1 finds a direct link between the sharing intention of social media posts containing disinformation and an interactive effect of AOT on such bandwagon heuristics. Study 2 demonstrates that for posts containing disinformation, the number of likes has a significant influence on sharing intentions, but not credibility, whilst comments have a significant influence on credibility, but not sharing intentions. Furthermore, Study 2 found the influence of AOT attenuates the effects of such heuristics. Overall, this research contributes to the extant literature and practice by demonstrating the influence bandwagon heuristics and AOT have on disinformation over social media. This paper further presents areas of future research to improve the understanding of how disinformation spreads. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",no
10.1177/00936502231206419,"checking the fact-checkers: the role of source type, perceived credibility, and individual differences in fact-checking effectiveness","This study investigates fact-checking effectiveness in reducing belief in misinformation across various types of fact-check sources (i.e., professional fact-checkers, mainstream news outlets, social media platforms, artificial intelligence, and crowdsourcing). We examine fact-checker credibility perceptions as a mechanism to explain variance in fact-checking effectiveness across sources, while taking individual differences into account (i.e., analytic thinking and alignment with the fact-check verdict). An experiment with 859 participants revealed few differences in effectiveness across fact-checking sources but found that sources perceived as more credible are more effective. Indeed, the data show that perceived credibility of fact-check sources mediates the relationship between exposure to fact-checking messages and their effectiveness for some source types. Moreover, fact-checker credibility moderates the effect of alignment on effectiveness, while analytic thinking is unrelated to fact-checker credibility perceptions, alignment, and effectiveness. Other theoretical contributions include extending the scope of the credibility-persuasion association and the MAIN model to the fact-checking context, and empirically verifying a critical component of the two-step motivated reasoning model of misinformation correction. © The Author(s) 2023.",yes
10.1080/10510974.2023.2246210,does tone of comments matter?: exploring the role of uncivil comments and political orientation on weakening belief in fake news and eliciting anger,"Although fake news has become a serious social issue and the detrimental effects of fake news have become more salient in online environments, scholars have not extensively studied the role of uncivil comments posted about fake news. As fake news itself is typically partisan and tends to deceive publics for specific purposes (e.g. gaining support for specific agendas), it usually induces heated discussion and uncivil commenting, especially among politically partisan individuals. Thus, in this study, we explored the effects of uncivil comments following fake news and political orientation on belief in fake news and anger. We used two issues to explore these mechanisms: climate change and immigration. Our results show that uncivil comments following fake news weakened participants’ belief in fake news about climate change. Moreover, uncivil comments made people angrier after viewing fake news about each issue. A significant moderating effect of political orientation on this relationship also emerged. Conservatives, who generally had a lower level of anger toward fake news than liberals, were more likely to feel anger when they viewed uncivil comments rather than civil comments. Theoretical and practical implications are discussed. © 2023 Central States Communication Association.",no
10.1177/02666669231206784,analyzing patterns of political news evaluation among university students in northeast thailand,"Through social media and digital platforms, fake news and both professional as well as non-professional news sources are increasingly circulated, thus having a greater impact on people's lives and society. As a result, evaluating news has emerged as a crucial skill. However, it is yet unclear what variables contribute to this increase. To offer more insights, this study attempts to investigate through political news accessibility the factors influencing political news assessment of university students in Northeast Thailand. This study was a quantitative research, and the theory underlying it was news literacy. 1200 samples from undergraduate students from state, private, and autonomous universities were obtained through a multi-stage sampling. 400 questionnaires, utilized as a research tool, were distributed to each type of university for data collection. In order to examine the reliability of the research instrument, Cronbach's alpha was also used in a pre-test stage along with a content validity analysis of the questionnaire. For all elements, the alpha coefficient was 0.93. The findings demonstrated that political news assessment was most influenced by political news accessibility, which is the intervening variable (Beta = 0.265); followed by political news exposure from social media (Beta = 0.217); inner drives for the follow-up of political news (Beta = 0.190); influence of groups and social networks (Beta = 0.170); specific characteristics of the Internet (Beta = 0.151); importance of political news (Beta = 0.147); political news exposure from websites (Beta = 0.099); benefits of political news (Beta = 0.075); and political news exposure from print media (Beta = 0.042). The student characteristic factor, motivation for political news exposure factor, and political news exposure factor accounted for 67.45 percent of the variance in explaining political news evaluation among Thai students, through political news accessibility (R2 = 0.6745). Consequently, improving these elements will lead to better political news evaluation. © The Author(s) 2023.",no
10.1515/commun-2023-0010,with time comes trust? the development of misinformation perceptions related to covid-19 over a six-month period: evidence from a five-wave panel survey study in the netherlands,"Misinformation perceptions related to global crises such as COVID-19 can have negative ramifications for democracy. Beliefs related to the prevalence of falsehoods may increase news avoidance or even vaccine hesitancy - a problematic context for successful interventions and policymaking. To explore how misinformation beliefs developed over a six-month pandemic period and how they corresponded to (digital) media preferences and selective exposure to the news, we rely on a five-wave panel survey conducted in the Netherlands (N =1,742). Our main findings show that misinformation perceptions got more pronounced as the pandemic evolved. Social media use related to more pronounced misinformation beliefs within waves, whereas mainstream news use corresponded to less pronounced misinformation beliefs. An important implication for journalists and policymakers is to lower the over-time accumulation of misinformation perceptions, for example, by increasing transparency and acknowledging ""honest mistakes."" © 2023 De Gruyter Mouton. All rights reserved.",yes
10.1017/XPS.2023.20,testing the effect of information on discerning the veracity of news in real time,"Despite broad adoption of digital media literacy interventions that provide online users with more information when consuming news, relatively little is known about the effect of this additional information on the discernment of news veracity in real time. Gaining a comprehensive understanding of how information impacts discernment of news veracity has been hindered by challenges of external and ecological validity. Using a series of pre-registered experiments, we measure this effect in real time. Access to the full article relative to solely the headline/lede and access to source information improves an individual's ability to correctly discern the veracity of news. We also find that encouraging individuals to search online increases belief in both false/misleading and true news. Taken together, we provide a generalizable method for measuring the effect of information on news discernment, as well as crucial evidence for practitioners developing strategies for improving the public's digital media literacy.  © The Author(s), 2023. Published by Cambridge University Press on behalf of American Political Science Association.",yes
10.1111/1475-6765.12646,mistakenly misinformed or intentionally deceived? mis- and disinformation perceptions on the russian war in ukraine among citizens in 19 countries,"In information environments characterized by institutional distrust, fragmentation and the widespread dissemination of conspiracies and disinformation, citizens perceive misinformation as a salient and threatening issue. Especially amidst disruptive events and crises, news users are likely to believe that information is inaccurate or deceptive. Using an original 19-country comparative survey study across diverse regions in the world (N = 19,037), we find that news users are likely to regard information on the Russian war in Ukraine as false. They are more likely to attribute false information to deliberative deception than to a lack of access to the war area or inaccurate expert knowledge. Russian sources are substantially more likely to be blamed for falsehoods than Ukrainian or Western sources – but these attribution biases depend on a country's position on the war. Our findings reveal that people mostly believe that falsehoods are intended to deceive them, and selectively associate misinformation with the opposed camp. © 2023 The Authors. European Journal of Political Research published by John Wiley & Sons Ltd on behalf of European Consortium for Political Research.",yes
10.3389/fpsyg.2023.1165039,"evaluation of misinformation among pro-ukrainian latvians – the role of prior attitude, analytical thinking, and emotions","In this exploratory study with a community sample (N = 115), we look at the perception of pro-Russia and pro-Ukraine misinformation, mimicking content shared by naive Facebook users, and the factors related to it among pro-Ukraine Latvians. Our results support the integrative model in the perception of misinformation—we found strong evidence of myside bias, as pro-Russia misinformation was judged to be significantly less accurate than pro-Ukraine misinformation. Analytical thinking, measured with the seven-item cognitive reflection test, was associated with lower levels of pro-Ukraine misinformation accuracy judgments and lower overall misinformation accuracy judgments; however, there was no correlation between analytical thinking and pro-Russian misinformation accuracy judgments. Pro-Ukrainian misinformation accuracy judgments were positively related to positive emotions elicited by misinformation, the level of support for Ukraine, and the participant's age. In addition, participants indicated a higher likelihood of engaging with misinformation if they came across it online, trusted the information, and if it elicited positive emotions. Thus, our findings emphasize the role of one's attitude, analytical thinking, and emotions in one's perception, evaluation, and engagement with congruent and incongruent misinformation. Copyright © 2023 Priedols and Dimdins.",no
10.37016/mr-2020-128,increasing accuracy motivations using moral reframing does not reduce republicans’ belief in false news,"In a pre-registered survey experiment with 2,009 conservative Republicans, we evaluated an intervention that framed accurate perceptions of information as consistent with a conservative political identity and conservative values (e.g., patriotism, respect for tradition, and religious purity). The intervention caused participants to report placing greater value on accuracy, and placing greater value on accuracy was correlated with successfully rating true headlines as more accurate than false headlines. Yet, the intervention had no significant direct effect on the accuracy of headline ratings. These results suggest that moral reframing, and perhaps interventions based on connecting accuracy motivation with political identity more generally, may not be promising for combatting belief in misinformation. © 2023, Harvard Kennedy School. All rights reserved.",yes
10.17645/mac.v11i2.6381,vulnerability to disinformation in relation to political affiliation in north macedonia,"This study aims to analyze the relationship between political affiliation and vulnerability to disinformation in North Macedonia through the role of psychological and social constraints in shaping how individuals respond to and process information. Research has shown that politically affiliated individuals may be particularly vulnerable to disinformation in part due to confirmation bias or the tendency to accept and seek out information that is consistent with one’s preex-isting beliefs and ignore or refute information that is not. Using the quantitative method and cross‐matched data from the empirical research, the study has shown that political affiliation affects the way individuals perceive disinformation. Correspondingly, disinformation with a negative connotation from one’s affiliated political party is perceived by a lower percentage as accurate, contrary to disinformation with a negative connotation from the opposing political party, which is perceived by a higher percentage as accurate. The study also found that politically affiliated individuals are more prone to disinformation than those who are not politically affiliated. The results suggest that political affiliation plays a significant role in an individual’s vulnerability to disinformation. © 2023 by the author(s).",no
10.1080/23311983.2023.2224601,social media: a watchdog or a conspiracy breeder?: covid-19 disinformation among iraqi students,"The author seeks to determine the scale of conspiracy belief among undergraduate students and their dependency on social media to enhance their conspiracy theories. The first goal was to determine the extent to which conspiracy theories affect how undergraduates explain and understand crises and events. For example, theories about secret government cabals controlling Iraqi citizens’ lives and other issues. The second objective is to apply COVID-19 as a case to determine the extent of the conspiratorial interpretation of the sprea)d of the virus through exposure to misinformation through social media and how social media impacted it. The study was recruited from a snowball sample of students in two universities in Baghdad. Sample size 331 (230 males and 101 females) aged 19–24. They were surveyed through phone interviews. The study applied media dependency and conspiracy theories in survey research on a snowball sample in two major public universities in Baghdad. The survey shows undergraduate students depend on conspiracies from social media, especially Facebook. Moreover, the study finds that students believe in government malfeasance. In contrast, many students believe in multiple COVID-19 conspiracies, global government conspiracies, scientific conspiracies, extraterrestrial coverups, and government conspiracies meant to cause personal harm. Finally, there was no significant difference between males and females in dependence on media or scale of conspiracy belief. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",yes
10.1177/00187208231173263,"who gets caught in the web of lies?: understanding susceptibility to phishing emails, fake news headlines, and scam text messages","Objective: The present study investigated if the same users are vulnerable to phishing emails, scam text messages, and fake news headlines and if there are universal predictors of susceptibility for all three tasks. Background: Theoretical research provides support for the notion that the same users likely fall for multiple forms of online deception. However, no research has directly compared susceptibility for various online deceptions (eg phishing, disinformation, scam text messages) within the same group of users. Method: Participants completed an online survey consisting of demographic questions, the Cognitive Reflection Test (ie impulsivity), and the Digital Literacy Scale, and classified 90 legitimate and deceptive emails, text messages, and news headlines. Results: Results suggest that individuals who struggle to discriminate between deceptive and legitimate stimuli on one task experience similar difficulties on the other two tasks. Additionally, while lower levels of digital literacy and cognitive reflectiveness predicted poorer discrimination abilities across all three tasks, age did not predict performance. Interestingly, participants appeared to be the most susceptible to phishing emails. Conclusion: Overall, individuals who fall for one form of online deception appear to be more likely to fall for other forms of deception, and digital literacy and cognitive reflectiveness can predict widespread vulnerability to online deception. Application: Organizations may be able to identify potential vulnerabilities for a variety of online attacks by measuring digital literacy, cognitive reflectiveness, and performance in one online deception task. Additionally, training interventions may be the most needed for phishing emails. © 2023, Human Factors and Ergonomics Society.",yes
10.1080/03637751.2023.2202728,estimating the impact of immediate versus delayed corrections on belief accuracy,"Prior work has found that early corrections are often more effective than corrections encountered sometime after exposure to misinformation. However, these studies have generally considered only brief delays between misinformation exposure and correction, and do not explore processing style as a potential moderator of correction timing. We conducted a two-wave online experiment randomly assigning participants to receive corrections either shortly after exposure or approximately one week later. We find that both immediate and delayed corrections influenced belief accuracy and policy support, but immediate corrections were no more influential than delayed corrections, contrary to earlier findings. In addition, processing style had no moderating effect on the influence of correction timing. © 2023 National Communication Association.",no
10.1080/10410236.2023.2206177,what influences audience susceptibility to fake health news: an experimental study using a dual model of information processing in credibility assessment,"This experimental study investigates the effects of several heuristic cues and systematic factors on users’ misinformation susceptibility in the context of health news. Specifically, it examines whether author credentials, writing style, and verification check flagging influence participants’ intent to follow article behavioral recommendations provided by the article, perceived article credibility, and sharing intent. Findings suggest that users rely only on verification checks (passing/failing) in assessing information credibility. Of the two antecedents to systematic processing, social media self-efficacy moderates the links between verification and participants’ susceptibility. Theoretical and practical implications are discussed. © 2023 Taylor & Francis Group, LLC.",no
10.1080/10510974.2023.2219704,using message strategies to attenuate the effects of disinformation on credibility,"In the growth of online news, the industry faces increased threats on a polarized landscape, such as online-targeted disinformation, that threaten the legitimacy of news sources. This research contributes to the theoretical advancement of crisis communication and social psychology theories and provides guidance for professionals navigating emerging forms of paracrises. Results from this experimental design study reveal that during orchestrated disinformation campaigns, an astroturf paracrisis can damage the credibility of a targeted organization. Findings share how political ideology affects perceptions of news credibility during these campaigns and how combined proactive and reactive messaging can attenuate the effects of an astroturfer across the political spectrum. © 2023 Central States Communication Association.",no
10.1177/00332941231164073,state mindfulness and misinformation susceptibility,"Two experiments examined whether brief mindful meditation exercises and belief in task utility impacted memory in the misinformation paradigm. Participants watched a fictionalized crime video, received post-event misinformation about the video, and completed a cued recall memory test. They were randomly assigned to complete either a brief mindfulness exercise or unrelated task prior to encoding the video (E1) or prior to the final cued recall test (E2). Further, half of the participants in each group were informed that their assigned task was beneficial to memory performance. In Experiment 1, information about task benefits reduced misinformation reports on the final recall test, regardless of the task. The brief mindfulness exercise increased self-reported mindfulness scores in both experiments. While no group differences in memory were found, correlational analyses across the two experiments suggest that individuals who achieve more intense states of mindfulness may have lower susceptibility to misinformation and better event memory when meditation occurs prior to encoding. The results suggest that brief mindfulness exercises can reliably increase state experiences of mindfulness and have potential for use as experimental manipulations. However, the intensity of a self-guided mindfulness experience can vary across individuals, so it is important to consider individual differences when considering the application of the exercises. © The Author(s) 2023.",no
10.1007/s12144-023-04464-w,are accuracy discernment and sharing of covid-19 misinformation associated with older age and lower neurocognitive functioning?,"The online proliferation of COVID-19 misinformation led to adverse health and societal consequences. This study investigated possible differences in COVID-19 headline accuracy discernment and online sharing of COVID-19 misinformation between older and younger adults, as well as the role of individual differences in global cognition, health literacy and verbal IQ. Fifty-two younger (18–35 years old) and fifty older adults (age 50 and older) completed a neurocognitive battery, health literacy and numeracy measures, and self-report questionnaires via telephone. Participants also completed a social media headline-sharing experiment (Pennycook et al., Psychological science, 31(7), 770–780, 2020) in which they were presented with true and false COVID-19 headlines about which they indicated: 1) the likelihood that they would share the story on social media; and 2) the factual accuracy of the story. A repeated measures multivariate analysis of variance controlling for gender and race/ethnicity showed no effects of age (p =.099) but a significant interaction between actual COVID-19 headline accuracy and the likelihood of sharing (p <.001), such that accuracy was more strongly related to sharing false headlines (r = −.64) versus true headlines (r = −.43). Moreover, a higher likelihood of sharing false COVID-19 headlines was associated with lower verbal IQ and numeracy skills in older adults (rs = −.51--.40) and with lower verbal IQ, numeracy, and global cognition in younger adults (rs = −.66--.60). Findings indicate that headline accuracy judgements, numeracy, and verbal IQ are important contributors to sharing COVID-19 misinformation in both older and younger adults. Future work might examine the benefits of psychoeducation for improving health and science literacy for COVID-19. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",yes
10.37016/mr-2020-115,"explaining beliefs in electoral misinformation in the 2022 brazilian election: the role of ideology, political trust, social media, and messaging apps","The 2022 elections in Brazil have demonstrated that disinformation can have violent consequences, particularly when it comes from the top, raising concerns around democratic backsliding. This study leverages a two-wave survey to investigate individual-level predictors of holding electoral misinformation beliefs and the role of trust and information habits during the 2022 Brazilian elections. Our findings demonstrate that susceptibility to electoral misinformation is affected by factors such as political ideology, trust in the electoral process and democratic institutions, and information consumption, with those who participate in political groups in messaging apps being more likely to believe in electoral misinformation. © 2023, Harvard Kennedy School. All rights reserved.",no
10.1080/15213269.2023.2208363,"believing and sharing false news on social media: the role of news presentation, epistemic motives, and deliberative thinking","How vulnerable are we to misinformation on social media? To address this question, this study examines not only how well (or poorly) individuals discern true and false news on social media, but also how contextual factors in news presentation and individual’s cognitive and motivational tendencies might shape the patterns of their beliefs in and likelihood to engage online news. We conducted an online survey experiment on a sample of Chinese social media users recruited from a national panel (N = 481). The results show that, first, people generally perceived social media news as accurate and were better at correctly identifying truthful news than false news, revealing both a truth bias and a veracity effect. Second, social endorsement cue and news content slant could affect how individuals judge the veracity of a news post and engage it online. Third, evidence was mixed on how individuals’ deliberative thinking propensity and epistemic motive operated. While our primary goal is to present evidence from a non-Western society to shed lights on the psychology of false news on social media, we also strive toward teasing out some implications specific to the China context. © 2023 Taylor & Francis Group, LLC.",yes
10.1007/978-3-031-32225-9_17,inoculating adolescents against climate change misinformation,"In the “post-truth” era, where fake news is increasingly present and young people rely on social media as information sources, teaching students strategies to counter such online misinformation becomes pivotal. Inoculation theory has shown to be a promising vehicle to effectively neutralise the influence of misinformation on adults in various contexts. However, possible applications of inoculation theory for climate change education with young people have not been looked at yet. In this study, we investigated whether Austrian adolescents can be “inoculated” against misinformation targeted at the scientific consensus regarding climate change. In a quantitative randomised online survey experiment (N = 1066) based on the study of van der Linden et al. (Global Challenges 1(2):1600008, 2017), we demonstrated that adolescents are susceptible to presented misinformation targeted at the scientific consensus regarding climate change, even in the presence of accurate information. However, it is possible to pre-emptively protect adolescents against such misinformation through attitudinal inoculation. Furthermore, the inoculation treatment led to not only an increase in the adolescents’ consensus estimate but also their belief certainty in their estimate increased. We recommend future climate change education research to further elaborate possible applications of inoculation theory in climate change education or when teaching other supposedly socially controversial topics. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",no
10.1177/00027642231174334,this is clearly fake! mis- and disinformation beliefs and the (accurate) recognition of pseudo-information—evidence from the united states and the netherlands,"To understand how beliefs about mis- and disinformation affect citizens’ (correct) classification of pseudo-information, this paper relies on an experimental survey study in the United States and the Netherlands in which we (a) measured mis- and disinformation attitudes, (b) exposed participants to a real versus fake article on immigration and criminality, and (c) compared classifications of mis- and disinformation in response to the real and fake news article. The main findings indicate that the veracity of information did not play a clear role in the attribution of mis- and disinformation. People with stronger mis- and disinformation beliefs, and people with incongruent prior attitudes, were most likely to classify information as false irrespective of the level of untruthfulness. These findings imply that beliefs about misinformation play a key role in the classification of information as false, whereas these beliefs do not contribute to the accuracy of veracity judgments. © 2023 SAGE Publications.",yes
10.37016/mr-2020-114,how effective are tiktok misinformation debunking videos?,"TikTok provides opportunity for citizen-led debunking where users correct other users’ misinformation. In the present study (N=1,169), participants either watched and rated the credibility of (1) a misinformation video, (2) a correction video, or (3) a misinformation video followed by a correction video (“debunking”). Afterwards, participants rated both a factual and a misinformation video about the same topic and judged the accuracy of the claim furthered by the misinformation video. We found modest evidence for the effectiveness of debunking on people’s ability to subsequently discern between true and false videos, but stronger evidence on subsequent belief in the false claim itself. © 2023, Harvard Kennedy School. All rights reserved.",yes
10.1080/1461670X.2023.2187652,can fighting misinformation have a negative spillover effect? how warnings for the threat of misinformation can decrease general news credibility,"In the battle against misinformation, do negative spillover effects of communicative efforts intended to protect audiences from inaccurate information exist? Given the relatively limited prevalence of misinformation in people’s news diets, this study explores if the heightened salience of misinformation as a persistent societal threat can have an unintended spillover effect by decreasing the credibility of factually accurate news. Using an experimental design (N = 1305), we test whether credibility ratings of factually accurate news are subject to exposure to misinformation, corrective information, misinformation warnings, and news media literacy (NML) interventions relativizing the misinformation threat. Findings suggest that efforts like warning about the threat of misinformation can prime general distrust in authentic news, hinting toward a deception bias in the context of fear of misinformation being salient. Next, the successfulness of NML interventions is not straight forward if it comes to avoiding that the salience of misinformation distorts people’s creditability accuracy. We conclude that the threats of the misinformation order may not just be remedied by fighting false information, but also by reestablishing trust in legitimate news. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",yes
10.1080/20445911.2023.2241699,the influence of involvement and emotional valence on accuracy judgments and sharing intention of fake news,"Recent studies proposed that emotional valence of news affected individuals’ beliefs in fake news. However, the results across various studies remain controversial. Involvement probably have an influence on beliefs in fake news. To understand whether involvement modulates the role of different valences of fake news, we designed two experiments. Both Experiment 1 and Experiment 2 were 2 (valence: positive, negative) *2 (involvement: high, low) within-subject designs. The results of Experiment 1 revealed that the interaction between involvement and emotional valence on accuracy judgment was significant. The results indicated that the role of emotional valence in the accuracy judgment of fake news was affected by involvement, which provided evidence to explain the contradictory results for the role of valence on fake news beliefs. Experiment 2 found the main effect of involvement and emotional valence on sharing intention, indicating that the sharing intention of fake news was regulated by involvement and emotional valence respectively. © 2023 Informa UK Limited, trading as Taylor & Francis Group.",no
10.1080/03623319.2020.1728508,"partisan online media use, political misinformation, and attitudes toward partisan issues","The purpose of this study is to investigate whether or to what extent partisan online media use is positively associated with people’s obtaining partisan misinformation and forming partisanship-consistent attitudes toward political issues. This study examines whether people are more likely to obtain attitude-consistent misinformation that undercuts their partisan beliefs. Also examined is the role that misinformation plays in the relationship between partisan online media use and attitudes towards partisan issues. A nation-wide online survey of 1,032 respondents in South Korea showed that people were more likely to accept misinformation if it was supportive of their partisanship. Findings further suggest that political misinformation mediated the relationship between partisan online media use and attitudes toward partisan issues. Partisan online media use appears to guide people in their learning party-consistent misinformation that leads them to have greater partisanship-consistent attitudes toward political issues. © 2020 Western Social Science Association.",no
10.1093/joc/jqac023,"what should i believe? a conjoint analysis of the influence of message characteristics on belief in, perceived credibility of, and intent to share political posts","Research on misinformation and misperceptions often investigates claims that have already reached a critical mass, resulting in little understanding of why certain claims gain widespread belief while others fall into obscurity. Here we consider how various message features factor into why certain claims are more likely to be believed, perceived as credible, and shared with others. Using a conjoint experiment, we randomly assigned participants (N = 1,489) to receive an experimentally manipulated message describing an allegation of political misconduct. Results suggest that partisan cues play a significant role in influencing both belief and perceived credibility. Furthermore, message specificity, language intensity, and whether other users' comments on the post refute or endorse the post also influenced belief judgment and credibility assessments. We conclude with a discussion of the theoretical and practical importance of these findings for understanding and combating the threat of misinformation.  © 2022 The Author(s).",no
10.1177/19401612211031457,"knowledge and the news: an investigation of the relation between news use, news avoidance, and the presence of (mis)beliefs","While increasing scholarly attention has been devoted to news avoidance, there are only few studies taking the distinction between intentional and unintentional news avoidance into consideration, and none that has investigated the linkage between the two types of news avoidance and knowledge about politics and society. To fill this void, this study explores this relationship while distinguishing between knowledge related to uncontested issues and knowledge related to issues that have been subject to public controversies (climate change, vaccination, genetically modified organisms, crime, and immigration). Relying on a large-scale survey among Swedish citizens conducted in 2020 (N = 2,160), we find that the relationship with patterns of news use is substantially different across these types of beliefs. Among other things, the results suggest that knowledge of uncontested issue domains is positively related to news use, but knowledge of contested issue domains is not. The intentional avoidance of news is only negatively related to knowledge of contested issues. Taken together, the results suggest that the mechanisms driving beliefs related to uncontested versus contested issues are substantially different. © The Author(s) 2021.",yes
10.1177/09717218211003413,"anti-science misinformation and conspiracies: covid–19, post-truth, and science & technology studies (sts)","COVID–19 has not only resulted in nearly two and a half million deaths globally but it has also spawned a pandemic of misinformation and conspiracies. In this article I examine COVID–19 misinformation and conspiracies in the United States (US). These misinformation and conspiracies have been commonly argued to be anti-science. I argue, although it is important to rebut false information and stop their spread, social scientists need to analyse how such anti-science claims are discursively framed and interpreted. Specifically, I show how the framing of the anti-science conspiracies utilise the credibility of science and scientists. I also explore how the COVID–19 misinformation and conspiracies were given different meaning among different social groups. The article is divided into three sections. In the first section I analyse the discursive emplotment of the Plandemic video that had Dr Judy Mikovits presenting several COVID–19 conspiracy theories and went viral before it was taken down from major social media platforms. I show how the video draws on the credibility of science, scientists, and scientific journals to present misinformation and conspiracies claims against vaccination, mask wearing, etc. The second section explores how COVID–19 misinformation and conspiracies were interpreted among the African-American community by drawing on the history of black community’s experiences in the US and as such how their interpretations stand in contrast to the interpretations of the COVID–19 misinformation and conspiracies among the White community. The last section analyses the role of STS in engaging with anti-science and post-truth issues and emphasises the need to excavate genealogies of the present even with regard to misinformation and conspiracies. © 2022 SAGE Publications.",no
10.1111/1468-5922.12807,observations on psychic vulnerability to media dissemination of false political-ideological messages (fake news),"The author seeks to understand the functioning of the dissemination of false messages (fake news) and its impact on the individual and collective psyche from the perspective of contemporary analytical psychology. The paper considers the current Zeitgeist along with the cultural factors that created the propitious ground for increasing media dissemination from the 1990s onwards. The growing influence of analytical psychology within the sociohistorical approach is valued. The author notes the vulnerability of the individual and collective consciousness to fake news and its insertion into competent and credible conspiracy theories. Despite, on the one hand, the formal efforts of websites, digital platforms and other digital distribution agents to verify and control this dysfunctional communication and, on the other hand, the search for psychological defence measures, there still seems to be no solution in sight. © 2022 The Society of Analytical Psychology.",no
10.1093/poq/nfac034,factual corrections eliminate false beliefs about covid-19 vaccines,"The spread of misinformation about COVID-19 vaccines threatens to prolong the pandemic, with prior evidence indicating that exposure to misinformation has negative effects on intent to be vaccinated. We describe results from randomized experiments in the United States (n = 5,075) that allow us to measure the effects of factual corrections on false beliefs about the vaccine and vaccination intent. Our evidence makes clear that corrections eliminate the effects of misinformation on beliefs about the vaccine, but that neither misinformation nor corrections affect vaccination intention. These effects are robust to formatting changes in the presentation of the corrections. Indeed, corrections without any formatting modifications whatsoever prove effective at reducing false beliefs, with formatting variations playing a very minor role. Despite the politicization of the pandemic, misperceptions about COVID-19 vaccines can be consistently rebutted across party lines.  © 2022 The Author(s).",no
10.1017/S0007123420000198,political knowledge and misinformation in the era of social media: evidence from the 2015 uk election,"Does social media educate voters, or mislead them? This study measures changes in political knowledge among a panel of voters surveyed during the 2015 UK general election campaign while monitoring the political information to which they were exposed on the Twitter social media platform. The study's panel design permits identification of the effect of information exposure on changes in political knowledge. Twitter use led to higher levels of knowledge about politics and public affairs, as information from news media improved knowledge of politically relevant facts, and messages sent by political parties increased knowledge of party platforms. But in a troubling demonstration of campaigns' ability to manipulate knowledge, messages from the parties also shifted voters' assessments of the economy and immigration in directions favorable to the parties' platforms, leaving some voters with beliefs further from the truth at the end of the campaign than they were at its beginning. Copyright © The Author(s), 2020. Published by Cambridge University Press.",no
10.37016/mr-2020-102,audio misinformation on whatsapp: a case study from lebanon,"Since 2019, Lebanon has witnessed sequential crises that have routinely spurred media attention. A great deal of misinformation has proliferated during these events, much of it spreading on WhatsApp. One format is particularly understudied: audio instant messages, otherwise known as voice notes. Utilizing a grounded theory approach to examine 35 misleading WhatsApp voice notes collected between October 2019 and October 2020, this study documents how audio misinformation on Lebanese WhatsApp follows a consistent structure through the manipulation of interpersonal relationships, the establishing of source credibility, the imbuing of negative discrete emotions, and the inclusion of calls to action. © 2022, Harvard Kennedy School. All rights reserved.",no
10.1080/09658211.2021.1917618,resisting misinformation via discrepancy detection: effects of an unaware suspicion cue,"Previous studies have shown that contaminating effects of misinformation can be reduced by consciously raising the awareness of eyewitnesses to the discrepancy between the misinformation and the original information (e.g., Tousignant, J. P., Hall, D., & Loftus, E. F. [1986]. Discrepancy detection and vulnerability misleading postevent information. Memory & Cognition, 14(4), 329–338. doi:10.3758/BF03202511). We tested whether similar effects could be obtained without conscious awareness, by drawing on the metaphor “something smells fishy” linking fishy smells and suspicion (Lee, S. W. S., & Schwarz, N. [2012]. Bidirectionality, mediation, and moderation of metaphorical effects: The embodiment of social suspicion and fishy smells. Journal of Personality and Social Psychology, 103(5), 737–749. doi:10.1037/a0029708). In a pilot study, we established the replicability and generality of previous findings concerning this metaphorical link. We then examined the effects of the smell-suspicion link on susceptibility to misleading post-event information using the misinformation paradigm. Here, the “something smells fishy” metaphor was used to invoke suspicion and increase discrepancy detection. Forty-eight hours after viewing an event, participants received misinformation in a room sprayed with either a fishy or a neutral smell. As expected, unaware exposure to the fishy smell (compared to the neutral smell) increased discrepancy detection (measured indirectly) and resistance to the contaminating effects of misinformation, eliminating misinformation interference and lowering suggestibility on the final test. © 2021 Informa UK Limited, trading as Taylor & Francis Group.",no
10.1002/9781119743347.ch4,do you believe in fake after all? whatsapp disinformation campaign during the brazilian 2018 presidential election,"The flow of persuasive disinformation depends not only on the technology and its social uses, but also on the media and information ecosystem and the environmental conditions for social influence. The Brazilian media landscape shows a high concentration of audience and property, lack of transparency, and economic, political and religious interference. This chapter aims to identify features and patterns in the content shared that reveal narratives developed by the Bolsonaro campaign to win the Brazilian presidential election. In Brazil and in India, WhatsApp groups were used to bypass mainstream media and speak directly to citizens, spreading disinformation and polarizing voters along moral and religious lines. The difficulties in debunking disinformation campaigns and determining content credibility, especially for users, can have detrimental effects on democracy. The chapter considers that WhatsApp's affordances create the socio-technical conditions for audience fragmentation and microtargeting strategy. © 2021 John Wiley & Sons, Inc.",no
10.1177/1532673X211041570,reliable sources? correcting misinformation in polarized media environments,"Providing corrective information can reduce factual misperceptions among the public but it tends to have little effect on people’s underlying attitudes. Our study examines how the impact of misinformation corrections is moderated by media choice. In our experiment, participants are asked to read a news article published by Fox News or MSNBC, each highlighting the positive economic impact of legal immigration in the United States. While the news content is held constant, our treatment manipulates whether participants are allowed to freely choose a media outlet or are randomly assigned. Our results demonstrate the importance of people’s ability to choose: While factual misperceptions are easily corrected regardless of how people gained access to information, subsequent opinion change is conditional on people’s prior willingness to seek out alternative sources. As such, encouraging people to broaden their media diet may be more effective to combat misinformation than disseminating fact-checks alone. © The Author(s) 2021.",yes
10.1002/acp.3823,correcting the unknown: negated corrections may increase belief in misinformation,"Corrections are not always effective at reducing belief in misinformation. Negated corrections, which state a piece of information is not true, may only be effective at inhibiting information an observer has already encountered. We compared the effectiveness of negated corrections and replacements while manipulating initial exposure to a target concept. Subjects read one (Experiment 1) or six (Experiment 2) passages presenting a target concept (e.g., blue car) or not, followed by a negated correction (e.g., not blue), replacement (e.g., red), or no correction, then answered open-ended questions which were scored for mentions of the target concept. When subjects were exposed to the target concept, negated corrections reduced mentions of the misinformation relative to no correction; however, when not exposed to the concept, negated corrections increased mentions relative to no correction. These results demonstrate that negated corrections can increase belief in misinformation when observers have not been exposed to the misinformation. © 2021 The Authors. Applied Cognitive Psychology published by John Wiley & Sons Ltd.",no
10.1093/oso/9780198863977.003.0006,enquiry and normative deviance: the role of fake news in science denialism,"It is argued that science denialism brings about an aberrant form of enquiry that deviates in significant ways from the epistemic norms governing scientific enquiry. Science denialism doesn’t involve just a rejection of a scientific theory; it also challenges the practice of continuously and impartially testing research methods, theories, and evidential sources with the aim of improving the accuracy of our theories. This chapter provides an in-depth analysis of the epistemic mechanisms at work. It develops a fine-grained framework to model a variety of normative deviances that may take place in enquiry. Through analysing two case studies, it is argued that fake news plays two pivotal roles in shaping epistemic norms operating within science denialism. First, it discredits a variety of (institutional) sources of evidence; second, it also plays a part in building the alternative explanation of the target phenomena. © Oxford University Press 2021.",no
10.1007/s11109-021-09701-1,"the (null) effects of happiness on affective polarization, conspiracy endorsement, and deep fake recognition: evidence from five survey experiments in three countries","Affective polarization is a key concern in America and other democracies. Although past evidence suggests some ways to minimize it, there are no easily applicable interventions that have been found to work in the increasingly polarized climate. This project examines whether irrelevant factors, or incidental happiness more specifically, have the power to reduce affective polarization (i.e., misattribution of affect or “carryover effect”). On the flip side, happiness can minimize systematic processing, thus enhancing beliefs in conspiracy theories and impeding individual ability to recognize deep fakes. Three preregistered survey experiments in the US, Poland, and the Netherlands (total N = 3611) induced happiness in three distinct ways. Happiness had no effects on affective polarization toward political outgroups and hostility toward various divisive social groups, and also on endorsement of conspiracy theories and beliefs that a deep fake was real. Two additional studies in the US and Poland (total N = 2220), also induced anger and anxiety, confirming that all these incidental emotions had null effects. These findings, which emerged uniformly in three different countries, among different partisan and ideological groups, and for those for whom the inductions were differently effective, underscore the stability of outgroup attitudes in contemporary America and other countries. © 2021, The Author(s).",no
10.1177/1532673X211022639,"republicans, not democrats, are more likely to endorse anti-vaccine misinformation","Vaccine safety skeptics are often thought to be more likely to self-identify as Democrats (vs. Independents or Republicans). Recent studies, however, suggest that childhood vaccine misinformation is either more common among Republicans, or is uninfluenced by partisan identification (PID). Uncertainty about the partisan underpinnings of vaccine misinformation acceptance is important, as it could complicate efforts to pursue pro-vaccine health policies. I theorize that Republicans should be more likely to endorse anti-vaccine misinformation, as they tend to express more-negative views toward scientific experts. Across six demographically and nationally representative surveys, I find that—while few Americans think that “anti-vaxxers” are more likely to be Republicans than Democrats—Republican PID is significantly associated with the belief that childhood vaccines can cause autism. Consistent with theoretical expectations, effect is strongly mediated by anti-expert attitudes—an effect which supplemental panel analyses suggest is unlikely to be reverse causal. © The Author(s) 2021.",no
10.3389/fcomm.2021.613794,"misconceptions, misinformation and politics of covid-19 on social media: a multi-level analysis in ghana","Background: Ghana developed an Emergency Preparedness and Response Plan (EPRP) in response to the Severe Acute Respiratory Syndrome Coronavirus (SARS CoV-2) pandemic. A key strategy in the EPRP is to mobilize national resources and put in place strategies for improved risk and behavioral change communication. Nonetheless, concerns have been raised on social media about COVID-19 misinformation and misconceptions. This study used social media content to determine the types, forms and the effects of the myths, misconceptions and misinformation in Ghana's COVID-19 containment. Method: The study was conducted in three phases involving the use of both primary and secondary data. Review of social media information on COVID-19 was done. This was complemented with document review and interviews with key stakeholders with expertise in the management of public health emergencies and mass communication experts (N = 18). All interviews were transcribed verbatim and analyzed using NVivo 12. Results: The study showed a changing pattern in the misconceptions and misinformation about COVID-19. Initially myths were largely on causes and vulnerability. It was widely speculated that black people had some immunity against COVID-19. Also, the condition was perceived to cause severe disease among the elderly. These misconceptions served as risk attenuators among Ghanaians, especially the younger generation. As the infection evolved in the country, another misconception emerged that the hot climate in Africa inhibited viral replication and transmission only to be followed by speculations and conjectures that COVID-19 was being used as a biological weapon to target developed economics. For the management of COVID-19, the use of local remedies such as Neem tree (Azadirachta indica) and herbal preparation also emerged. Myths about the efficacy of locally manufactured gin (akpeteshie) and hydroxychloroquine as prophylaxis led to abuse of such substances. Interview segments revealed the use of myths to propagate political agenda in the country. Conclusion: The study concludes that COVID-19 misconceptions and misinformation are widespread and cover the course of the condition. These myths necessitate culturally sensitive health communication strategies that take into account local perceptions of COVID-19 in order to tackle the circulation of misconceived messages about the pandemic in Ghana. © Tabong and Segtub.",no
10.30658/jicrcr.4.3.4,misinformation and government crisis management in south korea: understanding active publics’ belief in misinformation about the yemeni refugee issue and its effect on active communication behaviors,"This study aims to investigate how situationally motivated publics respond to misinformation in the context of the Yemeni refugee issue in South Korea. In particular, this study examined how situational motivation in problem-solving on the issue is associated with belief in misinformation and active communication behaviors in the framework of situation theory of problem-solving (STOPS). The results of this study showed that individuals with a high level of situational motivation are more likely to believe misinformation on a given issue. In addition, the result found that belief in misinformation mediates between situational motivation in problem-solving and information forwarding. The results of this study contribute to government crisis management dealing with refugee issues. Copyright 2021 Authors. Published under a Creative Commons Attribution.",no
10.1371/journal.pone.0243024,"myths, beliefs, and perceptions about covid-19 in ethiopia: a need to address information gaps and enable combating efforts","Background The endeavor to tackle the spread of COVID-19 effectively remains futile without the right grasp of perceptions and beliefs presiding in the community. Therefore, this study aimed to assess myths, beliefs, perceptions, and information gaps about COVID-19 in Ethiopia. Methods An internet-based survey was conducted in Ethiopia from April 22 to May 04, 2020. The survey link was promoted through emails, social media, and the Jimma University website. Perceptions about COVID-19 have considered the World Health Organization (WHO) resources and local beliefs. The data were analyzed using Statistical Package for Social Science (SPSS) software version 20.0. Classifications and lists of factors for each thematic perception of facilitators, inhibitors, and information needs were generated. Explanatory factor analysis (EFA) was executed to assist categorizations. Standardized mean scores of the categories were compared using analysis of variance (ANOVA) and t-tests. A significant difference was claimed at p-value <0.05. Results A total of 929 responses were gathered during the study period. The EFA generated two main categories of perceived facilitators of COVID-19 spread: behavioral non-adherence (55.9%) and lack of enablers (86.5%). Behavioral non-adherence was illustrated by fear of stigma (62.9%), not seeking care (59.3%), and hugging and shaking (44.8%). Perceived lack of enablers of precautionary measures includes staying home impossible due to economic challenges (92.4%), overcrowding (87.6%), and inaccessible face masks (81.6%) and hand sanitizers (79.1%). Perceived inhibitors were categorized into three factors: two misperceived, myths (31.6%) and false assurances (32.9%), and one correctly identified; engagement in standard precautions (17.1%). Myths about protection from the virus involve perceived religiosity and effectiveness of selected food items, hot weather, traditional medicine, and alcohol drinking, ranging from 15.1% to 54.7%. False assurances include people’s perception that they were living far away from areas where COVID-19 was rampant (36.9%), and no locally reported cases were present (29.5%). There were tremendous information needs reported about COVID-19 concerning protection methods (62.6%), illness behavior and treatment (59.5%), and quality information, including responses to key unanswered questions such as the origin of the virus (2.4%). Health workers were perceived as the most at-risk group (83.3%). The children, adolescents, youths were marked at low to moderate (45.1%-62.2%) risk of COVID-19. Regional, township, and access to communication showed significant variations in myths, false assurances, and information needs (p <0.05). Conclusions Considering young population as being at low risk of COVID-19 would be challenging to the control efforts, and needs special attention. Risk communication and community engagement efforts should consider regional and township variations of myths and false assurances. It should also need to satisfy information needs, design local initiatives that enhance community ownership of the control of the virus, and thereby support engagement in standard precautionary measures. All forms of media should be properly used and regulated to disseminate credible information while filtering out myths and falsehoods. © 2020 Kebede et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",no
10.4018/978-1-7998-7291-7.ch031,news credibility and media literacy in the digital age,"With the hostile media phenomenon as an overarching framework, this chapter discusses how challenging it can be for media literacy education to successfully combat motivated reasoning in which individuals are likely to be hostile when exposed to news content that is incongruent with their personal point of view. Such discussion is vital in times when news audiences are cynical and skeptical towards both politicians and media agencies. Given the importance of understanding and studying individuals' perceptions of news biases and assessments of news credibility, this chapter makes a case for establishing more objective standards for journalistic work to overcome the challenges brought about by the rise of fake news in the digital era. © 2021, IGI Global.",no
10.4018/978-1-7998-7291-7.ch002,"""ridiculous and untrue - fake news!"": the impact of labeling fake news","Beyond the spread of fake news, the term ""fake news"" has been used by people on social media and by people in the Trump administration to discredit reporting and show disagreement with the content of a story. This study offers a series of defining traits of fake news and a corresponding experiment testing its impact. Overall, this study shows that fake news, or at least labeling fake news can impact the gratifications people derive from news. Further, this study provides evidence that the impact of fake news might, in some cases, rely on whether or not the fake news complies with preexisting beliefs. © 2021, IGI Global.",no
10.3390/soc10030071,testing children and adolescents’ ability to identify fake news: a combined design of quasi-experiment and group discussions,"Nowadays, people increasingly choose to turn to the Internet and especially to social media for news and other types of content, while often not questioning the trustworthiness of the information. An acute form of this problem is that children and adolescents tend to include the use of new technologies in all the aspects of their daily life, yet most of them are unable to distinguish between fake news and trustful information in an online environment. This study is based on a Dutch empirical study and was conducted in Romania to examine whether schoolchildren and adolescents were able to identify a hoax website as fake, using a self-administrative questionnaire and open group discussions about the given online source. Similar to other studies based on the same research design, this research aims to explore the vulnerability of students to fake news and the way they experience an experimental situation in which they are exposed to online fake information. This exploratory study revealed that both children and adolescents are not preoccupied with the trustworthiness of the information they are exposed to in social media. While only 4 of the 54 students stated that they would not choose to save a fake animal (from a hoax website), all four of them had reasons that proved that they did not perceive the information as being a hoax. Thus, participants proved that they would act upon being exposed to fake information even when they do not trust the source. © 2020 by the author. Licensee MDPI, Basel, Switzerland.",no
10.37016/mr-2020-55,"right and left, partisanship predicts (asymmetric) vulnerability to misinformation","We analyze the relationship between partisanship, echo chambers, and vulnerability to online misinformation by studying news sharing behavior on Twitter. While our results confirm prior findings that online misinformation sharing is strongly correlated with right-leaning partisanship, we also uncover a similar, though weaker, trend among left-leaning users. Because of the correlation between a user’s partisanship and their position within a partisan echo chamber, these types of influence are confounded. To disentangle their effects, we performed a regression analysis and found that vulnerability to misinformation is most strongly influenced by partisanship for both left-and right-leaning users. © 2020, Harvard Kennedy School. All rights reserved.",no
10.1080/10410236.2019.1573295,seeking formula for misinformation treatment in public health crises: the effects of corrective information type and source,"An increasing lack of information truthfulness has become a fundamental challenge to communications. Insights into how to debunk this type of misinformation can especially be crucial for public health crises. To identify corrective information strategies that increase awareness and trigger actions during infectious disease outbreaks, an online experiment (N = 700) was conducted, using a U.S. sample. After initial misinformation exposure, participants’ exposure to corrective information type (simple rebuttal vs. factual elaboration) and source (government health agency vs. news media vs. social peer) was varied, including a control group without corrective information. Results show that, if corrective information is present rather than absent, incorrect beliefs based on misinformation are debunked and the exposure to factual elaboration, compared to simple rebuttal, stimulates intentions to take protective actions. Moreover, government agency and news media sources are found to be more successful in improving belief accuracy compared to social peers. The observed mediating role of crisis emotions reveals the mechanism underlying the effects of corrective information. The findings contribute to misinformation research by providing a formula for correcting the increasing spread of misinformation in times of crisis. © 2019, © 2019 The Author(s). Published with license by Taylor & Francis Group, LLC.",no
10.20473/rlj.V6-I2.2020.136-145,university students' ability in evaluating fake news on social media,"Background of the study: Social media has become a traffic information exchange for both true and false information. Therefore, social media users should not simply believe the information they received. This paper investigates the process of evaluating news on social media carried out by students in assessing the news they find on social media, and their ability to distinguish fact and false news. Purpose: It is to find out more about the process of students evaluating news on social media by assessing the news they found on social media, and how can they know which is the factual news and which is the fake news and the difference between them. Method: Qualitative research methods with a descriptive approach are used in this research. This research was conducted at Gadjah Mada University. The purposive sampling technique was chosen to be used in determining students. Findings: Overall, participants were able to identify almost all news articles. Participants are able to identify almost all factual news articles correctly and most fake news articles correctly. Only a small portion of all news articles cannot be correctly identified by participants. Participants are better to identify factual news than fake news. Conclusion: Although participants already have experienced finding fake news on social media and have self-taught knowledge about how to distinguish fake news from reliable news, there is no guarantee that they can tell the news article they got, fake or fact. The researcher wants to give advice to the academic library to provide training on the characteristics of reliable referral sources and to think critically in assessing information as part of student information literacy training. © 2020, Airlangga University Faculty of Vocational Studies. All rights reserved.",yes
10.1027/1618-3169/a000489,anger increases susceptibility to misinformation,"The effect of anger on acceptance of false details was examined using a three-phase misinformation paradigm. Participants viewed an event, were presented with schema-consistent and schema-irrelevant misinformation about it, and were given a surprise source monitoring test to examine the acceptance of the suggested material. Between each phase of the experiment, they performed a task that either induced anger or maintained a neutral mood. Participants showed greater susceptibility to schema-consistent than schema-irrelevant misinformation. Anger did not affect either recognition or source accuracy for true details about the initial event, but suggestibility for false details increased with anger. In spite of this increase in source errors (i.e., misinformation acceptance), both confidence in the accuracy of source attributions and decision speed for incorrect judgments also increased with anger. Implications are discussed with respect to both the general effects of anger and real-world applications such as eyewitness memory. © 2020 Hogrefe Publishing.",no
10.1016/j.jarmac.2020.04.001,correcting misinformation in news stories: an investigation of correction timing and correction durability,"Early reports of an unfolding news story sometimes contain incomplete or mistaken information that is later updated or corrected. Research shows that retracted information continues to influence beliefs and inferential reasoning in sometimes subtle ways. The present study sought to assess how the efficacy of corrections interacts with the passage of time. We assessed whether delaying a correction by 2 days, relative to providing the correction minutes after the mistaken information, influenced the efficacy of the correction. In the same experiments, we also assessed whether corrections lead to durable changes in belief, by assessing belief in the corrected information in the same individuals at several points in time. Although we found no evidence that correction timing mattered, we found clear evidence that corrected beliefs were not durable. In three experiments, belief in the mistaken information increased over the 2 days following a correction despite participants’ continued memory for the correction. © 2020 Society for Applied Research in Memory and Cognition",no
10.37016/mr-2020-026,do the right thing: tone may not affect correction of misinformation on social media,"An experiment conducted with 610 participants suggests that corrections to misinformation – pointing out information that is wrong or misleading and offering credible information in its place – on social media reduce misperceptions regardless of the correction’s tone (uncivil, affirmational, or neutral). There is also an opportunity to correct secondary but related misperceptions (dealing with the same topic but with a different specific fact) when responding to misinformation on social media. Our findings emphasize that correction on social media could operate as part of a broader strategy to reduce beliefs in misinformation, and users should be encouraged to bring additional relevant information into the conversation, using whatever tone feels most comfortable for them. © 2020, Harvard Kennedy School. All rights reserved.",no
10.37016/mr-2020-033,exposure to social engagement metrics increases vulnerability to misinformation,"News feeds in virtually all social media platforms include engagement metrics, such as the number of times each post is liked and shared. We find that exposure to these signals increases the vulnerability of users to low-credibility information in a simulated social media feed. This finding has important implications for the design of social media interactions in the post-truth age. To reduce the spread of misinformation, we call for technology platforms to rethink the display of social engagement metrics. Further research is needed to investigate how engagement metrics can be presented without amplifying the spread of low-credibility information. © 2020, Harvard Kennedy School. All rights reserved.",no
10.4018/978-1-7998-4718-2.ch004,detecting fake news on social media: the case of turkey,"As Web 2.0 technologies have turned the Internet into an interactive medium, users dominate the field. With the spread of social media, the Internet has become much more user-oriented. In contrast to traditional media, social media's lack of control mechanisms makes the accuracy of spreading news questionable. This brings us to the significance of fact-checking platforms. This study investigates the antecedents of spreading false news in Turkey. The purpose of the study is to determine the features of fake news. For this purpose, teyit.org, the biggest fact-checking platform in Turkey, has been chosen for analysis. The current study shows fake news to be detectable based on four features: Propagation, User Type, Social Media Type, and Formatting. According to the logistic regression analysis, the study's model obtained 86.7% accuracy. The study demonstrates that Facebook increases the likelihood of news being fake compared to Twitter or Instagram. Emoji usage is also statistically significant in terms of increasing the probability of fake news. Unexpectedly, the impact of photos or videos was found statistically insignificant. © 2021 by IGI Global. All rights reserved.",no
10.37016/mr-2020-47,breaking harmony square: a game that “inoculates” against political misinformation,"We present Harmony Square, a short, free-to-play online game in which players learn how political misinformation is produced and spread. We find that the game confers psychological resistance against manipulation techniques commonly used in political misinformation: players from around the world find social media content making use of these techniques significantly less reliable after playing, are more confident in their ability to spot such content, and less likely to report sharing it with others in their network. © 2020, Harvard Kennedy School. All rights reserved.",yes
10.17645/mac.v8i2.3219,spreading (dis)trust: covid-19 misinformation and government intervention in italy,"The commentary focuses on the spread of Covid-19 misinformation in Italy, highlighting the dynamics that have impacted on its pandemic communication. Italy has recently been affected by a progressive erosion of trust in public institutions and a general state of information crisis regarding matters of health and science. In this context, the politicization of health issues and a growing use of social media to confront the Coronavirus “infodemic” have led the Italian Ministry of Health to play a strategic role in using its official Facebook page to mitigate the spread of misinformation and to offer updates to online publics. Despite this prompt intervention, which increased the visibility and reliability of public health communication, coordinated efforts involving different institutions, media and digital platform companies still seem necessary to reduce the impact of misinformation, as using a multichannel strategy helps avoid increasing social and technological disparities at a time of crisis. © 2020 by the author; licensee Cogitatio (Lisbon, Portugal).",yes
10.5771/2192-4007-2019-4-523,susceptibility to mis- and disinformation and the effectiveness of fact-checkers: can misinformation be effectively combated?; [anfälligkeit für fehl- und desinformationen und die effektivität von faktenprüfern: können fehlinformationen wirksam bekämpft werden?],"The online dissemination of mis- and disinformation may pose vexing problems on democracy. The factual basis of (political) information may be challenged by opposed partisans or issue publics, and misinformation may impact decision-making as confirmation biases may outweigh accuracy motivations. In this setting, fact-checkers that refute the false claims of misinformation may be regarded as an important tool to combat misinformation. Yet, the effectiveness of corrective information may be contingent upon partisan lenses, or the framing used in misinformation. In this study, the effectiveness of fact-checkers that refute different forms of misinformation on the polarizing issue of crime rates related to anti-immigration framing was assessed in the US and Netherlands. The main findings indicate that exposure to fact-checkers can correct misperceptions on immigration, and lowers the credibility of misinformation. Fact-checkers are more effective in the Netherlands than the US. These findings have important ramifications for understanding citizens' susceptibility to (partisan) misinformation and rebuttals. © 2019 Institute of the Lithuanian Language. All Rights Reserved.",no
10.4018/978-1-5225-9261-7.ch009,news credibility and media literacy in the digital age,"With the hostile media phenomenon as an overarching framework, this chapter discusses how challenging it can be for media literacy education to successfully combat motivated reasoning in which individuals are likely to be hostile when exposed to news content that is incongruent with their personal point of view. Such discussion is vital in times when news audiences are cynical and skeptical towards both politicians and media agencies. Given the importance of understanding and studying individuals' perceptions of news biases and assessments of news credibility, this chapter makes a case for establishing more objective standards for journalistic work to overcome the challenges brought about by the rise of fake news in the digital era. © 2019, IGI Global.",no
10.1177/2053168019870351,counting the pinocchios: the effect of summary fact-checking data on perceived accuracy and favorability of politicians,"Can the media effectively hold politicians accountable for making false claims? Journalistic fact-checking assesses the accuracy of individual public statements by public officials, but less is known about whether this process effectively imposes reputational costs on misinformation-prone politicians who repeatedly make false claims. This study therefore explores the effects of exposure to summaries of fact-check ratings, a new format that presents a more comprehensive assessment of politician statement accuracy over time. Across three survey experiments, we compared the effects of negative individual statement ratings and summary fact-checking data on favorability and perceived statement accuracy of two prominent elected officials. As predicted, summary fact-checking had a greater effect on politician perceptions than individual fact-checking. Notably, we did not observe the expected pattern of motivated reasoning: co-partisans were not consistently more resistant than supporters of the opposition party. Our findings suggest that summary fact-checking is particularly effective at holding politicians accountable for misstatements. © The Author(s) 2019.",no
10.1098/rsos.180593,does truth matter to voters? the effects of correcting political misinformation in an australian sample,"In the 'post-truth era', political fact-checking has become an issue of considerable significance. A recent study in the context of the 2016 US election found that fact-checks of statements by Donald Trump changed participants' beliefs about those statements-regardless of whether participants supported Trump-but not their feelings towards Trump or voting intentions. However, the study balanced corrections of inaccurate statements with an equal number of affirmations of accurate statements. Therefore, the null effect of fact-checks on participants' voting intentions and feelings may have arisen because of this artificially created balance. Moreover, Trump's statements were not contrasted with statements from an opposing politician, and Trump's perceived veracity was not measured. The present study (N = 370) examined the issue further, manipulating the ratio of corrections to affirmations, and using Australian politicians (and Australian participants) from both sides of the political spectrum. We hypothesized that fact-checks would correct beliefs and that fact-checks would affect voters' support (i.e. voting intentions, feelings and perceptions of veracity), but only when corrections outnumbered affirmations. Both hypotheses were supported, suggesting that a politician's veracity does sometimes matter to voters. The effects of fact-checking were similar on both sides of the political spectrum, suggesting little motivated reasoning in the processing of fact-checks. © 2018 The Author(s) Published by the Royal Society.",no
10.5964/ejop.v7i3.147,role of arousal states in susceptibility to accept misinformation,"The fragile nature of eyewitness memory makes the witnesses susceptible to various sources of post event information. Many factors of individual differences further moderate the impact of misinformation. The experiment reported here attempts to explore the effects of post event information on recognition accuracy of witnessed events, as moderated by the arousal states of energetic arousal, tense arousal, hedonic tone and anger/frustration. Experiment used those participants who scored high on four arousal states and average on rest of the three arousal states. Participants viewed a video clip, depicting a murder, followed by presentation of one week delayed post event information and recognition test for details of the event. Results indicated that participants who were misled retained less number of details of the event than did the participants who were given either consistent or no post event information. High scorer energetic arousal and hedonic tone participants retained more details of the event than did the high scorer tense arousal and anger/frustration participants under all the three post event information conditions. However, high tense arousal and anger/frustration participants' eyewitness retention dropped more sharply when they were given misleading post event information in comparison to the high energetic arousal and hedonic tone participants. Thus, results of the study indicated a moderating effect of post event information by the arousal states. © 2005-2011 Europe's Journal of Psychology.",no
10.1111/jcom.12159,the power of a picture: overcoming scientific misinformation by communicating weight-of-evidence information with visual exemplars,"Although most experts agree that vaccines do not cause autism, a considerable portion of the American public believes in a link. In an experiment (N = 371), we identified journalistic balance as a source of misperception about this issue and examined ways to attenuate misperceptions. In particular, by including weight-of-evidence information (i.e., stating that only one view is supported by evidence and a scientific consensus), we explored whether an article can present conflicting views without causing misperceptions. Including weight-of-evidence information fostered more accurate beliefs about an autism-vaccine link, but only for people with favorable pre-existing scientific views. However, this conditional effect disappeared when visual exemplars accompanied weight-of-evidence information. The findings of this study have both theoretical and practical implications for science communication. © 2015 International Communication Association.",no
10.1007/s11109-010-9112-2,when corrections fail: the persistence of political misperceptions,"An extensive literature addresses citizen ignorance, but very little research focuses on misperceptions. Can these false or unsubstantiated beliefs about politics be corrected? Previous studies have not tested the efficacy of corrections in a realistic format. We conducted four experiments in which subjects read mock news articles that included either a misleading claim from a politician, or a misleading claim and a correction. Results indicate that corrections frequently fail to reduce misperceptions among the targeted ideological group. We also document several instances of a ""backfire effect"" in which corrections actually increase misperceptions among the group in question. © Springer Science+Business Media, LLC 2010.",no
10.3758/s13421-013-0358-x,do people keep believing because they want to? preexisting attitudes and the continued influence of misinformation,"Misinformation-defined as information that is initially assumed to be valid but is later corrected or retracted-often has an ongoing effect on people's memory and reasoning. We tested the hypotheses that (a) reliance on misinformation is affected by people's preexisting attitudes and (b) attitudes determine the effectiveness of retractions. In two experiments, participants scoring higher and lower on a racial prejudice scale read a news report regarding a robbery. In one scenario, the suspects were initially presented as being Australian Aboriginals, whereas in a second scenario, a hero preventing the robbery was introduced as an Aboriginal person. Later, these critical, race-related pieces of information were or were not retracted. We measured participants' reliance on misinformation in response to inferential reasoning questions. The results showed that preexisting attitudes influence people's use of attitude-related information but not the way in which a retraction of that information is processed. © 2013 Psychonomic Society, Inc.",no
10.1016/j.actpsy.2014.06.006,confidence-accuracy resolution in the misinformation paradigm is influenced by the availability of source cues,"After witnessing an event, people often report having seen details that were merely suggested to them. Evidence is mixed regarding how well participants can use confidence judgments to discriminate between their correct and misled memory reports. We tested the prediction that the confidence-accuracy relationship for misled details depends upon the availability of source cues at retrieval. In Experiment 1, participants (N=77) viewed a videotaped staged crime before reading a misleading narrative. After seven minutes or one week, the participants completed a cued recall test for the details of the original event. Prior to completing the test, all participants were warned that the narrative contained misleading details to encourage source monitoring. The results showed that the strength of the confidence-accuracy relationship declined significantly over the delay. We interpret our results in the source monitoring framework. After an extended delay, fewer diagnostic source details were available to participants, increasing reliance on retrieval fluency as a basis for memory and metamemory decisions. We tested this interpretation in a second experiment, in which participants (N=42) completed a source monitoring test instead of a cued recall test. We observed a large effect of retention interval on source monitoring, and no significant effect on item memory. This research emphasizes the importance of securing eyewitness statements as soon as possible after an event, when witnesses are most able to discriminate between information that was personally seen and information obtained from secondary sources. © 2014.",no
10.1111/jcom.12164,"emotions, partisanship, and misperceptions: how anger and anxiety moderate the effect of partisan bias on susceptibility to political misinformation","Citizens are frequently misinformed about political issues and candidates but the circumstances under which inaccurate beliefs emerge are not fully understood. This experimental study demonstrates that the independent experience of two emotions, anger and anxiety, in part determines whether citizens consider misinformation in a partisan or open-minded fashion. Anger encourages partisan, motivated evaluation of uncorrected misinformation that results in beliefs consistent with the supported political party, while anxiety at times promotes initial beliefs based less on partisanship and more on the information environment. However, exposure to corrections improves belief accuracy, regardless of emotion or partisanship. The results indicate that the unique experience of anger and anxiety can affect the accuracy of political beliefs by strengthening or attenuating the influence of partisanship. © 2015 International Communication Association.",no
10.1046/j.1365-2923.2002.01299.x,"misinformation, partial knowledge and guessing in true/false tests","Context: Examiners disagree on whether or not multiple choice and true/false tests should be negatively marked. Much of the debate has been clouded by neglect of the role of misinformation and by vagueness regarding both the specification of test types and 'partial knowledge' in relation to guessing. Moreover, variations in risk-taking in the face of negative marking have too often been treated in absolute terms rather than in relation to the effect of guessing on test unreliability. Objectives: This paper aims to clarify these points and to compare the ill-effects on test reliability of guessing and of variable risk-taking. Methods: Three published studies on medical students are examined. These compare responses in true/false tests obtained with both negative marking and number-right scoring. The studies yield data on misinformation and on the extent to which students may fail to benefit from distrusted partial knowledge when there is negative marking. A simple statistical model is used to compare variations in risk-taking with test unreliability due to blind guessing under number-right scoring conditions. Conclusions: Partial knowledge should be least problematic with independent true/false items. The effect on test reliability of blind guessing under number-right conditions is generally greater than that due to the over-cautiousness of some students when there is negative marking.",yes