# Signal Detection Theory {#signal-detection-theory}

Our two measures - discernment and skepticism bias - are akin to two measures of signal detection theory (SDT): D' (sensitivity), and C (response bias). As our discernment measure, a positive D' score indicates that people rate true news as more accurate than false news. As our skepticism bias measure, a positive C score arises when the miss rate (rating true news as not accurate) is greater than the false alarm rate (rating false news as accurate). A body of recent studies uses a SDT framework to evaluate people's news judgments [@bataillerSignalDetectionApproach2019; @gawronskiTruthSensitivityPartisan2023; @modirrousta-galianGamifiedInoculationInterventions2023]. Do our results from our measures align with those from an SDT framework?

As with all individual-level analysis before, we rely on the subset of raw data for all ratings that individual participants made on each news headline they saw. If not already on a binary scale, we collapse likert scale responses to a binary scale. This allows to us to calculate D' and C for each participant.

```{r, message=FALSE}
# load individual level data
sdt_individual <- read_csv("data/individual_level_subset.csv") %>% 
  filter(condition == "control") %>% 
  # collapse accuracy scores to binary (if not already binary)
  mutate(
    # add helper variable that indicates scales with midpoint
    midpoint_scale = ifelse(scale_numeric %% 2 != 0, TRUE, FALSE),
    accuracy = case_when(
      # keep binary scores
      scale == "binary"~accuracy, 
      # code midpoints as NA,
      midpoint_scale == TRUE & 
        accuracy == (scale_numeric/2)+0.5 ~ NA,
      # transform continuous scores
      accuracy <= scale_numeric/2 ~ 0, 
      accuracy > scale_numeric/2 ~ 1, 
      TRUE ~ NA)
  ) %>% 
  # remove NA's 
  drop_na(accuracy) %>% 
  # calculate hit rate and false alarm rate per participant
  group_by(unique_participant_id, veracity) %>%
  summarize(
    # add corrections (following Ariana Modirrousta-Galian & Philip A. Higham, 2023 and 
    # Batailler et al., 2022):
    # When participants have a Hit rate of 1 and a False alarm rate of 0, the formulas for D' and C 
    # yield inifinetly large/small scores. We applied a loglinear correction when calculating the 
    # hit and false alarm rates by adding 0.5 to both the number of hits and false alarms and 
    # adding 1 to both the number of signal (true news) and noise (fake news) trials (Stanislaw & Todorov, 1999).
    n_items = n() + 1, 
    n_rated_as_accurate = sum(accuracy) + 0.5, 
    share_rated_as_accurate = n_rated_as_accurate/n_items
  ) %>% 
  ungroup() %>% 
  group_by(unique_participant_id) %>% 
  mutate(n_items_total = sum(n_items)) %>% 
  pivot_wider(names_from = veracity, 
              values_from = c(share_rated_as_accurate, n_rated_as_accurate, n_items)) %>% 
  rename(
    # In SDT language a true news item rated as accurate is a "hit", 
    # while a false news item rated as accurate is a "false alarm".
    hits = n_rated_as_accurate_true,
    false_alarms = n_rated_as_accurate_fake,
    hit_rate = share_rated_as_accurate_true, 
    false_alarm_rate = share_rated_as_accurate_fake) %>% 
  # calculate d' and c
  mutate(
    dprime   = qnorm(hit_rate) - qnorm(false_alarm_rate),
    c        = -1 * (qnorm(hit_rate) + qnorm(false_alarm_rate)) / 2 
  ) %>% 
  ungroup()
```

(ref:SDT-descriptive-plot) Distributions of outcomes of individual participants in the subset of studies that we have raw data on. The upper plot shows the distribution for the SDT outcome measures ("D prime", sensitivity, and "C", response bias). The lower plot corresponds to Fig. \@ref(fig:individual-level-plot) from the results section of the main article and shows the distribution for our outcome measures for the same sample of participants (discernment and skepticism bias). The percentage labels (from left to right) represent the share of participants with a negative score, a score of exactly 0, and a positive score, for all measures respectively.

```{r SDT-descriptive-plot, fig.cap="(ref:SDT-descriptive-plot)"}
# plot

# Main plot data: shape data to long format
data <- sdt_individual %>% 
  pivot_longer(c(dprime, c),
               names_to = "outcome", 
               values_to = "value") %>% 
  # make nicer names
  mutate(outcome = ifelse(outcome == "dprime", "D' (sensitivity)", 
                          "C (response bias)"),
         outcome = factor(outcome, levels = c("D' (sensitivity)", 
                                              "C (response bias)")
                          )
         )

# summary data for labels
# table 
summary_data <- data %>% 
  drop_na(value) %>% 
  mutate(valence = ifelse(value > 0, "positive", 
                          ifelse(value == 0, "neutral", 
                                 "negative")
                          )
         ) %>% 
  group_by(valence, outcome) %>% 
  summarize(n_subj = n_distinct(unique_participant_id)) %>% 
    pivot_wider(names_from = outcome, 
              values_from = n_subj) %>% 
  # relative frequency
  ungroup() %>% 
  mutate(
    share_d = `D' (sensitivity)` / sum(`D' (sensitivity)`),
    share_c = `C (response bias)` / sum(`C (response bias)`)
    ) %>% 
  pivot_longer(c(share_d, share_c), 
               names_to = "outcome", 
               values_to = "value") %>% 
  mutate(outcome = ifelse(outcome == "share_d", "D' (sensitivity)", 
                          "C (response bias)"), 
         outcome = factor(outcome, levels = c("D' (sensitivity)", 
                                                 "C (response bias)")
                             ),
         label = paste0(round(value, digits = 4)*100, " %"),
         x_position = case_when(valence == "negative" ~ -1.5,
                                valence == "neutral" ~ 0,
                                valence == "positive" ~ 1.5), 
         y_position = 0.8)

# make plot
SDT_descriptive_plot <- ggplot(data, aes(x = value, fill = outcome, color = outcome)) +
  geom_density(alpha = 0.5)+
  # add line at 0
  geom_vline(xintercept = 0, 
             linewidth = 0.5, linetype = "24", color = "grey") +
  # scale
  #scale_x_continuous(breaks = seq(from = -1, to = 1, by = 0.2)) +
  # add labels for share of participants
  geom_label(inherit.aes = FALSE, data = summary_data,
             aes(x = x_position, y = y_position, 
                 label = label),
             alpha = 0.6,
             color = "grey50", size = 3, show.legend = FALSE) +
  # colors 
  scale_color_viridis_d(option = "turbo", begin = 0.1, end = 0.7)+
  scale_fill_viridis_d(option = "turbo", begin = 0.1, end = 0.7) +
  # labels and scales
  labs(x = "Score (z-transformed)", y = "Density") +
  guides(fill = FALSE, color = FALSE) +
  plot_theme +
  theme(legend.position = "bottom",
        axis.text.y = element_blank(),
        strip.text = element_text(size = 14)) +
  facet_wrap(~outcome)

# Label the individual plots using annotate_figure
SDT <- annotate_figure(SDT_descriptive_plot, top = text_grob("(SDT Framework)", size = 14))
individual_level <- annotate_figure(individual_level_plot, top = text_grob("(Our measures)", size = 14))

SDT /
  individual_level
```

Fig. \@ref(fig:SDT-descriptive-plot) visualizes the results. From descriptively comparing the share of participants with positive, negative, and scores of 0, we can see that sensitivity (D') and discernment yield almost identical results, while our skepticism bias measure qualifies slightly more people as having a tendency to be skeptical than the response bias C. However, conclusions remain the same. 
