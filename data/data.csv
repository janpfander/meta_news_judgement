paperID,reference,ref,intervention_study,comments_intervention_selection,comments,peer_reviewed,sampleID, country,design,online,pre_test,details_pretest,recycled_news,recycled_news_reference,news_selection,selection_fake_news,selection_true_news,news_family,newsID,n_news,n_news_pool,share_true_news,news_format,news_source,accuracy_measure,accuracy_measure_detailed,symetry,perfect_symetry,accuracy_scale,condition,treatment_intention,intervention,intervention_detail,experimentID,correlates,correlates_detail,n,mean_fake_as_accurate,SD_fake_as_accurate,mean_true_as_accurate,SD_true_as_accurate,values_from,panel
1,"Altay, S., de Araujo, E., & Mercier, H. (2022). “If This account is True, It is Most Enormously Wonderful”: Interestingness-If-True and the Sharing of True and False News. Digital Journalism, 10(3), 373–394. https://doi.org/10.1080/21670811.2021.1941163",Altay 2022,,,"data correspond to experiment 1
did not entirely rely on the news of Pennycook et al. (2020) because some of them were outdated.",yes,1,United States,within,yes,no,,recycled,"Pennycook, G., McPhetres, J., Zhang, Y., Lu, J. G., & Rand, D. G. (2020). Fighting COVID-19 Misinformation on Social Media: Experimental Evidence for a Scalable Accuracy-Nudge Intervention. 11.",researchers,fact_checking,mainstream,covid,1,10,,0.5,title_picture_pitch,nosource,accuracy,"we measured how accurate participants deemed the headlines using
the same accuracy question as Pennycook and Rand (2018): “To the best of your knowledge,
how accurate is the claim in the above headline?” (1[Not at all accurate], 2[Not very accurate],
3[Somewhat accurate], 4[Very accurate])",1,0,4,control,,,,,,,299,1.99,0.89,2.71,0.88,paper,no
1,"Altay, S., de Araujo, E., & Mercier, H. (2022). “If This account is True, It is Most Enormously Wonderful”: Interestingness-If-True and the Sharing of True and False News. Digital Journalism, 10(3), 373–394. https://doi.org/10.1080/21670811.2021.1941163",Altay 2022,,,"data correspond to experiment 2
did not entirely rely on the news of Pennycook et al. (2020) because some of them were outdated.",yes,2,United States,within,yes,no,,recycled,"Pennycook, G., McPhetres, J., Zhang, Y., Lu, J. G., & Rand, D. G. (2020). Fighting COVID-19 Misinformation on Social Media: Experimental Evidence for a Scalable Accuracy-Nudge Intervention. 11.",researchers,fact_checking,mainstream,covid,2,10,,0.5,title_picture_pitch,nosource,accuracy,"we measured how accurate participants deemed the headlines using
the same accuracy question as Pennycook and Rand (2018): “To the best of your knowledge,
how accurate is the claim in the above headline?” (1[Not at all accurate], 2[Not very accurate],
3[Somewhat accurate], 4[Very accurate])",1,0,4,control,,,,,,,299,2.04,0.88,2.74,0.83,paper,no
1,"Altay, S., de Araujo, E., & Mercier, H. (2022). “If This account is True, It is Most Enormously Wonderful”: Interestingness-If-True and the Sharing of True and False News. Digital Journalism, 10(3), 373–394. https://doi.org/10.1080/21670811.2021.1941163",Altay 2022,,,"data correspond to experiment 3
did not entirely rely on the news of Pennycook et al. (2020) because some of them were outdated.",yes,3,United States,within,yes,no,,recycled,"Pennycook, G., McPhetres, J., Zhang, Y., Lu, J. G., & Rand, D. G. (2020). Fighting COVID-19 Misinformation on Social Media: Experimental Evidence for a Scalable Accuracy-Nudge Intervention. 11.",researchers,fact_checking,mainstream,covid,3,10,,0.5,title_picture_pitch,nosource,accuracy,"we measured how accurate participants deemed the headlines using
the same accuracy question as Pennycook and Rand (2018): “To the best of your knowledge,
how accurate is the claim in the above headline?” (1[Not at all accurate], 2[Not very accurate],
3[Somewhat accurate], 4[Very accurate])",1,0,4,control,,,,,,,299,1.98,0.88,2.76,1.99,paper,no
2,"Lutzke, L., Drummond, C., Slovic, P., & Árvai, J. (2019). Priming critical thinking: Simple interventions limit the influence of fake news about climate change on Facebook. Global Environmental Change, 58, 101964. https://doi.org/10.1016/j.gloenvcha.2019.101964",Lutzke 2019,yes,"We merge both the treatment conditions (literacy and enhanced literacy), since they are sufficiently similar","values for  taken from Table 2; 
sample size aggregated by condition, values from Table 1;
Regarding False news selection: We confirmed that the Breitbart (Now 400 scientific papers in 2017 say “global warming” is a myth) and Natural News (NASA confirms sea levels have been falling across the planet for two years...media silent) posts contained falsehoods by cross-checking them with an independent fact-checking database (snopes.com). The post from InfoWars (Al Gore insists global warming causes global cooling) was confirmed as false by tracing the sources and information it cited; specifically, we located the blog post shared by Mr. Gore (from The Climate Reality Project) which explained that climate change may in some cases lead to colder weather, but not a cooler climate overall.",yes,1,United States,between,yes,no,,original,,researchers,hyper_partisan_sites,mainstream,environment_climate,1,6,,0.5,title_picture_pitch,source,trust,"After reviewing their randomly assigned post, participants were
asked to rate its trustworthiness on a 10-point scale from 1 (not at all
trustworthy) to 10 (very trustworthy). Participants also rated each post
in terms of perceived accuracy on a 10-point scale from 1 (not at all
accurate) to 10 (very accurate). Judged trustworthiness and accuracy
were combined to create a single item index variable for trust
(Cronbach’s α=0.93).",1,0,10,control,,,,1,,,934,4.28,2.55,6.38,2.34,paper,no
2,"Lutzke, L., Drummond, C., Slovic, P., & Árvai, J. (2019). Priming critical thinking: Simple interventions limit the influence of fake news about climate change on Facebook. Global Environmental Change, 58, 101964. https://doi.org/10.1016/j.gloenvcha.2019.101964",Lutzke 2019,yes,"We merge both the treatment conditions (literacy and enhanced literacy), since they are sufficiently similar","values for  taken from Table 2; 
sample size aggregated by condition, values from Table 1;
Regarding False news selection: We confirmed that the Breitbart (Now 400 scientific papers in 2017 say “global warming” is a myth) and Natural News (NASA confirms sea levels have been falling across the planet for two years...media silent) posts contained falsehoods by cross-checking them with an independent fact-checking database (snopes.com). The post from InfoWars (Al Gore insists global warming causes global cooling) was confirmed as false by tracing the sources and information it cited; specifically, we located the blog post shared by Mr. Gore (from The Climate Reality Project) which explained that climate change may in some cases lead to colder weather, but not a cooler climate overall.",yes,2,United States,between,yes,no,,original,,researchers,hyper_partisan_sites,mainstream,environment_climate,1,6,,0.5,title_picture_pitch,source,trust,"After reviewing their randomly assigned post, participants were
asked to rate its trustworthiness on a 10-point scale from 1 (not at all
trustworthy) to 10 (very trustworthy). Participants also rated each post
in terms of perceived accuracy on a 10-point scale from 1 (not at all
accurate) to 10 (very accurate). Judged trustworthiness and accuracy
were combined to create a single item index variable for trust
(Cronbach’s α=0.93).",1,0,10,treatment,positive,literacy,"In the Guidelines condition, participants were informed that they
would view a Facebook post about climate change. Next, they were
asked to consider a series of four questions (i.e., the guidelines) that
would help them to evaluate the credibility of news online. The questions
were: (1) Do I recognize the news organization that posted the story?;
(2) Does the information in the post seem believable?; (3) Is the post written
in a style that I expect from a professional news organization?; and (4) Is the
post politically motivated? These guidelines reflected common recommendations
for identifying fake news",1,,,917,3.93,2.6,6.69,2.4,paper,no
2,"Lutzke, L., Drummond, C., Slovic, P., & Árvai, J. (2019). Priming critical thinking: Simple interventions limit the influence of fake news about climate change on Facebook. Global Environmental Change, 58, 101964. https://doi.org/10.1016/j.gloenvcha.2019.101964",Lutzke 2019,yes,"We merge both the treatment conditions (literacy and enhanced literacy), since they are sufficiently similar","values for  taken from Table 2; 
sample size aggregated by condition, values from Table 1;
Regarding False news selection: We confirmed that the Breitbart (Now 400 scientific papers in 2017 say “global warming” is a myth) and Natural News (NASA confirms sea levels have been falling across the planet for two years...media silent) posts contained falsehoods by cross-checking them with an independent fact-checking database (snopes.com). The post from InfoWars (Al Gore insists global warming causes global cooling) was confirmed as false by tracing the sources and information it cited; specifically, we located the blog post shared by Mr. Gore (from The Climate Reality Project) which explained that climate change may in some cases lead to colder weather, but not a cooler climate overall.",yes,3,United States,between,yes,no,,original,,researchers,hyper_partisan_sites,mainstream,environment_climate,1,6,,0.5,title_picture_pitch,source,trust,"After reviewing their randomly assigned post, participants were
asked to rate its trustworthiness on a 10-point scale from 1 (not at all
trustworthy) to 10 (very trustworthy). Participants also rated each post
in terms of perceived accuracy on a 10-point scale from 1 (not at all
accurate) to 10 (very accurate). Judged trustworthiness and accuracy
were combined to create a single item index variable for trust
(Cronbach’s α=0.93).",1,0,10,treatment,positive,literacy,"In the Enhanced Guidelines condition, participants were also informed that they would view a Facebook post about climate change, 
and they were also asked to consider the same four questions from the Guidelines condition. But, participants in this condition 
were also asked to rate the importance of each guideline (on a 1–10 scale from not at all important to very important) in terms 
of its ability to help them evaluate the credibility of news online.",1,,,899,4.03,2.44,6.6,2.27,paper,no
3,"Pennycook, G., Cannon, T. D., & Rand, D. G. (2018). Prior exposure increases perceived accuracy of fake news. Journal of Experimental Psychology: General, 147(12), 1865–1880. https://doi.org/10.1037/xge0000465",Pennycook 2018,yes,We consider only the warning tags intervention with non-previously familiarized items. That is because this is the intervention most comparable to other studies.,"data correspond to experiment 2, values taken from Table 3;
Considered as  control condition here: Novel (i.e. no familiarized) politically concordant news with no warning of 3rd fact checker sites",yes,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_concordant,1,6,,0.5,title_picture_pitch,source,accuracy,"As in other work on perceptions of news accuracy (Pennycook & Rand, 2017a, 2017b; Pennycook & Rand, 2018), participants were then asked “To the best of your knowledge, how accurate is the claim in the above headline?” and they rated accuracy on the following 4-point scale: 1) not at all accurate, 2) not very accurate, 3) somewhat accurate, 4) very accurate.",1,0,4,control,,,,1,,,474.5,1.78,0.6,2.83,0.7,paper,no
3,"Pennycook, G., Cannon, T. D., & Rand, D. G. (2018). Prior exposure increases perceived accuracy of fake news. Journal of Experimental Psychology: General, 147(12), 1865–1880. https://doi.org/10.1037/xge0000465",Pennycook 2018,yes,We consider only the warning tags intervention with non-previously familiarized items. That is because this is the intervention most comparable to other studies.,"data correspond to experiment 2, values taken from Table 3;
Considered as  control condition here: Novel (i.e. no familiarized) politically discordant news with no warning of 3rd fact checker sites",yes,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_discordant,2,6,,0.5,title_picture_pitch,source,accuracy,"As in other work on perceptions of news accuracy (Pennycook & Rand, 2017a, 2017b; Pennycook & Rand, 2018), participants were then asked “To the best of your knowledge, how accurate is the claim in the above headline?” and they rated accuracy on the following 4-point scale: 1) not at all accurate, 2) not very accurate, 3) somewhat accurate, 4) very accurate.",1,0,4,control,,,,2,,,474.5,1.6,0.5,2.39,0.6,paper,no
3,"Pennycook, G., Cannon, T. D., & Rand, D. G. (2018). Prior exposure increases perceived accuracy of fake news. Journal of Experimental Psychology: General, 147(12), 1865–1880. https://doi.org/10.1037/xge0000465",Pennycook 2018,yes,We consider only the warning tags intervention with non-previously familiarized items. That is because this is the intervention most comparable to other studies.,"data correspond to experiment 2, values taken from Table 3;
Considered as  treatment condition here: Familiarized politically concordant news with no warning of 3rd fact checker sites",yes,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_concordant,3,6,,0.5,title_picture_pitch,source,accuracy,"As in other work on perceptions of news accuracy (Pennycook & Rand, 2017a, 2017b; Pennycook & Rand, 2018), participants were then asked “To the best of your knowledge, how accurate is the claim in the above headline?” and they rated accuracy on the following 4-point scale: 1) not at all accurate, 2) not very accurate, 3) somewhat accurate, 4) very accurate.",1,0,4,treatment,neutral,familiarization,"""In the familiarization stage, participants engaged with the news headlines in an ecologically valid way: they indicated whether they would share each headline on social media. Specifically, participants were asked “Would you consider sharing this story online (for example, through Facebook or Twitter)?"" The participants then advanced to the distractor stage, in which they completed a set of filler demographic questions.”;
as far as we can tell, participants have not been given any feedback in the first wave - hence we code treatment_intention as neutral",,,,474.5,1.93,0.7,2.98,0.6,paper,no
3,"Pennycook, G., Cannon, T. D., & Rand, D. G. (2018). Prior exposure increases perceived accuracy of fake news. Journal of Experimental Psychology: General, 147(12), 1865–1880. https://doi.org/10.1037/xge0000465",Pennycook 2018,yes,We consider only the warning tags intervention with non-previously familiarized items. That is because this is the intervention most comparable to other studies.,"data correspond to experiment 2, values taken from Table 3;
Considered as  treatment condition here: Familiarized politically discordant news with no warning of 3rd fact checker sites",yes,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_discordant,4,6,,0.5,title_picture_pitch,source,accuracy,"As in other work on perceptions of news accuracy (Pennycook & Rand, 2017a, 2017b; Pennycook & Rand, 2018), participants were then asked “To the best of your knowledge, how accurate is the claim in the above headline?” and they rated accuracy on the following 4-point scale: 1) not at all accurate, 2) not very accurate, 3) somewhat accurate, 4) very accurate.",1,0,4,treatment,neutral,familiarization,"""In the familiarization stage, participants engaged with the news headlines in an ecologically valid way: they indicated whether they would share each headline on social media. Specifically, participants were asked “Would you consider sharing this story online (for example, through Facebook or Twitter)?"" The participants then advanced to the distractor stage, in which they completed a set of filler demographic questions.”;
as far as we can tell, participants have not been given any feedback in the first wave - hence we code treatment_intention as neutral",,,,474.5,1.72,0.6,2.5,0.6,paper,no
3,"Pennycook, G., Cannon, T. D., & Rand, D. G. (2018). Prior exposure increases perceived accuracy of fake news. Journal of Experimental Psychology: General, 147(12), 1865–1880. https://doi.org/10.1037/xge0000465",Pennycook 2018,yes,We consider only the warning tags intervention with non-previously familiarized items. That is because this is the intervention most comparable to other studies.,"data correspond to experiment 2, values taken from Table 3;
Considered as  treatment condition here: Novel (i.e. no familiarized) politically concordant news with warning of 3rd fact checker sites",yes,2,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_concordant,1,6,,0.5,title_picture_pitch,source,accuracy,"As in other work on perceptions of news accuracy (Pennycook & Rand, 2017a, 2017b; Pennycook & Rand, 2018), participants were then asked “To the best of your knowledge, how accurate is the claim in the above headline?” and they rated accuracy on the following 4-point scale: 1) not at all accurate, 2) not very accurate, 3) somewhat accurate, 4) very accurate.",1,0,4,treatment,positive,tagwarningfakenews,,1,,,474.5,1.68,0.6,2.86,0.7,paper,no
3,"Pennycook, G., Cannon, T. D., & Rand, D. G. (2018). Prior exposure increases perceived accuracy of fake news. Journal of Experimental Psychology: General, 147(12), 1865–1880. https://doi.org/10.1037/xge0000465",Pennycook 2018,yes,We consider only the warning tags intervention with non-previously familiarized items. That is because this is the intervention most comparable to other studies.,"data correspond to experiment 2, values taken from Table 3;
Considered as  treatment condition here: Novel (i.e. no familiarized) politically discordant news with warning of 3rd fact checker sites",yes,2,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_discordant,2,6,,0.5,title_picture_pitch,source,accuracy,"As in other work on perceptions of news accuracy (Pennycook & Rand, 2017a, 2017b; Pennycook & Rand, 2018), participants were then asked “To the best of your knowledge, how accurate is the claim in the above headline?” and they rated accuracy on the following 4-point scale: 1) not at all accurate, 2) not very accurate, 3) somewhat accurate, 4) very accurate.",1,0,4,treatment,positive,tagwarningfakenews,,2,,,474.5,1.53,0.5,2.4,0.6,paper,no
3,"Pennycook, G., Cannon, T. D., & Rand, D. G. (2018). Prior exposure increases perceived accuracy of fake news. Journal of Experimental Psychology: General, 147(12), 1865–1880. https://doi.org/10.1037/xge0000465",Pennycook 2018,yes,We consider only the warning tags intervention with non-previously familiarized items. That is because this is the intervention most comparable to other studies.,"data correspond to experiment 2, values taken from Table 3;
Considered as  treatment condition here: Familiarized politically concordant news with warning of 3rd fact checker sites",yes,2,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_concordant,3,6,,0.5,title_picture_pitch,source,accuracy,"As in other work on perceptions of news accuracy (Pennycook & Rand, 2017a, 2017b; Pennycook & Rand, 2018), participants were then asked “To the best of your knowledge, how accurate is the claim in the above headline?” and they rated accuracy on the following 4-point scale: 1) not at all accurate, 2) not very accurate, 3) somewhat accurate, 4) very accurate.",1,0,4,treatment,positive,multiple_familiarization_warningforfakenews,,,,,474.5,1.81,0.7,2.92,0.7,paper,no
3,"Pennycook, G., Cannon, T. D., & Rand, D. G. (2018). Prior exposure increases perceived accuracy of fake news. Journal of Experimental Psychology: General, 147(12), 1865–1880. https://doi.org/10.1037/xge0000465",Pennycook 2018,yes,We consider only the warning tags intervention with non-previously familiarized items. That is because this is the intervention most comparable to other studies.,"data correspond to experiment 2, values taken from Table 3;
Considered as  treatment condition here: Familiarized politically discordant news with warning of 3rd fact checker sites",yes,2,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_discordant,4,6,,0.5,title_picture_pitch,source,accuracy,"As in other work on perceptions of news accuracy (Pennycook & Rand, 2017a, 2017b; Pennycook & Rand, 2018), participants were then asked “To the best of your knowledge, how accurate is the claim in the above headline?” and they rated accuracy on the following 4-point scale: 1) not at all accurate, 2) not very accurate, 3) somewhat accurate, 4) very accurate.",1,0,4,treatment,positive,multiple_familiarization_warningforfakenews,,,,,474.5,1.6,0.6,2.49,0.6,paper,no
4,"Pennycook, G., & Rand, D. G. (2020). Who falls for fake news? The roles of bullshit receptivity, overclaiming, familiarity, and analytic thinking. Journal of Personality, 88(2), 185–200. https://doi.org/10.1111/jopy.12476",Pennycook 2020,,,"data correspond to study 2, values for SD'S extracted from supplementary material;
'source' was coded as 'mixed' because no fine grained results were available for the two distinct source conditions;
regarding news items: ""Fake news stories were taken from a previous analysis of some of the most widely circulated during the 2016 Presidential election (along with contemporary real news stories) (Silverman et al., 2016). We did not attempt to balance the partisan leanings of the stories and therefore cannot draw inferences about partisanship here.""",yes,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,political,1,10,,0.5,title_picture_pitch,mixed,accuracy,"“To
the best of your knowledge, how accurate is the claim in
the above headline?” (response options: not at all accurate/
not very accurate/somewhat accurate/very accurate)",1,0,4,control,,,,,,,402,1.95,0.6,2.64,0.53,paper,no
4,"Pennycook, G., & Rand, D. G. (2020). Who falls for fake news? The roles of bullshit receptivity, overclaiming, familiarity, and analytic thinking. Journal of Personality, 88(2), 185–200. https://doi.org/10.1111/jopy.12476",Pennycook 2020,,,"data correspond to study 3, values extracted from supplementary material ; 
data are from Pennycook and Rand 2019, 'Lazy not biased', experiment 1; because we don't report this experiment to avoid doubles, we code the news headlines use here as 'original'",yes,2,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,2,30,,0.5,title_picture_pitch,source,accuracy,"“To
the best of your knowledge, how accurate is the claim in
the above headline?” (response options: not at all accurate/
not very accurate/somewhat accurate/very accurate)",1,0,4,control,,,,,,,802,1.83,0.42,2.76,0.43,paper,no
5,"Bronstein, M. V., Pennycook, G., Bear, A., Rand, D. G., & Cannon, T. D. (2019). Belief in Fake News is Associated with Delusionality, Dogmatism, Religious Fundamentalism, and Reduced Analytic Thinking. Journal of Applied Research in Memory and Cognition, 8(1), 108–117. https://doi.org/10.1016/j.jarmac.2018.09.005",Bronstein 2019,,,data correspond to study 1; values extracted from table 1,yes,1,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2020). Who falls for fake news? The roles of bullshit receptivity, overclaiming, familiarity, and analytic thinking. Journal of Personality, 88(2), 185–200. https://doi.org/10.1111/jopy.12476",researchers,fact_checking,mainstream,politically_balanced,1,24,,0.5,title_picture_pitch,source,accuracy,"Accuracy ratingswere made on a four-point scale (1 = Not at all accurate, 4 = Veryaccurate). 
Belief in fake news was calculated using the averageof these judgments across all fake stories, 
while belief in realnews was calculated using the average across all real stories.",1,0,4,control,,,,,,,502,1.79,0.46,2.78,0.47,paper,no
5,"Bronstein, M. V., Pennycook, G., Bear, A., Rand, D. G., & Cannon, T. D. (2019). Belief in Fake News is Associated with Delusionality, Dogmatism, Religious Fundamentalism, and Reduced Analytic Thinking. Journal of Applied Research in Memory and Cognition, 8(1), 108–117. https://doi.org/10.1016/j.jarmac.2018.09.005",Bronstein 2019,,,data correspond to study 2; values extracted from table 1,yes,2,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2020). Who falls for fake news? The roles of bullshit receptivity, overclaiming, familiarity, and analytic thinking. Journal of Personality, 88(2), 185–200. https://doi.org/10.1111/jopy.12476",researchers,fact_checking,mainstream,politically_balanced,1,24,,0.5,title_picture_pitch,source,accuracy,"Accuracy ratingswere made on a four-point scale (1 = Not at all accurate, 4 = Veryaccurate). 
Belief in fake news was calculated using the averageof these judgments across all fake stories, 
while belief in realnews was calculated using the average across all real stories.",1,0,4,control,,,,,,,446,1.85,0.49,2.82,0.46,paper,no
6,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",Pennycook 2019,,,"data correspond to study 2; values extracted from supplementary material; 
Data for Study 2 were taken from the control condition of a set of five identical experiments 
that assessed a fact-checking intervention for fake news (Pennycook & Rand, 2017; 'the implied truth effect'; study 1); because we don't report this experiment to avoid doubles, we code the news headlines use here as 'original'
It would have been possible to read the different ratings according to politically concordant/discordant from a graph - but due to potential imprecision and no majort differences, I relied on the pooled ratings ",yes,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,24,,0.5,title_picture_pitch,source,accuracy,"“To the best of your knowledge, how accurate is the claim in the above headline?” 
(response options: not at all accurate, not very accurate, somewhat accurate, very accurate)",1,0,4,control,,,,,,,2644,1.66,0.45,2.59,0.44,paper,no
7,"Guess, A. M., Lerner, M., Lyons, B., Montgomery, J. M., Nyhan, B., Reifler, J., & Sircar, N. (2020). A digital media literacy intervention increases discernment between mainstream and false news in the United States and India. Proceedings of the National Academy of Sciences, 117(27), 15536–15545. https://doi.org/10.1073/pnas.1920498117",Guess 2020,yes,,"data correspond to online India sample, wave 1, control group; values are obtained from correspondence with author Andy Guess; 
sample size not reported seperately for control and treatement group - we took overal sample size reported in paper and divided by two",yes,1,India,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,12,,0.5,title,nosource,accuracy,"original scale: 4-point scale ranging from very accurate (4) to not at all accurate (1).
The shares reported are on a binary scale, where 'somewhat accurate' (3) and 'very accurate' (4) are one category, 
and (1) and (2) the other, respectively.",1,0,4,control,,,,1,,,1636.5,2.4,0.729,2.77,0.694,authors,panel
7,"Guess, A. M., Lerner, M., Lyons, B., Montgomery, J. M., Nyhan, B., Reifler, J., & Sircar, N. (2020). A digital media literacy intervention increases discernment between mainstream and false news in the United States and India. Proceedings of the National Academy of Sciences, 117(27), 15536–15545. https://doi.org/10.1073/pnas.1920498117",Guess 2020,yes,,"data correspond to online India sample, wave 1, treatment group; values are obtained from correspondence with author Andy Guess; sample size not reported seperately for control and treatement group - we took overal sample size reported in paper and divided by two",yes,2,India,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,12,,0.5,title,nosource,accuracy,"original scale: 4-point scale ranging from very accurate (4) to not at all accurate (1).
The shares reported are on a binary scale, where 'somewhat accurate' (3) and 'very accurate' (4) are one category, 
and (1) and (2) the other, respectively.",1,0,4,treatment,positive,literacy,"6 strategies that readers can use to identify false or misleading stories that appear on their news feeds;
""Each respondent was randomly assigned to either the placebo or treatment condition for the media literacy intervention experiment (randomization occurs at the individual level in both the face-toface and the online survey). Those assigned to the treatment condition were shown (online) or read (face-to-face) six tips for spotting false news adapted from the ads Facebook and WhatsApp published in Hindi-language newspapers in India. Respondents in the control condition were not exposed to any tips. The tips were read or shown in two groups of three with a comprehension question after each set of tips. (See Figure A2 for wording.) To increase the likelihood of respondents understanding the tips, respondents in the online survey who provided an incorrect answer to either comprehension question were asked to read the tips and answer the question again. They were allowed to proceed in the survey after answering the question correctly or trying three times — whichever comes first. In the face-to-face survey, such a process was not undertaken due to concerns about respondent attention and attrition. Respondents who provide an incorrect answer to either comprehension question simply proceeded in the survey.""",1,,,1636.5,2.27,0.749,2.69,0.716,authors,panel
7,"Guess, A. M., Lerner, M., Lyons, B., Montgomery, J. M., Nyhan, B., Reifler, J., & Sircar, N. (2020). A digital media literacy intervention increases discernment between mainstream and false news in the United States and India. Proceedings of the National Academy of Sciences, 117(27), 15536–15545. https://doi.org/10.1073/pnas.1920498117",Guess 2020,yes,,"data correspond to online India sample, wave 2, control group; values are obtained from correspondence with author Andy Guess; sample size not reported seperately for control and treatement group - we took overal sample size reported in paper and divided by two",yes,1,India,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,2,16,,0.375,title,nosource,accuracy,"original scale: 4-point scale ranging from very accurate (4) to not at all accurate (1).
The shares reported are on a binary scale, where 'somewhat accurate' (3) and 'very accurate' (4) are one category, 
and (1) and (2) the other, respectively.",1,0,4,control,,,,2,,,684.5,2.11,0.731,2.62,0.685,authors,panel
7,"Guess, A. M., Lerner, M., Lyons, B., Montgomery, J. M., Nyhan, B., Reifler, J., & Sircar, N. (2020). A digital media literacy intervention increases discernment between mainstream and false news in the United States and India. Proceedings of the National Academy of Sciences, 117(27), 15536–15545. https://doi.org/10.1073/pnas.1920498117",Guess 2020,yes,,"data correspond to online India sample, wave 2, treatment group; values are obtained from correspondence with author Andy Guess; sample size not reported seperately for control and treatement group - we took overal sample size reported in paper and divided by two",yes,2,India,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,2,16,,0.375,title,nosource,accuracy,"original scale: 4-point scale ranging from very accurate (4) to not at all accurate (1).
The shares reported are on a binary scale, where 'somewhat accurate' (3) and 'very accurate' (4) are one category, 
and (1) and (2) the other, respectively.",1,0,4,treatment,positive,1monthbefore_literacy,"In the first wave, ~1 month before, the sample received this treatment: 
the 6 strategies that readers can use to identify false or misleading stories that appear on their news feeds;
""Each respondent was randomly assigned to either the placebo or treatment condition for the media literacy intervention experiment (randomization occurs at the individual level in both the face-toface and the online survey). Those assigned to the treatment condition were shown (online) or read (face-to-face) six tips for spotting false news adapted from the ads Facebook and WhatsApp published in Hindi-language newspapers in India. Respondents in the control condition were not exposed to any tips. The tips were read or shown in two groups of three with a comprehension question after each set of tips. (See Figure A2 for wording.) To increase the likelihood of respondents understanding the tips, respondents in the online survey who provided an incorrect answer to either comprehension question were asked to read the tips and answer the question again. They were allowed to proceed in the survey after answering the question correctly or trying three times — whichever comes first. In the face-to-face survey, such a process was not undertaken due to concerns about respondent attention and attrition. Respondents who provide an incorrect answer to either comprehension question simply proceeded in the survey.""",2,,,684.5,2.13,0.738,2.57,0.709,authors,panel
7,"Guess, A. M., Lerner, M., Lyons, B., Montgomery, J. M., Nyhan, B., Reifler, J., & Sircar, N. (2020). A digital media literacy intervention increases discernment between mainstream and false news in the United States and India. Proceedings of the National Academy of Sciences, 117(27), 15536–15545. https://doi.org/10.1073/pnas.1920498117",Guess 2020,yes,,"data correspond to face-to-face India sample, wave 1, control group; values are obtained from correspondence with author Andy Guess; 
sample size not reported seperately for control and treatement group - we took overal sample size reported in paper and divided by two",yes,3,India,within,no,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,12,,0.5,title_read_out,nosource,accuracy,"original scale: 4-point scale ranging from very accurate (4) to not at all accurate (1).
The shares reported are on a binary scale, where 'somewhat accurate' (3) and 'very accurate' (4) are one category, 
and (1) and (2) the other, respectively.",1,0,4,control,,,,3,,,1872,2.83,0.766,3.08,0.753,authors,panel
7,"Guess, A. M., Lerner, M., Lyons, B., Montgomery, J. M., Nyhan, B., Reifler, J., & Sircar, N. (2020). A digital media literacy intervention increases discernment between mainstream and false news in the United States and India. Proceedings of the National Academy of Sciences, 117(27), 15536–15545. https://doi.org/10.1073/pnas.1920498117",Guess 2020,yes,,"data correspond to face-to-face India sample, wave 1, treatment group; values are obtained from correspondence with author Andy Guess; 
sample size not reported seperately for control and treatement group - we took overal sample size reported in paper and divided by two",yes,4,India,within,no,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,12,,0.5,title_read_out,nosource,accuracy,"original scale: 4-point scale ranging from very accurate (4) to not at all accurate (1).
The shares reported are on a binary scale, where 'somewhat accurate' (3) and 'very accurate' (4) are one category, 
and (1) and (2) the other, respectively.",1,0,4,treatment,positive,literacy,"6 strategies that readers can use to identify false or misleading stories that appear on their news feeds;
""Each respondent was randomly assigned to either the placebo or treatment condition for the media literacy intervention experiment (randomization occurs at the individual level in both the face-toface and the online survey). Those assigned to the treatment condition were shown (online) or read (face-to-face) six tips for spotting false news adapted from the ads Facebook and WhatsApp published in Hindi-language newspapers in India. Respondents in the control condition were not exposed to any tips. The tips were read or shown in two groups of three with a comprehension question after each set of tips. (See Figure A2 for wording.) To increase the likelihood of respondents understanding the tips, respondents in the online survey who provided an incorrect answer to either comprehension question were asked to read the tips and answer the question again. They were allowed to proceed in the survey after answering the question correctly or trying three times — whichever comes first. In the face-to-face survey, such a process was not undertaken due to concerns about respondent attention and attrition. Respondents who provide an incorrect answer to either comprehension question simply proceeded in the survey.""",3,,,1872,2.83,0.758,3.07,0.727,authors,panel
7,"Guess, A. M., Lerner, M., Lyons, B., Montgomery, J. M., Nyhan, B., Reifler, J., & Sircar, N. (2020). A digital media literacy intervention increases discernment between mainstream and false news in the United States and India. Proceedings of the National Academy of Sciences, 117(27), 15536–15545. https://doi.org/10.1073/pnas.1920498117",Guess 2020,yes,,"data correspond to face-to-face India sample, wave 2, control group; values are obtained from correspondence with author Andy Guess; 
sample size not reported seperately for control and treatement group - we took overal sample size reported in paper and divided by two",yes,3,India,within,no,no,,original,,researchers,fact_checking,mainstream,politically_balanced,2,16,,0.375,title_read_out,nosource,accuracy,"original scale: 4-point scale ranging from very accurate (4) to not at all accurate (1).
The shares reported are on a binary scale, where 'somewhat accurate' (3) and 'very accurate' (4) are one category, 
and (1) and (2) the other, respectively.",1,0,4,control,,,,4,,,1347.5,2,0.805,2.85,0.838,authors,panel
7,"Guess, A. M., Lerner, M., Lyons, B., Montgomery, J. M., Nyhan, B., Reifler, J., & Sircar, N. (2020). A digital media literacy intervention increases discernment between mainstream and false news in the United States and India. Proceedings of the National Academy of Sciences, 117(27), 15536–15545. https://doi.org/10.1073/pnas.1920498117",Guess 2020,yes,,"data correspond to face-to-face India sample, wave 2, treatment group; values are obtained from correspondence with author Andy Guess; 
sample size not reported seperately for control and treatement group - we took overal sample size reported in paper and divided by two",yes,4,India,within,no,no,,original,,researchers,fact_checking,mainstream,politically_balanced,2,16,,0.375,title_read_out,nosource,accuracy,"original scale: 4-point scale ranging from very accurate (4) to not at all accurate (1).
The shares reported are on a binary scale, where 'somewhat accurate' (3) and 'very accurate' (4) are one category, 
and (1) and (2) the other, respectively.",1,0,4,treatment,positive,1monthbefore_literacy,"In the first wave, ~1 month before, the sample received this treatment: 
the 6 strategies that readers can use to identify false or misleading stories that appear on their news feeds;
""Each respondent was randomly assigned to either the placebo or treatment condition for the media literacy intervention experiment (randomization occurs at the individual level in both the face-toface and the online survey). Those assigned to the treatment condition were shown (online) or read (face-to-face) six tips for spotting false news adapted from the ads Facebook and WhatsApp published in Hindi-language newspapers in India. Respondents in the control condition were not exposed to any tips. The tips were read or shown in two groups of three with a comprehension question after each set of tips. (See Figure A2 for wording.) To increase the likelihood of respondents understanding the tips, respondents in the online survey who provided an incorrect answer to either comprehension question were asked to read the tips and answer the question again. They were allowed to proceed in the survey after answering the question correctly or trying three times — whichever comes first. In the face-to-face survey, such a process was not undertaken due to concerns about respondent attention and attrition. Respondents who provide an incorrect answer to either comprehension question simply proceeded in the survey.""",4,,,1347.5,2.03,0.819,2.85,0.845,authors,panel
8,"Pennycook, G., McPhetres, J., Zhang, Y., Lu, J. G., & Rand, D. G. (2020). Fighting COVID-19 Misinformation on Social Media: Experimental Evidence for a Scalable Accuracy-Nudge Intervention. 11.",Pennycook 2020_b,,,"data correspond to study 1 (study 2 is about sharing);
numbers are calculated based on appendix on OSF
where the authors report average accuracy ratings 
per headline. The scores here are the respective averages
(they also match the figures reported in the paper, from eyeballing) ",yes,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,30,,0.5,title_picture_pitch,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” (yes/no)",1,1,binary,control,,,,,,,426.5,0.33,0.28,0.65,0.22,paper,no
9,"Clayton, K., Blair, S., Busam, J. A., Forstner, S., Glance, J., Green, G., Kawata, A., Kovvuri, A., Martin, J., Morgan, E., Sandhu, M., Sang, R., Scholz-Bright, R., Welch, A. T., Wolff, A. G., Zhou, A., & Nyhan, B. (2020). Real Solutions for Fake News? Measuring the Effectiveness of General Warnings and Fact-Check Tags in Reducing Belief in False Stories on Social Media. Political Behavior, 42(4), 1073–1095. https://doi.org/10.1007/s11109-019-09533-0",Clayton 2020,yes,"We did not consider general warnings about fake news. We only considered tags put on each news items (without additional general warnings). There were two distinctinct conditions that did this: one in which the label was ""disputed"", another in which the label was ""fake"". We merged the two conditions. ","values are based on our own calculations using their data;
corresponds to the sample assigned to the General Warning = No and Tag = None condition (cf. table 1 in paper)",yes,1,United States,within,yes,no,,recycled,"Pennycook, G., Cannon, T. D., & Rand, D. G. (2018). Prior exposure increases perceived accuracy of fake news. Journal of Experimental Psychology: General, 147(12), 1865–1880. https://doi.org/10.1037/xge0000465",researchers,fact_checking,mainstream,politically_balanced,1,9,,0.3333333333,title_picture_pitch,nosource,accuracy,participants were asked to evaluate the accuracy of each claim on a four-point Likert scale from “Not at all accurate” (1) to “Very accurate” (4).,1,0,4,control,,,"""We manipulated whether participants were exposed to a general warning about misleading articles or not (middle column of Table  1). We also independently randomized noncontrols into one of three headline conditions: a condition in which no fact-checking tags were presented (first two rows of Table  1), a specific warning condition that included tags labeling articles as “Disputed” (second two rows of Table  1), and a specific warning condition in which they were instead labeled as “Rated false” (last two rows of Table 1).""",1,,,469,1.96,0.934,3.34,0.927,raw data,no
9,"Clayton, K., Blair, S., Busam, J. A., Forstner, S., Glance, J., Green, G., Kawata, A., Kovvuri, A., Martin, J., Morgan, E., Sandhu, M., Sang, R., Scholz-Bright, R., Welch, A. T., Wolff, A. G., Zhou, A., & Nyhan, B. (2020). Real Solutions for Fake News? Measuring the Effectiveness of General Warnings and Fact-Check Tags in Reducing Belief in False Stories on Social Media. Political Behavior, 42(4), 1073–1095. https://doi.org/10.1007/s11109-019-09533-0",Clayton 2020,yes,"We did not consider general warnings about fake news. We only considered tags put on each news items (without additional general warnings). There were two distinctinct conditions that did this: one in which the label was ""disputed"", another in which the label was ""fake"". We merged the two conditions. ","values are based on our own calculations using their data;
corresponds to the sample assigned to the General Warning = Yes and Tag = None condition (cf. table 1 in paper)",yes,2,United States,within,yes,no,,recycled,"Pennycook, G., Cannon, T. D., & Rand, D. G. (2018). Prior exposure increases perceived accuracy of fake news. Journal of Experimental Psychology: General, 147(12), 1865–1880. https://doi.org/10.1037/xge0000465",researchers,fact_checking,mainstream,politically_balanced,1,9,,0.3333333333,title_picture_pitch,nosource,accuracy,participants were asked to evaluate the accuracy of each claim on a four-point Likert scale from “Not at all accurate” (1) to “Very accurate” (4).,1,0,4,treatment,,warninggeneral_literacy,"""We manipulated whether participants were exposed to a general warning about misleading articles or not""; 
""In the general warning condition, participants were shown a message warning them about misleading articles and providing advice for identifying false information (see Online Appendix A for exact wording and design).""",,,,424,1.88,0.927,3.22,0.999,raw data,no
9,"Clayton, K., Blair, S., Busam, J. A., Forstner, S., Glance, J., Green, G., Kawata, A., Kovvuri, A., Martin, J., Morgan, E., Sandhu, M., Sang, R., Scholz-Bright, R., Welch, A. T., Wolff, A. G., Zhou, A., & Nyhan, B. (2020). Real Solutions for Fake News? Measuring the Effectiveness of General Warnings and Fact-Check Tags in Reducing Belief in False Stories on Social Media. Political Behavior, 42(4), 1073–1095. https://doi.org/10.1007/s11109-019-09533-0",Clayton 2020,yes,"We did not consider general warnings about fake news. We only considered tags put on each news items (without additional general warnings). There were two distinctinct conditions that did this: one in which the label was ""disputed"", another in which the label was ""fake"". We merged the two conditions. ","values are based on our own calculations using their data;
corresponds to the sample assigned to the General Warning = No and Tag = Disputed (cf. table 1 in paper)",yes,3,United States,within,yes,no,,recycled,"Pennycook, G., Cannon, T. D., & Rand, D. G. (2018). Prior exposure increases perceived accuracy of fake news. Journal of Experimental Psychology: General, 147(12), 1865–1880. https://doi.org/10.1037/xge0000465",researchers,fact_checking,mainstream,politically_balanced,1,9,,0.3333333333,title_picture_pitch,nosource,accuracy,participants were asked to evaluate the accuracy of each claim on a four-point Likert scale from “Not at all accurate” (1) to “Very accurate” (4).,1,0,4,treatment,,tagdisputedfakenews,a specific warning condition that included tags labeling articles as “Disputed”,2,,,413,1.81,0.901,3.37,0.911,raw data,no
9,"Clayton, K., Blair, S., Busam, J. A., Forstner, S., Glance, J., Green, G., Kawata, A., Kovvuri, A., Martin, J., Morgan, E., Sandhu, M., Sang, R., Scholz-Bright, R., Welch, A. T., Wolff, A. G., Zhou, A., & Nyhan, B. (2020). Real Solutions for Fake News? Measuring the Effectiveness of General Warnings and Fact-Check Tags in Reducing Belief in False Stories on Social Media. Political Behavior, 42(4), 1073–1095. https://doi.org/10.1007/s11109-019-09533-0",Clayton 2020,yes,"We did not consider general warnings about fake news. We only considered tags put on each news items (without additional general warnings). There were two distinctinct conditions that did this: one in which the label was ""disputed"", another in which the label was ""fake"". We merged the two conditions. ","values are based on our own calculations using their data;
corresponds to the sample assigned to the General Warning = Yes and Tag = Disputed (cf. table 1 in paper)",yes,4,United States,within,yes,no,,recycled,"Pennycook, G., Cannon, T. D., & Rand, D. G. (2018). Prior exposure increases perceived accuracy of fake news. Journal of Experimental Psychology: General, 147(12), 1865–1880. https://doi.org/10.1037/xge0000465",researchers,fact_checking,mainstream,politically_balanced,1,9,,0.3333333333,title_picture_pitch,nosource,accuracy,participants were asked to evaluate the accuracy of each claim on a four-point Likert scale from “Not at all accurate” (1) to “Very accurate” (4).,1,0,4,treatment,,multiple_warninggeneral_literacy_tagdisputedfakenews,"""We manipulated whether participants were exposed to a general warning about misleading articles or not""; 
""In the general warning condition, participants were shown a message warning them about misleading articles and providing advice for identifying false information (see Online Appendix A for exact wording and design)."";
a specific warning condition that included tags labeling articles as “Disputed”",,,,429,1.76,0.882,3.37,0.885,raw data,no
9,"Clayton, K., Blair, S., Busam, J. A., Forstner, S., Glance, J., Green, G., Kawata, A., Kovvuri, A., Martin, J., Morgan, E., Sandhu, M., Sang, R., Scholz-Bright, R., Welch, A. T., Wolff, A. G., Zhou, A., & Nyhan, B. (2020). Real Solutions for Fake News? Measuring the Effectiveness of General Warnings and Fact-Check Tags in Reducing Belief in False Stories on Social Media. Political Behavior, 42(4), 1073–1095. https://doi.org/10.1007/s11109-019-09533-0",Clayton 2020,yes,"We did not consider general warnings about fake news. We only considered tags put on each news items (without additional general warnings). There were two distinctinct conditions that did this: one in which the label was ""disputed"", another in which the label was ""fake"". We merged the two conditions. ","values are based on our own calculations using their data;
corresponds to the sample assigned to the General Warning = No and Tag = Rated False (cf. table 1 in paper)",yes,5,United States,within,yes,no,,recycled,"Pennycook, G., Cannon, T. D., & Rand, D. G. (2018). Prior exposure increases perceived accuracy of fake news. Journal of Experimental Psychology: General, 147(12), 1865–1880. https://doi.org/10.1037/xge0000465",researchers,fact_checking,mainstream,politically_balanced,1,9,,0.3333333333,title_picture_pitch,nosource,accuracy,participants were asked to evaluate the accuracy of each claim on a four-point Likert scale from “Not at all accurate” (1) to “Very accurate” (4).,1,0,4,treatment,,tagfalsefakenews,a specific warning condition in which they were instead labeled as “Rated false”,2,,,429,1.73,0.907,3.37,0.887,raw data,no
9,"Clayton, K., Blair, S., Busam, J. A., Forstner, S., Glance, J., Green, G., Kawata, A., Kovvuri, A., Martin, J., Morgan, E., Sandhu, M., Sang, R., Scholz-Bright, R., Welch, A. T., Wolff, A. G., Zhou, A., & Nyhan, B. (2020). Real Solutions for Fake News? Measuring the Effectiveness of General Warnings and Fact-Check Tags in Reducing Belief in False Stories on Social Media. Political Behavior, 42(4), 1073–1095. https://doi.org/10.1007/s11109-019-09533-0",Clayton 2020,yes,"We did not consider general warnings about fake news. We only considered tags put on each news items (without additional general warnings). There were two distinctinct conditions that did this: one in which the label was ""disputed"", another in which the label was ""fake"". We merged the two conditions. ","values are based on our own calculations using their data;
corresponds to the sample assigned to the General Warning = Yes and Tag = Rated False (cf. table 1 in paper)",yes,6,United States,within,yes,no,,recycled,"Pennycook, G., Cannon, T. D., & Rand, D. G. (2018). Prior exposure increases perceived accuracy of fake news. Journal of Experimental Psychology: General, 147(12), 1865–1880. https://doi.org/10.1037/xge0000465",researchers,fact_checking,mainstream,politically_balanced,1,9,,0.3333333333,title_picture_pitch,nosource,accuracy,participants were asked to evaluate the accuracy of each claim on a four-point Likert scale from “Not at all accurate” (1) to “Very accurate” (4).,1,0,4,treatment,,multiple_warninggeneral_literacy_tagfalsefakenews,"""We manipulated whether participants were exposed to a general warning about misleading articles or not""; 
""In the general warning condition, participants were shown a message warning them about misleading articles and providing advice for identifying false information (see Online Appendix A for exact wording and design)."";
a specific warning condition in which they were instead labeled as “Rated false”",,,,397,1.69,0.888,3.37,0.906,raw data,no
10,"Luo, M., Hancock, J. T., & Markowitz, D. M. (2022). Credibility Perceptions and Detection Accuracy of Fake News Headlines on Social Media: Effects of Truth-Bias and Endorsement Cues. Communication Research, 49(2), 171–195. https://doi.org/10.1177/0093650220921321",Luo 2022,,,"data correspond to study 1; values displayed in table 1 - since they reporte SE and not SD, but made data available, we calculated values ourselves based on raw data;
""Upon consenting to take part in the study, participants were told that “all headlines [they see] have been widely circulated on Facebook and some of them involve blatant fake content.""
This might work in a way like an accuracy prime/general warning. ",yes,1,United States,within,yes,implicit_selection,"from appendix: ""We controlled for the relative virality of real and fake news by matching real and fake news by total shares. We identified the total number of times a fake news item was shared on Facebook by September 2017 using buzzsumo.com, an online content database (see Allcott & Gentzkow, 2017), and then selected real news items with similar Facebook share frequencies.""",original,,researchers,fact_checking,mainstream,political,1,10,,0.5,title_pitch,nosource,message_credibility,"""Participants reported the extent to which they believed that the news was fake or real on a 7-point Likert-type scale from 1 = definitely fake to 7 = definitely real.""
We report this as the main scale. The authors also provide percentages of accuracy on a binary scale: 
""We followed prior work for calculating detection accuracy from Likert-type scale responses (Levine et al., 2010): scores of 1 to 3 were rescored as fake and were coded as accurate if the news was actually fake and as inaccurate if the news was actually real, while scores of 5 to 7 were rescored as real and were coded for accuracy in the same manner. The midpoint 4 was always coded as half accurate.""",1,1,7,control,,,,,,,115,2.98,1.95,4.72,2.01,raw data,no
10,"Luo, M., Hancock, J. T., & Markowitz, D. M. (2022). Credibility Perceptions and Detection Accuracy of Fake News Headlines on Social Media: Effects of Truth-Bias and Endorsement Cues. Communication Research, 49(2), 171–195. https://doi.org/10.1177/0093650220921321",Luo 2022,,,"data correspond to study 1; values displayed in table 1 - since they reporte SE and not SD, but made data available, we calculated values ourselves based on raw data;
""Upon consenting to take part in the study, participants were told that “all headlines [they see] have been widely circulated on Facebook and some of them involve blatant fake content.""
This might work in a way like an accuracy prime/general warning. ",yes,2,United States,within,yes,implicit_selection,"from appendix: ""We controlled for the relative virality of real and fake news by matching real and fake news by total shares. We identified the total number of times a fake news item was shared on Facebook by September 2017 using buzzsumo.com, an online content database (see Allcott & Gentzkow, 2017), and then selected real news items with similar Facebook share frequencies.""",original,,researchers,fact_checking,mainstream,health,2,10,,0.5,title_pitch,nosource,message_credibility,"""Participants reported the extent to which they believed that the news was fake or real on a 7-point Likert-type scale from 1 = definitely fake to 7 = definitely real.""
We report this as the main scale. The authors also provide percentages of accuracy on a binary scale: 
""We followed prior work for calculating detection accuracy from Likert-type scale responses (Levine et al., 2010): scores of 1 to 3 were rescored as fake and were coded as accurate if the news was actually fake and as inaccurate if the news was actually real, while scores of 5 to 7 were rescored as real and were coded for accuracy in the same manner. The midpoint 4 was always coded as half accurate.""",1,1,7,control,,,,,,,116,3.47,1.92,4.08,2.06,raw data,no
10,"Luo, M., Hancock, J. T., & Markowitz, D. M. (2022). Credibility Perceptions and Detection Accuracy of Fake News Headlines on Social Media: Effects of Truth-Bias and Endorsement Cues. Communication Research, 49(2), 171–195. https://doi.org/10.1177/0093650220921321",Luo 2022,,,"data correspond to study 1; values from table 1
""Upon consenting to take part in the study, participants were told that “all headlines [they see] have been widely circulated on Facebook and some of them involve blatant fake content.""
This might work in a way like an accuracy prime/general warning. ",yes,3,United States,within,yes,implicit_selection,"from appendix: ""We controlled for the relative virality of real and fake news by matching real and fake news by total shares. We identified the total number of times a fake news item was shared on Facebook by September 2017 using buzzsumo.com, an online content database (see Allcott & Gentzkow, 2017), and then selected real news items with similar Facebook share frequencies.""",original,,researchers,fact_checking,mainstream,science,3,10,,0.5,title_pitch,nosource,message_credibility,"""Participants reported the extent to which they believed that the news was fake or real on a 7-point Likert-type scale from 1 = definitely fake to 7 = definitely real.""
We report this as the main scale. The authors also provide percentages of accuracy on a binary scale: 
""We followed prior work for calculating detection accuracy from Likert-type scale responses (Levine et al., 2010): scores of 1 to 3 were rescored as fake and were coded as accurate if the news was actually fake and as inaccurate if the news was actually real, while scores of 5 to 7 were rescored as real and were coded for accuracy in the same manner. The midpoint 4 was always coded as half accurate.""",1,1,7,control,,,,,,,106,3.95,2.12,4,1.96,raw data,no
10,"Luo, M., Hancock, J. T., & Markowitz, D. M. (2022). Credibility Perceptions and Detection Accuracy of Fake News Headlines on Social Media: Effects of Truth-Bias and Endorsement Cues. Communication Research, 49(2), 171–195. https://doi.org/10.1177/0093650220921321",Luo 2022,,,"data correspond to study 2; values from table 1 - since they reporte SE and not SD, but made data available, we calculated values ourselves based on raw data;
Study 2 (sample_ID's 4,5 & 6) had multiple conditions. Since there was no main effect found for friend vs. non-friend conditions, 
we take the average per news topic as shown in Table 1 (e.g. for message credibility of real political news in the high likes 
condition, we calculate (4.82 + 4.77)/2 for the mean, respectively for the SD. This is just to illustrate, we simply glossed over this factor when calculating summary statistics based on the raw data). This way we enter only high vs. low likes as treatment.
Although there was no other control condition, both low and high number of likes are coded as treatment, since it was a within-participant factor and 
both could yield their own respective effects compared to a (fictive) no-likes condition.",yes,4,United States,within,yes,implicit_selection,"from appendix: ""We controlled for the relative virality of real and fake news by matching real and fake news by total shares. We identified the total number of times a fake news item was shared on Facebook by September 2017 using buzzsumo.com, an online content database (see Allcott & Gentzkow, 2017), and then selected real news items with similar Facebook share frequencies.""",original,,researchers,fact_checking,mainstream,political,1,8,,0.5,title_picture_pitch,nosource,message_credibility,"""Participants reported the extent to which they believed that the news was fake or real on a 7-point Likert-type scale from 1 = definitely fake to 7 = definitely real.""
We report this as the main scale. The authors also provide percentages of accuracy on a binary scale: 
""We followed prior work for calculating detection accuracy from Likert-type scale responses (Levine et al., 2010): scores of 1 to 3 were rescored as fake and were coded as accurate if the news was actually fake and as inaccurate if the news was actually real, while scores of 5 to 7 were rescored as real and were coded for accuracy in the same manner. The midpoint 4 was always coded as half accurate.""",1,1,7,treatment,negative,low_likes,,,,,103,2.68,1.74,4.55,1.94,raw data,no
10,"Luo, M., Hancock, J. T., & Markowitz, D. M. (2022). Credibility Perceptions and Detection Accuracy of Fake News Headlines on Social Media: Effects of Truth-Bias and Endorsement Cues. Communication Research, 49(2), 171–195. https://doi.org/10.1177/0093650220921321",Luo 2022,,,"data correspond to study 2; values from table 1 - since they reporte SE and not SD, but made data available, we calculated values ourselves based on raw data;
Study 2 (sample_ID's 4,5 & 6) had multiple conditions. Since there was no main effect found for friend vs. non-friend conditions, 
we take the average per news topic as shown in Table 1 (e.g. for message credibility of real political news in the high likes 
condition, we calculate (4.82 + 4.77)/2 for the mean, respectively for the SD. This is just to illustrate, we simply glossed over this factor when calculating summary statistics based on the raw data). This way we enter only high vs. low likes as treatment.
Although there was no other control condition, both low and high number of likes are coded as treatment, since it was a within-participant factor and 
both could yield their own respective effects compared to a (fictive) no-likes condition.",yes,4,United States,within,yes,implicit_selection,"from appendix: ""We controlled for the relative virality of real and fake news by matching real and fake news by total shares. We identified the total number of times a fake news item was shared on Facebook by September 2017 using buzzsumo.com, an online content database (see Allcott & Gentzkow, 2017), and then selected real news items with similar Facebook share frequencies.""",original,,researchers,fact_checking,mainstream,political,1,8,,0.5,title_picture_pitch,nosource,message_credibility,"""Participants reported the extent to which they believed that the news was fake or real on a 7-point Likert-type scale from 1 = definitely fake to 7 = definitely real.""
We report this as the main scale. The authors also provide percentages of accuracy on a binary scale: 
""We followed prior work for calculating detection accuracy from Likert-type scale responses (Levine et al., 2010): scores of 1 to 3 were rescored as fake and were coded as accurate if the news was actually fake and as inaccurate if the news was actually real, while scores of 5 to 7 were rescored as real and were coded for accuracy in the same manner. The midpoint 4 was always coded as half accurate.""",1,1,7,treatment,positive,high_likes,,,,,103,2.74,1.73,4.79,1.83,raw data,no
10,"Luo, M., Hancock, J. T., & Markowitz, D. M. (2022). Credibility Perceptions and Detection Accuracy of Fake News Headlines on Social Media: Effects of Truth-Bias and Endorsement Cues. Communication Research, 49(2), 171–195. https://doi.org/10.1177/0093650220921321",Luo 2022,,,"data correspond to study 2; values from table 1 - since they reporte SE and not SD, but made data available, we calculated values ourselves based on raw data;
Study 2 (sample_ID's 4,5 & 6) had multiple conditions. Since there was no main effect found for friend vs. non-friend conditions, 
we take the average per news topic as shown in Table 1 (e.g. for message credibility of real political news in the high likes 
condition, we calculate (4.82 + 4.77)/2 for the mean, respectively for the SD. This is just to illustrate, we simply glossed over this factor when calculating summary statistics based on the raw data). This way we enter only high vs. low likes as treatment.
Although there was no other control condition, both low and high number of likes are coded as treatment, since it was a within-participant factor and 
both could yield their own respective effects compared to a (fictive) no-likes condition.",yes,5,United States,within,yes,implicit_selection,"from appendix: ""We controlled for the relative virality of real and fake news by matching real and fake news by total shares. We identified the total number of times a fake news item was shared on Facebook by September 2017 using buzzsumo.com, an online content database (see Allcott & Gentzkow, 2017), and then selected real news items with similar Facebook share frequencies.""",original,,researchers,fact_checking,mainstream,health,2,8,,0.5,title_picture_pitch,nosource,message_credibility,"""Participants reported the extent to which they believed that the news was fake or real on a 7-point Likert-type scale from 1 = definitely fake to 7 = definitely real.""
We report this as the main scale. The authors also provide percentages of accuracy on a binary scale: 
""We followed prior work for calculating detection accuracy from Likert-type scale responses (Levine et al., 2010): scores of 1 to 3 were rescored as fake and were coded as accurate if the news was actually fake and as inaccurate if the news was actually real, while scores of 5 to 7 were rescored as real and were coded for accuracy in the same manner. The midpoint 4 was always coded as half accurate.""",1,1,7,treatment,negative,low_likes,,,,,105,3.44,1.85,3.11,1.92,raw data,no
10,"Luo, M., Hancock, J. T., & Markowitz, D. M. (2022). Credibility Perceptions and Detection Accuracy of Fake News Headlines on Social Media: Effects of Truth-Bias and Endorsement Cues. Communication Research, 49(2), 171–195. https://doi.org/10.1177/0093650220921321",Luo 2022,,,"data correspond to study 2; values from table 1 - since they reporte SE and not SD, but made data available, we calculated values ourselves based on raw data;
Study 2 (sample_ID's 4,5 & 6) had multiple conditions. Since there was no main effect found for friend vs. non-friend conditions, 
we take the average per news topic as shown in Table 1 (e.g. for message credibility of real political news in the high likes 
condition, we calculate (4.82 + 4.77)/2 for the mean, respectively for the SD. This is just to illustrate, we simply glossed over this factor when calculating summary statistics based on the raw data). This way we enter only high vs. low likes as treatment.
Although there was no other control condition, both low and high number of likes are coded as treatment, since it was a within-participant factor and 
both could yield their own respective effects compared to a (fictive) no-likes condition.",yes,5,United States,within,yes,implicit_selection,"from appendix: ""We controlled for the relative virality of real and fake news by matching real and fake news by total shares. We identified the total number of times a fake news item was shared on Facebook by September 2017 using buzzsumo.com, an online content database (see Allcott & Gentzkow, 2017), and then selected real news items with similar Facebook share frequencies.""",original,,researchers,fact_checking,mainstream,health,2,8,,0.5,title_picture_pitch,nosource,message_credibility,"""Participants reported the extent to which they believed that the news was fake or real on a 7-point Likert-type scale from 1 = definitely fake to 7 = definitely real.""
We report this as the main scale. The authors also provide percentages of accuracy on a binary scale: 
""We followed prior work for calculating detection accuracy from Likert-type scale responses (Levine et al., 2010): scores of 1 to 3 were rescored as fake and were coded as accurate if the news was actually fake and as inaccurate if the news was actually real, while scores of 5 to 7 were rescored as real and were coded for accuracy in the same manner. The midpoint 4 was always coded as half accurate.""",1,1,7,treatment,positive,high_likes,,,,,105,3.84,1.87,3.89,2.07,raw data,no
10,"Luo, M., Hancock, J. T., & Markowitz, D. M. (2022). Credibility Perceptions and Detection Accuracy of Fake News Headlines on Social Media: Effects of Truth-Bias and Endorsement Cues. Communication Research, 49(2), 171–195. https://doi.org/10.1177/0093650220921321",Luo 2022,,,"data correspond to study 2; values from table 1 - since they reporte SE and not SD, but made data available, we calculated values ourselves based on raw data;
Study 2 (sample_ID's 4,5 & 6) had multiple conditions. Since there was no main effect found for friend vs. non-friend conditions, 
we take the average per news topic as shown in Table 1 (e.g. for message credibility of real political news in the high likes 
condition, we calculate (4.82 + 4.77)/2 for the mean, respectively for the SD. This is just to illustrate, we simply glossed over this factor when calculating summary statistics based on the raw data). This way we enter only high vs. low likes as treatment.
Although there was no other control condition, both low and high number of likes are coded as treatment, since it was a within-participant factor and 
both could yield their own respective effects compared to a (fictive) no-likes condition.",yes,6,United States,within,yes,implicit_selection,"from appendix: ""We controlled for the relative virality of real and fake news by matching real and fake news by total shares. We identified the total number of times a fake news item was shared on Facebook by September 2017 using buzzsumo.com, an online content database (see Allcott & Gentzkow, 2017), and then selected real news items with similar Facebook share frequencies.""",original,,researchers,fact_checking,mainstream,science,3,8,,0.5,title_picture_pitch,nosource,message_credibility,"""Participants reported the extent to which they believed that the news was fake or real on a 7-point Likert-type scale from 1 = definitely fake to 7 = definitely real.""
We report this as the main scale. The authors also provide percentages of accuracy on a binary scale: 
""We followed prior work for calculating detection accuracy from Likert-type scale responses (Levine et al., 2010): scores of 1 to 3 were rescored as fake and were coded as accurate if the news was actually fake and as inaccurate if the news was actually real, while scores of 5 to 7 were rescored as real and were coded for accuracy in the same manner. The midpoint 4 was always coded as half accurate.""",1,1,7,treatment,negative,low_likes,,,,,103,3.9,2.1,3.39,2.13,raw data,no
10,"Luo, M., Hancock, J. T., & Markowitz, D. M. (2022). Credibility Perceptions and Detection Accuracy of Fake News Headlines on Social Media: Effects of Truth-Bias and Endorsement Cues. Communication Research, 49(2), 171–195. https://doi.org/10.1177/0093650220921321",Luo 2022,,,"data correspond to study 2; values from table 1 - since they reporte SE and not SD, but made data available, we calculated values ourselves based on raw data;
Study 2 (sample_ID's 4,5 & 6) had multiple conditions. Since there was no main effect found for friend vs. non-friend conditions, 
we take the average per news topic as shown in Table 1 (e.g. for message credibility of real political news in the high likes 
condition, we calculate (4.82 + 4.77)/2 for the mean, respectively for the SD. This is just to illustrate, we simply glossed over this factor when calculating summary statistics based on the raw data). This way we enter only high vs. low likes as treatment.
Although there was no other control condition, both low and high number of likes are coded as treatment, since it was a within-participant factor and 
both could yield their own respective effects compared to a (fictive) no-likes condition.",yes,6,United States,within,yes,implicit_selection,"from appendix: ""We controlled for the relative virality of real and fake news by matching real and fake news by total shares. We identified the total number of times a fake news item was shared on Facebook by September 2017 using buzzsumo.com, an online content database (see Allcott & Gentzkow, 2017), and then selected real news items with similar Facebook share frequencies.""",original,,researchers,fact_checking,mainstream,science,3,8,,0.5,title_picture_pitch,nosource,message_credibility,"""Participants reported the extent to which they believed that the news was fake or real on a 7-point Likert-type scale from 1 = definitely fake to 7 = definitely real.""
We report this as the main scale. The authors also provide percentages of accuracy on a binary scale: 
""We followed prior work for calculating detection accuracy from Likert-type scale responses (Levine et al., 2010): scores of 1 to 3 were rescored as fake and were coded as accurate if the news was actually fake and as inaccurate if the news was actually real, while scores of 5 to 7 were rescored as real and were coded for accuracy in the same manner. The midpoint 4 was always coded as half accurate.""",1,1,7,treatment,positive,high_likes,,,,,103,4.17,2.01,3.7,1.96,raw data,no
11,"Bago, B., Rand, D. G., & Pennycook, G. (2020). Fake news, fast and slow: Deliberation reduces belief in false (but not true) news headlines. Journal of Experimental Psychology: General, 149(8), 1608–1613. https://doi.org/10.1037/xge0000729",Bago 2020,,,"data correspond to politically neutral news results (corresponding to study 1 on OSF);
one-response neutral ""pre-test"" study (appendix B); values are calculated based on provided data and cross-checked with values from Appendix, Table S3.
The ""neutral"" condition was a different sample, that the authors label ""pre-test"": 
(from appendix)""To avoid familiarity effects, participants who took part in the neutral headlines pre-test or participated in previous studies in which the same set of headlines were used, could not participate in this experiment.""
(from appendix) ""10 politically neutral headlines were presented, half of which were real (true and from a mainstreamsource) and half of which were fake (false and from an illegitimate source)."";
we coded 'neutral' for treatment intention, since it should be quite similar to control conditions (participants were allowed to revise an initial estimate made under time pressure, but they were not given any additional hints whatsoever - so whil the treatment is expected to be positive with regard to time pressure/ cognitive load conditon, we would expect it to be ""neutral"" with regard to a neutral control condition)",yes,1,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_neutral ,1,10,,0.5,title_picture_pitch,source,accuracy,participants were asked the following question: “Do you think this headline describes an event that actually happened in an accurate way?” with the response options “Yes/No” ,1,1,binary,control,,,,,,,202,0.307,0.461,0.746,0.436,raw data,no
11,"Bago, B., Rand, D. G., & Pennycook, G. (2020). Fake news, fast and slow: Deliberation reduces belief in false (but not true) news headlines. Journal of Experimental Psychology: General, 149(8), 1608–1613. https://doi.org/10.1037/xge0000729",Bago 2020,,,"data correspond to politically neutral news results (corresponding to study 1 on OSF);
one-response neutral ""pre-test"" study (appendix B); values are calculated based on provided data and cross-checked with values from Appendix, Table S3.
The ""neutral"" condition was a different sample, that the authors label ""pre-test"": 
(from appendix)""To avoid familiarity effects, participants who took part in the neutral headlines pre-test or participated in previous studies in which the same set of headlines were used, could not participate in this experiment.""
(from appendix) ""10 politically neutral headlines were presented, half of which were real (true and from a mainstreamsource) and half of which were fake (false and from an illegitimate source).""
we coded 'neutral' for treatment intention, since it should be quite similar to control conditions (participants were allowed to revise an initial estimate made under time pressure, but they were not given any additional hints whatsoever - so whil the treatment is expected to be positive with regard to time pressure/ cognitive load conditon, we would expect it to be ""neutral"" with regard to a neutral control condition)",yes,2,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_neutral ,1,10,,0.5,title_picture_pitch,source,accuracy,participants were asked the following question: “Do you think this headline describes an event that actually happened in an accurate way?” with the response options “Yes/No” ,1,1,binary,treatment,negative,multiple_timepressure_cognitiveload,"In the two-response experiment, participants made an initial response in which the extent of deliberation was minimized by having participants complete a load task (memorizing a pattern of five dots in a 4X4 matrix, see Bago & De Neys, 2019) and respond within 7 seconds (the average reading time in an N = 104 pre-test).",,,,421,0.394,0.489,0.674,0.469,raw data,no
11,"Bago, B., Rand, D. G., & Pennycook, G. (2020). Fake news, fast and slow: Deliberation reduces belief in false (but not true) news headlines. Journal of Experimental Psychology: General, 149(8), 1608–1613. https://doi.org/10.1037/xge0000729",Bago 2020,,,"data correspond to politically neutral news results (corresponding to study 1 on OSF);
one-response neutral ""pre-test"" study (appendix B); values are calculated based on provided data and cross-checked with values from Appendix, Table S3.
The ""neutral"" condition was a different sample, that the authors label ""pre-test"": 
(from appendix)""To avoid familiarity effects, participants who took part in the neutral headlines pre-test or participated in previous studies in which the same set of headlines were used, could not participate in this experiment.""
(from appendix) ""10 politically neutral headlines were presented, half of which were real (true and from a mainstreamsource) and half of which were fake (false and from an illegitimate source)."";
we coded 'neutral' for treatment intention, since it should be quite similar to control conditions (participants were allowed to revise an initial estimate made under time pressure, but they were not given any additional hints whatsoever - so whil the treatment is expected to be positive with regard to time pressure/ cognitive load conditon, we would expect it to be ""neutral"" with regard to a neutral control condition)",yes,2,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_neutral ,1,10,,0.5,title_picture_pitch,source,accuracy,participants were asked the following question: “Do you think this headline describes an event that actually happened in an accurate way?” with the response options “Yes/No” ,1,1,binary,treatment,neutral,revision_initial_estimate_under_time_pressure,"participants were presented with the same headline again they had rated under time pressure before – 
this time with no time deadline or cognitive load – and asked to give a final response.",,,,421,0.328,0.47,0.702,0.458,raw data,no
11,"Bago, B., Rand, D. G., & Pennycook, G. (2020). Fake news, fast and slow: Deliberation reduces belief in false (but not true) news headlines. Journal of Experimental Psychology: General, 149(8), 1608–1613. https://doi.org/10.1037/xge0000729",Bago 2020,,,"data correspond to politically laden (here, concordant) news results (corresponding to study 2 on OSF)
results from the one-response study; 
values are calculated based on provided data and cross-checked with Appendix, Table S3.;
we coded 'neutral' for treatment intention, since it should be quite similar to control conditions (participants were allowed to revise an initial estimate made under time pressure, but they were not given any additional hints whatsoever - so whil the treatment is expected to be positive with regard to time pressure/ cognitive load conditon, we would expect it to be ""neutral"" with regard to a neutral control condition)",yes,3,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_concordant,2,8,12,0.5,title_picture_pitch,source,accuracy,participants were asked the following question: “Do you think this headline describes an event that actually happened in an accurate way?” with the response options “Yes/No” ,1,1,binary,control,,,,,,,359,0.309,0.462,0.687,0.464,raw data,no
11,"Bago, B., Rand, D. G., & Pennycook, G. (2020). Fake news, fast and slow: Deliberation reduces belief in false (but not true) news headlines. Journal of Experimental Psychology: General, 149(8), 1608–1613. https://doi.org/10.1037/xge0000729",Bago 2020,,,"data correspond to politically laden (here, concordant) news results (corresponding to study 2 on OSF)
results from the two-response study; 
values are calculated based on provided data and cross-checked with Appendix, Table S3.;
we coded 'neutral' for treatment intention, since it should be quite similar to control conditions (participants were allowed to revise an initial estimate made under time pressure, but they were not given any additional hints whatsoever - so whil the treatment is expected to be positive with regard to time pressure/ cognitive load conditon, we would expect it to be ""neutral"" with regard to a neutral control condition)",yes,4,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_concordant,2,8,12,0.5,title_picture_pitch,source,accuracy,participants were asked the following question: “Do you think this headline describes an event that actually happened in an accurate way?” with the response options “Yes/No” ,1,1,binary,treatment,negative,multiple_timepressure_cognitiveload,"In the two-response experiment, participants made an initial response in which the extent of deliberation was minimized by having participants complete a load task (memorizing a pattern of five dots in a 4X4 matrix, see Bago & De Neys, 2019) and respond within 7 seconds (the average reading time in an N = 104 pre-test).",,,,653,0.376,0.484,0.675,0.468,raw data,no
11,"Bago, B., Rand, D. G., & Pennycook, G. (2020). Fake news, fast and slow: Deliberation reduces belief in false (but not true) news headlines. Journal of Experimental Psychology: General, 149(8), 1608–1613. https://doi.org/10.1037/xge0000729",Bago 2020,,,"data correspond to politically laden (here, concordant) news results (corresponding to study 2 on OSF)
results from the two-response study; 
values are calculated based on provided data and cross-checked with Appendix, Table S3.;
we coded 'neutral' for treatment intention, since it should be quite similar to control conditions (participants were allowed to revise an initial estimate made under time pressure, but they were not given any additional hints whatsoever - so whil the treatment is expected to be positive with regard to time pressure/ cognitive load conditon, we would expect it to be ""neutral"" with regard to a neutral control condition)",yes,4,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_concordant,2,8,12,0.5,title_picture_pitch,source,accuracy,participants were asked the following question: “Do you think this headline describes an event that actually happened in an accurate way?” with the response options “Yes/No” ,1,1,binary,treatment,neutral,revision_initial_estimate_under_time_pressure,"participants were presented with the same headline again they had rated under time pressure before – 
this time with no time deadline or cognitive load – and asked to give a final response.",,,,653,0.31,0.462,0.679,0.467,raw data,no
11,"Bago, B., Rand, D. G., & Pennycook, G. (2020). Fake news, fast and slow: Deliberation reduces belief in false (but not true) news headlines. Journal of Experimental Psychology: General, 149(8), 1608–1613. https://doi.org/10.1037/xge0000729",Bago 2020,,,"data correspond to politically laden (here, discordant) news results (corresponding to study 2 on OSF)
results from the one-response study; 
values are calculated based on provided data and cross-checked with Appendix, Table S3.;
we coded 'neutral' for treatment intention, since it should be quite similar to control conditions (participants were allowed to revise an initial estimate made under time pressure, but they were not given any additional hints whatsoever - so whil the treatment is expected to be positive with regard to time pressure/ cognitive load conditon, we would expect it to be ""neutral"" with regard to a neutral control condition)",yes,3,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_discordant,3,8,12,0.5,title_picture_pitch,source,accuracy,participants were asked the following question: “Do you think this headline describes an event that actually happened in an accurate way?” with the response options “Yes/No” ,1,1,binary,control,,,,,,,359,0.246,0.431,0.619,0.486,raw data,no
11,"Bago, B., Rand, D. G., & Pennycook, G. (2020). Fake news, fast and slow: Deliberation reduces belief in false (but not true) news headlines. Journal of Experimental Psychology: General, 149(8), 1608–1613. https://doi.org/10.1037/xge0000729",Bago 2020,,,"data correspond to politically laden (here, discordant) news results (corresponding to study 2 on OSF)
results from the two-response study; 
values are calculated based on provided data and cross-checked with Appendix, Table S3.;
we coded 'neutral' for treatment intention, since it should be quite similar to control conditions (participants were allowed to revise an initial estimate made under time pressure, but they were not given any additional hints whatsoever - so whil the treatment is expected to be positive with regard to time pressure/ cognitive load conditon, we would expect it to be ""neutral"" with regard to a neutral control condition)",yes,4,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_discordant,3,8,12,0.5,title_picture_pitch,source,accuracy,participants were asked the following question: “Do you think this headline describes an event that actually happened in an accurate way?” with the response options “Yes/No” ,1,1,binary,treatment,negative,multiple_timepressure_cognitiveload,"In the two-response experiment, participants made an initial response in which the extent of deliberation was minimized by having participants complete a load task (memorizing a pattern of five dots in a 4X4 matrix, see Bago & De Neys, 2019) and respond within 7 seconds (the average reading time in an N = 104 pre-test).",,,,653,0.333,0.471,0.567,0.496,raw data,no
11,"Bago, B., Rand, D. G., & Pennycook, G. (2020). Fake news, fast and slow: Deliberation reduces belief in false (but not true) news headlines. Journal of Experimental Psychology: General, 149(8), 1608–1613. https://doi.org/10.1037/xge0000729",Bago 2020,,,"data correspond to politically laden (here, discordant) news results (corresponding to study 2 on OSF)
results from the two-response study; 
values are calculated based on provided data and cross-checked with Appendix, Table S3.;
we coded 'neutral' for treatment intention, since it should be quite similar to control conditions (participants were allowed to revise an initial estimate made under time pressure, but they were not given any additional hints whatsoever - so whil the treatment is expected to be positive with regard to time pressure/ cognitive load conditon, we would expect it to be ""neutral"" with regard to a neutral control condition)",yes,4,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_discordant,3,8,12,0.5,title_picture_pitch,source,accuracy,participants were asked the following question: “Do you think this headline describes an event that actually happened in an accurate way?” with the response options “Yes/No” ,1,1,binary,treatment,neutral,revision_initial_estimate_under_time_pressure,"participants were presented with the same headline again they had rated under time pressure before – 
this time with no time deadline or cognitive load – and asked to give a final response.",,,,653,0.276,0.447,0.584,0.493,raw data,no
12,"Bago, B., Rosenzweig, L. R., Berinsky, A. J., & Rand, D. G. (2022). Emotion may predict susceptibility to fake news but emotion regulation does not seem to help. Cognition and Emotion, 1–15. https://doi.org/10.1080/02699931.2022.2090318",Bago 2022,yes,"study 1 has no intervention; for study 2, we merged the emotional re-appraisal and the emotional suppression condition, since both asked participants to react less ""emotionally"".","results are calculated based on raw data as published on the OSF repository https://osf.io/egy8p/ and correspond to those of Fig. 3 in paper;
study 1 in paper",yes,1,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_concordant,1,8,12,0.5,title_picture_pitch,source,accuracy,"For each headline, participants were asked the following question: “Do you think this headline accurately describes an event that actually happened?” with the response options “Yes/No”.",1,1,binary,control,,,,,,,998,0.167,0.373,0.562,0.496,raw data,no
12,"Bago, B., Rosenzweig, L. R., Berinsky, A. J., & Rand, D. G. (2022). Emotion may predict susceptibility to fake news but emotion regulation does not seem to help. Cognition and Emotion, 1–15. https://doi.org/10.1080/02699931.2022.2090318",Bago 2022,yes,"study 1 has no intervention; for study 2, we merged the emotional re-appraisal and the emotional suppression condition, since both asked participants to react less ""emotionally"".","results are calculated based on raw data as published on the OSF repository https://osf.io/egy8p/ and correspond to those of Fig. 3 in paper;
study 1 in paper",yes,1,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_concordant,1,8,12,0.5,title_picture_pitch,source,accuracy,"For each headline, participants were asked the following question: “Do you think this headline accurately describes an event that actually happened?” with the response options “Yes/No”.",1,1,binary,selected_by_correlate,,,,,emotional,when participants experienced any (at least one) of the six basic emotions in a given headline.,998,0.467,0.499,0.794,0.404,raw data,no
12,"Bago, B., Rosenzweig, L. R., Berinsky, A. J., & Rand, D. G. (2022). Emotion may predict susceptibility to fake news but emotion regulation does not seem to help. Cognition and Emotion, 1–15. https://doi.org/10.1080/02699931.2022.2090318",Bago 2022,yes,"study 1 has no intervention; for study 2, we merged the emotional re-appraisal and the emotional suppression condition, since both asked participants to react less ""emotionally"".","results are calculated based on raw data as published on the OSF repository https://osf.io/egy8p/ and correspond to those of Fig. 3 in paper;
study 1 in paper",yes,1,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_discordant,2,8,12,0.5,title_picture_pitch,source,accuracy,"For each headline, participants were asked the following question: “Do you think this headline accurately describes an event that actually happened?” with the response options “Yes/No”.",1,1,binary,control,,,,,,,998,0.134,0.341,0.5,0.5,raw data,no
12,"Bago, B., Rosenzweig, L. R., Berinsky, A. J., & Rand, D. G. (2022). Emotion may predict susceptibility to fake news but emotion regulation does not seem to help. Cognition and Emotion, 1–15. https://doi.org/10.1080/02699931.2022.2090318",Bago 2022,yes,"study 1 has no intervention; for study 2, we merged the emotional re-appraisal and the emotional suppression condition, since both asked participants to react less ""emotionally"".","results are calculated based on raw data as published on the OSF repository https://osf.io/egy8p/ and correspond to those of Fig. 3 in paper;
study 1 in paper",yes,1,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_discordant,2,8,12,0.5,title_picture_pitch,source,accuracy,"For each headline, participants were asked the following question: “Do you think this headline accurately describes an event that actually happened?” with the response options “Yes/No”.",1,1,binary,selected_by_correlate,,,,,emotional,when participants experienced any (at least one) of the six basic emotions in a given headline.,998,0.433,0.496,0.7,0.459,raw data,no
12,"Bago, B., Rosenzweig, L. R., Berinsky, A. J., & Rand, D. G. (2022). Emotion may predict susceptibility to fake news but emotion regulation does not seem to help. Cognition and Emotion, 1–15. https://doi.org/10.1080/02699931.2022.2090318",Bago 2022,yes,"study 1 has no intervention; for study 2, we merged the emotional re-appraisal and the emotional suppression condition, since both asked participants to react less ""emotionally"".","results are calculated based on raw data as published on the OSF repository https://osf.io/egy8p/ and correspond to those of Fig. 6 in paper;
study 2 in paper",yes,2,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_concordant,1,8,12,0.5,title_picture_pitch,source,accuracy,"For each headline, participants were asked the following question: “Do you think this headline accurately describes an event that actually happened?” with the response options “Yes/No”.",1,1,binary,control,,,,1,,,338,0.34,0.474,0.705,0.456,raw data,no
12,"Bago, B., Rosenzweig, L. R., Berinsky, A. J., & Rand, D. G. (2022). Emotion may predict susceptibility to fake news but emotion regulation does not seem to help. Cognition and Emotion, 1–15. https://doi.org/10.1080/02699931.2022.2090318",Bago 2022,yes,"study 1 has no intervention; for study 2, we merged the emotional re-appraisal and the emotional suppression condition, since both asked participants to react less ""emotionally"".","results are calculated based on raw data as published on the OSF repository https://osf.io/egy8p/ and correspond to those of Fig. 6 in paper;
study 2 in paper",yes,2,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_discordant,2,8,12,0.5,title_picture_pitch,source,accuracy,"For each headline, participants were asked the following question: “Do you think this headline accurately describes an event that actually happened?” with the response options “Yes/No”.",1,1,binary,control,,,,2,,,338,0.282,0.45,0.662,0.473,raw data,no
12,"Bago, B., Rosenzweig, L. R., Berinsky, A. J., & Rand, D. G. (2022). Emotion may predict susceptibility to fake news but emotion regulation does not seem to help. Cognition and Emotion, 1–15. https://doi.org/10.1080/02699931.2022.2090318",Bago 2022,yes,"study 1 has no intervention; for study 2, we merged the emotional re-appraisal and the emotional suppression condition, since both asked participants to react less ""emotionally"".","results are calculated based on raw data as published on the OSF repository https://osf.io/egy8p/ and correspond to those of Fig. 6 in paper;
study 2 in paper",yes,3,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_concordant,1,8,12,0.5,title_picture_pitch,source,accuracy,"For each headline, participants were asked the following question: “Do you think this headline accurately describes an event that actually happened?” with the response options “Yes/No”.",1,1,binary,treatment,,emotional_reappraisal,"We used the following instructions for the emotion reappraisal condition: As you view and read the headlines, please try to adopt a detached and unemotional attitude. Please try to think about what you are reading objectively. Read all of the headlines carefully, but please try to think about what you are seeing in such a way that you feel less emotion.",1,,,338,0.296,0.457,0.696,0.46,raw data,no
12,"Bago, B., Rosenzweig, L. R., Berinsky, A. J., & Rand, D. G. (2022). Emotion may predict susceptibility to fake news but emotion regulation does not seem to help. Cognition and Emotion, 1–15. https://doi.org/10.1080/02699931.2022.2090318",Bago 2022,yes,"study 1 has no intervention; for study 2, we merged the emotional re-appraisal and the emotional suppression condition, since both asked participants to react less ""emotionally"".","results are calculated based on raw data as published on the OSF repository https://osf.io/egy8p/ and correspond to those of Fig. 6 in paper;
study 2 in paper",yes,3,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_discordant,2,8,12,0.5,title_picture_pitch,source,accuracy,"For each headline, participants were asked the following question: “Do you think this headline accurately describes an event that actually happened?” with the response options “Yes/No”.",1,1,binary,treatment,,emotional_reappraisal,"We used the following instructions for the emotion reappraisal condition: As you view and read the headlines, please try to adopt a detached and unemotional attitude. Please try to think about what you are reading objectively. Read all of the headlines carefully, but please try to think about what you are seeing in such a way that you feel less emotion.",2,,,338,0.269,0.444,0.637,0.481,raw data,no
12,"Bago, B., Rosenzweig, L. R., Berinsky, A. J., & Rand, D. G. (2022). Emotion may predict susceptibility to fake news but emotion regulation does not seem to help. Cognition and Emotion, 1–15. https://doi.org/10.1080/02699931.2022.2090318",Bago 2022,yes,"study 1 has no intervention; for study 2, we merged the emotional re-appraisal and the emotional suppression condition, since both asked participants to react less ""emotionally"".","results are calculated based on raw data as published on the OSF repository https://osf.io/egy8p/ and correspond to those of Fig. 6 in paper;
study 2 in paper",yes,4,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_concordant,1,8,12,0.5,title_picture_pitch,source,accuracy,"For each headline, participants were asked the following question: “Do you think this headline accurately describes an event that actually happened?” with the response options “Yes/No”.",1,1,binary,treatment,,emotional_suppression,"We used the following instructions for the emotional suppression condition: As you view and read the headlines, if you have any feelings, please try your best not to let those feelings show. Read all of the headlines carefully, but try to behave so that someone watching you would not know that you are feeling anything at all.",1,,,331,0.285,0.452,0.717,0.451,raw data,no
12,"Bago, B., Rosenzweig, L. R., Berinsky, A. J., & Rand, D. G. (2022). Emotion may predict susceptibility to fake news but emotion regulation does not seem to help. Cognition and Emotion, 1–15. https://doi.org/10.1080/02699931.2022.2090318",Bago 2022,yes,"study 1 has no intervention; for study 2, we merged the emotional re-appraisal and the emotional suppression condition, since both asked participants to react less ""emotionally"".","results are calculated based on raw data as published on the OSF repository https://osf.io/egy8p/ and correspond to those of Fig. 6 in paper;
study 2 in paper",yes,4,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_discordant,2,8,12,0.5,title_picture_pitch,source,accuracy,"For each headline, participants were asked the following question: “Do you think this headline accurately describes an event that actually happened?” with the response options “Yes/No”.",1,1,binary,treatment,,emotional_suppression,"We used the following instructions for the emotional suppression condition: As you view and read the headlines, if you have any feelings, please try your best not to let those feelings show. Read all of the headlines carefully, but try to behave so that someone watching you would not know that you are feeling anything at all.",2,,,331,0.249,0.433,0.64,0.48,raw data,no
12,"Bago, B., Rosenzweig, L. R., Berinsky, A. J., & Rand, D. G. (2022). Emotion may predict susceptibility to fake news but emotion regulation does not seem to help. Cognition and Emotion, 1–15. https://doi.org/10.1080/02699931.2022.2090318",Bago 2022,yes,"study 1 has no intervention; for study 2, we merged the emotional re-appraisal and the emotional suppression condition, since both asked participants to react less ""emotionally"".","results are calculated based on raw data as published on the OSF repository https://osf.io/egy8p/ and correspond to those of Fig. 7 in paper;
study 3 in paper",yes,5,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_concordant,1,8,12,0.5,title_picture_pitch,source,accuracy,"For each headline, participants were asked the following question: “Do you think this headline accurately describes an event that actually happened?” with the response options “Yes/No”.",1,1,binary,control,,,,3,,,1499,0.293,0.455,0.709,0.454,raw data,no
12,"Bago, B., Rosenzweig, L. R., Berinsky, A. J., & Rand, D. G. (2022). Emotion may predict susceptibility to fake news but emotion regulation does not seem to help. Cognition and Emotion, 1–15. https://doi.org/10.1080/02699931.2022.2090318",Bago 2022,yes,"study 1 has no intervention; for study 2, we merged the emotional re-appraisal and the emotional suppression condition, since both asked participants to react less ""emotionally"".","results are calculated based on raw data as published on the OSF repository https://osf.io/egy8p/ and correspond to those of Fig. 7 in paper;
study 3 in paper",yes,5,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_discordant,2,8,12,0.5,title_picture_pitch,source,accuracy,"For each headline, participants were asked the following question: “Do you think this headline accurately describes an event that actually happened?” with the response options “Yes/No”.",1,1,binary,control,,,,4,,,1499,0.237,0.425,0.63,0.483,raw data,no
12,"Bago, B., Rosenzweig, L. R., Berinsky, A. J., & Rand, D. G. (2022). Emotion may predict susceptibility to fake news but emotion regulation does not seem to help. Cognition and Emotion, 1–15. https://doi.org/10.1080/02699931.2022.2090318",Bago 2022,yes,"study 1 has no intervention; for study 2, we merged the emotional re-appraisal and the emotional suppression condition, since both asked participants to react less ""emotionally"".","results are calculated based on raw data as published on the OSF repository https://osf.io/egy8p/ and correspond to those of Fig. 7 in paper;
study 3 in paper",yes,6,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_concordant,1,8,12,0.5,title_picture_pitch,source,accuracy,"For each headline, participants were asked the following question: “Do you think this headline accurately describes an event that actually happened?” with the response options “Yes/No”.",1,1,binary,treatment,,emotional_suppression,"We used the following instructions for the emotional suppression condition: As you view and read the headlines, if you have any feelings, please try your best not to let those feelings show. Read all of the headlines carefully, but try to behave so that someone watching you would not know that you are feeling anything at all.",3,,,1502,0.287,0.453,0.706,0.456,raw data,no
12,"Bago, B., Rosenzweig, L. R., Berinsky, A. J., & Rand, D. G. (2022). Emotion may predict susceptibility to fake news but emotion regulation does not seem to help. Cognition and Emotion, 1–15. https://doi.org/10.1080/02699931.2022.2090318",Bago 2022,yes,"study 1 has no intervention; for study 2, we merged the emotional re-appraisal and the emotional suppression condition, since both asked participants to react less ""emotionally"".","results are calculated based on raw data as published on the OSF repository https://osf.io/egy8p/ and correspond to those of Fig. 7 in paper;
study 3 in paper",yes,6,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_discordant,2,8,12,0.5,title_picture_pitch,source,accuracy,"For each headline, participants were asked the following question: “Do you think this headline accurately describes an event that actually happened?” with the response options “Yes/No”.",1,1,binary,treatment,,emotional_suppression,"We used the following instructions for the emotional suppression condition: As you view and read the headlines, if you have any feelings, please try your best not to let those feelings show. Read all of the headlines carefully, but try to behave so that someone watching you would not know that you are feeling anything at all.",4,,,1502,0.245,0.43,0.622,0.485,raw data,no
12,"Bago, B., Rosenzweig, L. R., Berinsky, A. J., & Rand, D. G. (2022). Emotion may predict susceptibility to fake news but emotion regulation does not seem to help. Cognition and Emotion, 1–15. https://doi.org/10.1080/02699931.2022.2090318",Bago 2022,yes,"study 1 has no intervention; for study 2, we merged the emotional re-appraisal and the emotional suppression condition, since both asked participants to react less ""emotionally"".","results are calculated based on raw data as published on the OSF repository https://osf.io/egy8p/ and correspond to those of Fig. 7 in paper;
study 4 in paper",yes,7,United States,within,yes,no,,recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_concordant,3,8,12,0.5,title_picture_pitch,source,accuracy,"For each headline, participants were asked the following question: “Do you think this headline accurately describes an event that actually happened?” with the response options “Yes/No”.",1,1,binary,control,,,,5,,,1512,0.187,0.39,0.796,0.403,raw data,no
12,"Bago, B., Rosenzweig, L. R., Berinsky, A. J., & Rand, D. G. (2022). Emotion may predict susceptibility to fake news but emotion regulation does not seem to help. Cognition and Emotion, 1–15. https://doi.org/10.1080/02699931.2022.2090318",Bago 2022,yes,"study 1 has no intervention; for study 2, we merged the emotional re-appraisal and the emotional suppression condition, since both asked participants to react less ""emotionally"".","results are calculated based on raw data as published on the OSF repository https://osf.io/egy8p/ and correspond to those of Fig. 7 in paper;
study 4 in paper",yes,7,United States,within,yes,no,,recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_discordant,4,8,12,0.5,title_picture_pitch,source,accuracy,"For each headline, participants were asked the following question: “Do you think this headline accurately describes an event that actually happened?” with the response options “Yes/No”.",1,1,binary,control,,,,6,,,1512,0.136,0.343,0.722,0.448,raw data,no
12,"Bago, B., Rosenzweig, L. R., Berinsky, A. J., & Rand, D. G. (2022). Emotion may predict susceptibility to fake news but emotion regulation does not seem to help. Cognition and Emotion, 1–15. https://doi.org/10.1080/02699931.2022.2090318",Bago 2022,yes,"study 1 has no intervention; for study 2, we merged the emotional re-appraisal and the emotional suppression condition, since both asked participants to react less ""emotionally"".","results are calculated based on raw data as published on the OSF repository https://osf.io/egy8p/ and correspond to those of Fig. 7 in paper;
study 4 in paper",yes,7,United States,within,yes,no,,recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_concordant,3,8,12,0.5,title_picture_pitch,source,accuracy,"For each headline, participants were asked the following question: “Do you think this headline accurately describes an event that actually happened?” with the response options “Yes/No”.",1,1,binary,treatment,,emotional_suppression,"We used the following instructions for the emotional suppression condition: As you view and read the headlines, if you have any feelings, please try your best not to let those feelings show. Read all of the headlines carefully, but try to behave so that someone watching you would not know that you are feeling anything at all.",5,,,1520,0.197,0.398,0.786,0.41,raw data,no
12,"Bago, B., Rosenzweig, L. R., Berinsky, A. J., & Rand, D. G. (2022). Emotion may predict susceptibility to fake news but emotion regulation does not seem to help. Cognition and Emotion, 1–15. https://doi.org/10.1080/02699931.2022.2090318",Bago 2022,yes,"study 1 has no intervention; for study 2, we merged the emotional re-appraisal and the emotional suppression condition, since both asked participants to react less ""emotionally"".","results are calculated based on raw data as published on the OSF repository https://osf.io/egy8p/ and correspond to those of Fig. 7 in paper;
study 4 in paper",yes,7,United States,within,yes,no,,recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_discordant,4,8,12,0.5,title_picture_pitch,source,accuracy,"For each headline, participants were asked the following question: “Do you think this headline accurately describes an event that actually happened?” with the response options “Yes/No”.",1,1,binary,treatment,,emotional_suppression,"We used the following instructions for the emotional suppression condition: As you view and read the headlines, if you have any feelings, please try your best not to let those feelings show. Read all of the headlines carefully, but try to behave so that someone watching you would not know that you are feeling anything at all.",6,,,1520,0.146,0.353,0.721,0.449,raw data,no
13,"Martel, C., Pennycook, G., & Rand, D. G. (2020). Reliance on emotion promotes belief in fake news. Cognitive Research: Principles and Implications, 5(1), 47. https://doi.org/10.1186/s41235-020-00252-3",Martel 2020,yes,"study 1 has no intervention; 
we do not consider the emotion induction condition (where participants are told to react emotionally) because the treatment is intended to reduce discernment. It is thus not a positively intended intervention. ","data correspond to study 1 in paper; results are taken from supplemental materials, Table S1
unclear whether the news headlines come entirely from the 2019 'Lazy not biased' study. The authors write: 
""Furthermore, half of the headlines were favorable to the Democratic Party and half were favorable to the Republican Party (based on ratings collected in a pretest, described in Pennycook and Rand 2019a).""",yes,1,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_balanced,1,20,32,0.5,title_picture_pitch,source,accuracy,"For each headline, participants were asked: “To the best of your knowledge, how accurate is the claim in the above headline” using a 4-point Likert-scale: 1 = Not at all accurate, 2 = Not very accurate, 3= Somewhat accurate, 4 = Very accurate.",1,1,4,control,,,,,,,409,1.62,0.47,2.84,0.44,paper,no
13,"Martel, C., Pennycook, G., & Rand, D. G. (2020). Reliance on emotion promotes belief in fake news. Cognitive Research: Principles and Implications, 5(1), 47. https://doi.org/10.1186/s41235-020-00252-3",Martel 2020,yes,"study 1 has no intervention; 
we do not consider the emotion induction condition (where participants are told to react emotionally) because the treatment is intended to reduce discernment. It is thus not a positively intended intervention. ","data correspond to study 2 in paper; results are taken from supplemental materials, Table S2
unclear whether the news headlines come entirely from the 2019 'Lazy not biased' study. The authors write: 
""Furthermore, half of the headlines were favorable to the Democratic Party and half were favorable to the Republican Party (based on ratings collected in a pretest, described in Pennycook and Rand 2019a).""

Study 2 analyzes a total of four experiments that shared a virtually identical experimental design. News items and sample size varied -- paper only allows to see aggregated measures; we report report three distinct (pooled) samples, each tested on politically_balanced and 12 news items (as in experiment 2 and 4) for simplicity; we sum the sample size of all experiments and divide them by 3 (i.e. the number of between-conditions)",yes,2,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_balanced,1,12,32,0.5,title_picture_pitch,source,accuracy,"For each headline, real or fake, perceived accuracy was assessed. Participants were asked: “How accurate is the claim in the above headline?” Likert-scale: 1 = Definitely false, 2 = Probably false, 3 = Possibly false, 4 = Possibly true, 5 = Probably true, 6 = Definitely true.",1,1,6,control,,,,1,,,1294.666667,2.66,0.9,4.2,0.73,paper,no
13,"Martel, C., Pennycook, G., & Rand, D. G. (2020). Reliance on emotion promotes belief in fake news. Cognitive Research: Principles and Implications, 5(1), 47. https://doi.org/10.1186/s41235-020-00252-3",Martel 2020,yes,"study 1 has no intervention; 
we do not consider the emotion induction condition (where participants are told to react emotionally) because the treatment is intended to reduce discernment. It is thus not a positively intended intervention. ","data correspond to study 2 in paper; results are taken from supplemental materials, Table S2
unclear whether the news headlines come entirely from the 2019 'Lazy not biased' study. The authors write: 
""Furthermore, half of the headlines were favorable to the Democratic Party and half were favorable to the Republican Party (based on ratings collected in a pretest, described in Pennycook and Rand 2019a).""

Study 2 analyzes a total of four experiments that shared a virtually identical experimental design. News items and sample size varied -- paper only allows to see aggregated measures; we report report three distinct (pooled) samples, each tested on politically_balanced and 12 news items (as in experiment 2 and 4) for simplicity; we sum the sample size of all experiments and divide them by 3 (i.e. the number of between-conditions)",yes,3,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_balanced,1,12,32,0.5,title_picture_pitch,source,accuracy,"For each headline, real or fake, perceived accuracy was assessed. Participants were asked: “How accurate is the claim in the above headline?” Likert-scale: 1 = Definitely false, 2 = Probably false, 3 = Possibly false, 4 = Possibly true, 5 = Probably true, 6 = Definitely true.",1,1,6,treatment,negative,emotion_induction,"“Many people believe that emotion leads to good decision-making. When we use feelings, rather than logic, we make emotionally satisfying decisions. Please assess the news headlines by relying on emotion, rather than reason.”",,,,1294.666667,2.75,0.92,4.22,0.74,paper,no
13,"Martel, C., Pennycook, G., & Rand, D. G. (2020). Reliance on emotion promotes belief in fake news. Cognitive Research: Principles and Implications, 5(1), 47. https://doi.org/10.1186/s41235-020-00252-3",Martel 2020,yes,"study 1 has no intervention; 
we do not consider the emotion induction condition (where participants are told to react emotionally) because the treatment is intended to reduce discernment. It is thus not a positively intended intervention. ","data correspond to study 2 in paper; results are taken from supplemental materials, Table S2
unclear whether the news headlines come entirely from the 2019 'Lazy not biased' study. The authors write: 
""Furthermore, half of the headlines were favorable to the Democratic Party and half were favorable to the Republican Party (based on ratings collected in a pretest, described in Pennycook and Rand 2019a).""

Study 2 analyzes a total of four experiments that shared a virtually identical experimental design. News items and sample size varied -- paper only allows to see aggregated measures; we report report three distinct (pooled) samples, each tested on politically_balanced and 12 news items (as in experiment 2 and 4) for simplicity; we sum the sample size of all experiments and divide them by 3 (i.e. the number of between-conditions)",yes,4,United States,within,yes,no,,recycled,"Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011",researchers,fact_checking,mainstream,politically_balanced,1,12,32,0.5,title_picture_pitch,source,accuracy,"For each headline, real or fake, perceived accuracy was assessed. Participants were asked: “How accurate is the claim in the above headline?” Likert-scale: 1 = Definitely false, 2 = Probably false, 3 = Possibly false, 4 = Possibly true, 5 = Probably true, 6 = Definitely true.",1,1,6,treatment,positive,reason_induction,"“Many people believe that reason leads to good decision-making. When we use logic, rather than feelings, we make rationally satisfying decisions. Please assess the news headlines by relying on reason, rather than emotion.”",1,,,1294.666667,2.66,0.92,4.24,0.73,paper,no
14,"Roozenbeek, J., Schneider, C. R., Dryhurst, S., Kerr, J., Freeman, A. L. J., Recchia, G., van der Bles, A. M., & van der Linden, S. (2020). Susceptibility to misinformation about COVID-19 around the world. Royal Society Open Science, 7(10), 201199. https://doi.org/10.1098/rsos.201199",Roozenbeek 2020,,,"data are from supplementary material, table S4
average results for all misinformation items are already reported;
for the two factual statements, we take the average; the ambiguous statement is ignored",yes,1,Ireland,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,8,,0.25,NA,NA,reliability,"participants were asked to rate the reliability of each of these statements on a 1–7 Likert scale, from ‘very unreliable’ (1) to ‘very reliable’ (7).",1,1,7,control,,,,,,,700,2.49,1.34,5.4,1.62,paper,no
14,"Roozenbeek, J., Schneider, C. R., Dryhurst, S., Kerr, J., Freeman, A. L. J., Recchia, G., van der Bles, A. M., & van der Linden, S. (2020). Susceptibility to misinformation about COVID-19 around the world. Royal Society Open Science, 7(10), 201199. https://doi.org/10.1098/rsos.201199",Roozenbeek 2020,,,"data are from supplementary material, table S4
average results for all misinformation items are already reported;
for the two factual statements, we take the average; the ambiguous statement is ignored",yes,2,Mexico,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,8,,0.25,NA,NA,reliability,"participants were asked to rate the reliability of each of these statements on a 1–7 Likert scale, from ‘very unreliable’ (1) to ‘very reliable’ (7).",1,1,7,control,,,,,,,700,2.79,1.38,5.49,1.66,paper,no
14,"Roozenbeek, J., Schneider, C. R., Dryhurst, S., Kerr, J., Freeman, A. L. J., Recchia, G., van der Bles, A. M., & van der Linden, S. (2020). Susceptibility to misinformation about COVID-19 around the world. Royal Society Open Science, 7(10), 201199. https://doi.org/10.1098/rsos.201199",Roozenbeek 2020,,,"data are from supplementary material, table S4
average results for all misinformation items are already reported;
for the two factual statements, we take the average; the ambiguous statement is ignored",yes,3,Spain,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,8,,0.25,NA,NA,reliability,"participants were asked to rate the reliability of each of these statements on a 1–7 Likert scale, from ‘very unreliable’ (1) to ‘very reliable’ (7).",1,1,7,control,,,,,,,700,2.67,1.34,5.06,1.705,paper,no
14,"Roozenbeek, J., Schneider, C. R., Dryhurst, S., Kerr, J., Freeman, A. L. J., Recchia, G., van der Bles, A. M., & van der Linden, S. (2020). Susceptibility to misinformation about COVID-19 around the world. Royal Society Open Science, 7(10), 201199. https://doi.org/10.1098/rsos.201199",Roozenbeek 2020,,,"data are from supplementary material, table S4
average results for all misinformation items are already reported;
for the two factual statements, we take the average; the ambiguous statement is ignored",yes,4,UK,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,8,,0.25,NA,NA,reliability,"participants were asked to rate the reliability of each of these statements on a 1–7 Likert scale, from ‘very unreliable’ (1) to ‘very reliable’ (7).",1,1,7,control,,,,,,,1050,2.31,1.25,5.205,1.635,paper,no
14,"Roozenbeek, J., Schneider, C. R., Dryhurst, S., Kerr, J., Freeman, A. L. J., Recchia, G., van der Bles, A. M., & van der Linden, S. (2020). Susceptibility to misinformation about COVID-19 around the world. Royal Society Open Science, 7(10), 201199. https://doi.org/10.1098/rsos.201199",Roozenbeek 2020,,,"data are from supplementary material, table S4
average results for all misinformation items are already reported;
for the two factual statements, we take the average; the ambiguous statement is ignored",yes,5,UK,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,8,,0.25,NA,NA,reliability,"participants were asked to rate the reliability of each of these statements on a 1–7 Likert scale, from ‘very unreliable’ (1) to ‘very reliable’ (7).",1,1,7,control,,,,,,,1150,2.32,1.3,5.275,1.58,paper,no
14,"Roozenbeek, J., Schneider, C. R., Dryhurst, S., Kerr, J., Freeman, A. L. J., Recchia, G., van der Bles, A. M., & van der Linden, S. (2020). Susceptibility to misinformation about COVID-19 around the world. Royal Society Open Science, 7(10), 201199. https://doi.org/10.1098/rsos.201199",Roozenbeek 2020,,,"data are from supplementary material, table S4
average results for all misinformation items are already reported;
for the two factual statements, we take the average; the ambiguous statement is ignored",yes,6,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,8,,0.25,NA,NA,reliability,"participants were asked to rate the reliability of each of these statements on a 1–7 Likert scale, from ‘very unreliable’ (1) to ‘very reliable’ (7).",1,1,7,control,,,,,,,700,2.36,1.28,5.41,1.495,paper,no
15,"Rosenzweig, L. R., Bago, B., Berinsky, A. J., & Rand, D. G. (2021). Happiness and surprise are associated with worse truth discernment of COVID-19 headlines among social media users in Nigeria. Harvard Kennedy School Misinformation Review. https://doi.org/10.37016/mr-2020-75",Rosenzweig 2021,,,"data of means from figure 1; SD are from table D2 in appendix as averages of 5 respective items per veracity (since not reported for emotional vs. neutral seperately, we report the same SD for the two)
Importantly, there were differences between the different emotions: 
Analyzing each distinct emotion’s correspondence with discernment, we find that happiness and surprise are both negatively and significantly associated with truth discernment. While happiness is associated with increased belief in both true and false headlines, this relationship is stronger for false than true (see left panel in Figure 2). Surprise, on the other hand, is associated with both increased belief in false headlines and reduced belief in true headlines. Similarly, happiness and surprise are also associated with greater likelihood of wanting to share false headlines, compared to true headlines.7 We do not find a robust relationship between these emotions, headline veracity, and clicking to read the story. The other four emotions we measured all have a positive correlation with discernment, as well as clicking and sharing more true, relative to false, headlines, but none of these relationships are statistically significant.",yes,1,Nigeria,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,10,,0.5,title_picture,source,accuracy,Belief was measured using the following question: “Do you think this headline accurately describes an event that actually happened?” All responses were binary—respondents could either answer “yes” or “no.”,1,1,binary,control,,,,,,,1341,0.452,0.472,0.749,0.274,paper,no
15,"Rosenzweig, L. R., Bago, B., Berinsky, A. J., & Rand, D. G. (2021). Happiness and surprise are associated with worse truth discernment of COVID-19 headlines among social media users in Nigeria. Harvard Kennedy School Misinformation Review. https://doi.org/10.37016/mr-2020-75",Rosenzweig 2021,,,"data of means from figure 1; SD are from table D2 in appendix as averages of 5 respective items per veracity (since not reported for emotional vs. neutral seperately, we report the same SD for the two)
Importantly, there were differences between the different emotions: 
Analyzing each distinct emotion’s correspondence with discernment, we find that happiness and surprise are both negatively and significantly associated with truth discernment. While happiness is associated with increased belief in both true and false headlines, this relationship is stronger for false than true (see left panel in Figure 2). Surprise, on the other hand, is associated with both increased belief in false headlines and reduced belief in true headlines. Similarly, happiness and surprise are also associated with greater likelihood of wanting to share false headlines, compared to true headlines.7 We do not find a robust relationship between these emotions, headline veracity, and clicking to read the story. The other four emotions we measured all have a positive correlation with discernment, as well as clicking and sharing more true, relative to false, headlines, but none of these relationships are statistically significant.",yes,1,Nigeria,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,10,,0.5,title_picture,source,accuracy,Belief was measured using the following question: “Do you think this headline accurately describes an event that actually happened?” All responses were binary—respondents could either answer “yes” or “no.”,1,1,binary,selected_by_correlate,,,,,emotional,"cases in which respondents reported feeling any of the six distinct emotions presented (anger, fear, sadness, happiness, surprise, and disgust).",1341,0.684,0.472,0.892,0.274,paper,no
16,"Brashier, N. M., Pennycook, G., Berinsky, A. J., & Rand, D. G. (2021). Timing matters when correcting fake news. Proceedings of the National Academy of Sciences, 118(5), e2020043118. https://doi.org/10.1073/pnas.2020043118",Brashier 2021,yes,"they also test the long-term effects (1 week later) of their interventions - we do not consider this data; we do also not consider familiarization conditions (where participants were merely exposed to the same headlines before); we focus on the tags intervention, were ""true"" and ""false"" tags were put on items; we merge the ""before"" and ""during"" tag conditions, but exclude the ""after"" tag condition, since it can only possibly have a long term effect on the second wave. ","data correspond to experiment 1; values calculated based on data available on OSF (first, i.e. 'initial' wave);
Two-wave panel design: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags. One week later, all participants judged the same 36 headlines for accuracy, this time with no veracity information.
weird: in their text, they write about the sample size: ""In two experiments (total N = 2,683)"". We find an overal sample size of 3268 (1612 experiment 1, 1656 experiment 2). This matches their pre-registration",yes,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,36,,0.5,title_picture,source,accuracy,participants evaluated the accuracy of these 36 headlines on a scale from 1 (not at all accurate) to 4 (very accurate).,1,0,4,control,,,1,,,,406,1.55,0.53,2.9,0.47,raw data,panel
16,"Brashier, N. M., Pennycook, G., Berinsky, A. J., & Rand, D. G. (2021). Timing matters when correcting fake news. Proceedings of the National Academy of Sciences, 118(5), e2020043118. https://doi.org/10.1073/pnas.2020043118",Brashier 2021,yes,"they also test the long-term effects (1 week later) of their interventions - we do not consider this data; we do also not consider familiarization conditions (where participants were merely exposed to the same headlines before); we focus on the tags intervention, were ""true"" and ""false"" tags were put on items; we merge the ""before"" and ""during"" tag conditions, but exclude the ""after"" tag condition, since it can only possibly have a long term effect on the second wave. ","data correspond to experiment 1; values calculated based on data available on OSF (second, i.e. 'final' wave);
Two-wave panel design: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags. One week later, all participants judged the same 36 headlines for accuracy, this time with no veracity information.
weird: in their text, they write about the sample size: ""In two experiments (total N = 2,683)"". We find an overal sample size of 3268 (1612 experiment 1, 1656 experiment 2). This matches their pre-registration",yes,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,36,,0.5,title_picture,source,accuracy,participants evaluated the accuracy of these 36 headlines on a scale from 1 (not at all accurate) to 4 (very accurate).,1,0,4,treatment,neutral,familiarization,"in the second wave, participants would see the same headlines they saw the week before;
as far as we can tell, participants have not been given any feedback in the first wave - hence we code treatment_intention as neutral",,,,337,1.48,0.477,2.93,0.498,raw data,panel
16,"Brashier, N. M., Pennycook, G., Berinsky, A. J., & Rand, D. G. (2021). Timing matters when correcting fake news. Proceedings of the National Academy of Sciences, 118(5), e2020043118. https://doi.org/10.1073/pnas.2020043118",Brashier 2021,yes,"they also test the long-term effects (1 week later) of their interventions - we do not consider this data; we do also not consider familiarization conditions (where participants were merely exposed to the same headlines before); we focus on the tags intervention, were ""true"" and ""false"" tags were put on items; we merge the ""before"" and ""during"" tag conditions, but exclude the ""after"" tag condition, since it can only possibly have a long term effect on the second wave. ","data correspond to experiment 1; values calculated based on data available on OSF (first, i.e. 'initial' wave);
Two-wave panel design: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags. One week later, all participants judged the same 36 headlines for accuracy, this time with no veracity information.
weird: in their text, they write about the sample size: ""In two experiments (total N = 2,683)"". We find an overal sample size of 3268 (1612 experiment 1, 1656 experiment 2). This matches their pre-registration",yes,2,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,36,,0.5,title_picture,source,accuracy,participants evaluated the accuracy of these 36 headlines on a scale from 1 (not at all accurate) to 4 (very accurate).,1,0,4,treatment,positive,accuracy_tag_before,1,,,,404,1.49,0.557,3.32,0.471,raw data,panel
16,"Brashier, N. M., Pennycook, G., Berinsky, A. J., & Rand, D. G. (2021). Timing matters when correcting fake news. Proceedings of the National Academy of Sciences, 118(5), e2020043118. https://doi.org/10.1073/pnas.2020043118",Brashier 2021,yes,"they also test the long-term effects (1 week later) of their interventions - we do not consider this data; we do also not consider familiarization conditions (where participants were merely exposed to the same headlines before); we focus on the tags intervention, were ""true"" and ""false"" tags were put on items; we merge the ""before"" and ""during"" tag conditions, but exclude the ""after"" tag condition, since it can only possibly have a long term effect on the second wave. ","data correspond to experiment 1; values calculated based on data available on OSF (second, i.e. 'final' wave);
Two-wave panel design: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags. One week later, all participants judged the same 36 headlines for accuracy, this time with no veracity information.
weird: in their text, they write about the sample size: ""In two experiments (total N = 2,683)"". We find an overal sample size of 3268 (1612 experiment 1, 1656 experiment 2). This matches their pre-registration",yes,2,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,36,,0.5,title_picture,source,accuracy,participants evaluated the accuracy of these 36 headlines on a scale from 1 (not at all accurate) to 4 (very accurate).,1,0,4,treatment,positive,multiple_1weekbeforeaccuracytagbefore_familiarization,"~1 week before participants received the following treatment: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags.;
participants would see the same headlines they saw the week before, but without any tags",,,,342,1.59,0.559,3.01,0.47,raw data,panel
16,"Brashier, N. M., Pennycook, G., Berinsky, A. J., & Rand, D. G. (2021). Timing matters when correcting fake news. Proceedings of the National Academy of Sciences, 118(5), e2020043118. https://doi.org/10.1073/pnas.2020043118",Brashier 2021,yes,"they also test the long-term effects (1 week later) of their interventions - we do not consider this data; we do also not consider familiarization conditions (where participants were merely exposed to the same headlines before); we focus on the tags intervention, were ""true"" and ""false"" tags were put on items; we merge the ""before"" and ""during"" tag conditions, but exclude the ""after"" tag condition, since it can only possibly have a long term effect on the second wave. ","data correspond to experiment 1; values calculated based on data available on OSF (first, i.e. 'initial' wave);
Two-wave panel design: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags. One week later, all participants judged the same 36 headlines for accuracy, this time with no veracity information.
weird: in their text, they write about the sample size: ""In two experiments (total N = 2,683)"". We find an overal sample size of 3268 (1612 experiment 1, 1656 experiment 2). This matches their pre-registration",yes,3,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,36,,0.5,title_picture,source,accuracy,participants evaluated the accuracy of these 36 headlines on a scale from 1 (not at all accurate) to 4 (very accurate).,1,0,4,treatment,positive,accuracy_tag_during,1,,,,397,1.36,0.571,3.53,0.439,raw data,panel
16,"Brashier, N. M., Pennycook, G., Berinsky, A. J., & Rand, D. G. (2021). Timing matters when correcting fake news. Proceedings of the National Academy of Sciences, 118(5), e2020043118. https://doi.org/10.1073/pnas.2020043118",Brashier 2021,yes,"they also test the long-term effects (1 week later) of their interventions - we do not consider this data; we do also not consider familiarization conditions (where participants were merely exposed to the same headlines before); we focus on the tags intervention, were ""true"" and ""false"" tags were put on items; we merge the ""before"" and ""during"" tag conditions, but exclude the ""after"" tag condition, since it can only possibly have a long term effect on the second wave. ","data correspond to experiment 1; values calculated based on data available on OSF (second, i.e. 'final' wave);
Two-wave panel design: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags. One week later, all participants judged the same 36 headlines for accuracy, this time with no veracity information.
weird: in their text, they write about the sample size: ""In two experiments (total N = 2,683)"". We find an overal sample size of 3268 (1612 experiment 1, 1656 experiment 2). This matches their pre-registration",yes,3,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,36,,0.5,title_picture,source,accuracy,participants evaluated the accuracy of these 36 headlines on a scale from 1 (not at all accurate) to 4 (very accurate).,1,0,4,treatment,positive,multiple_1weekbeforeaccuracytagduring_familiarization,"~1 week before participants received the following treatment: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags.; participants would see the same headlines they saw the week before, but without any tags",,,,325,1.39,0.45,3.03,0.456,raw data,panel
16,"Brashier, N. M., Pennycook, G., Berinsky, A. J., & Rand, D. G. (2021). Timing matters when correcting fake news. Proceedings of the National Academy of Sciences, 118(5), e2020043118. https://doi.org/10.1073/pnas.2020043118",Brashier 2021,yes,"they also test the long-term effects (1 week later) of their interventions - we do not consider this data; we do also not consider familiarization conditions (where participants were merely exposed to the same headlines before); we focus on the tags intervention, were ""true"" and ""false"" tags were put on items; we merge the ""before"" and ""during"" tag conditions, but exclude the ""after"" tag condition, since it can only possibly have a long term effect on the second wave. ","data correspond to experiment 1; values calculated based on data available on OSF (first, i.e. 'initial' wave);
Two-wave panel design: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags. One week later, all participants judged the same 36 headlines for accuracy, this time with no veracity information.
weird: in their text, they write about the sample size: ""In two experiments (total N = 2,683)"". We find an overal sample size of 3268 (1612 experiment 1, 1656 experiment 2). This matches their pre-registration",yes,4,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,36,,0.5,title_picture,source,accuracy,participants evaluated the accuracy of these 36 headlines on a scale from 1 (not at all accurate) to 4 (very accurate).,1,0,4,treatment,positive,accuracy_tag_after,"In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags.;
We code positive here as a direction although participants received the tag ""after"" rating a news item, becasue there is reason to assume that it still affects participants subsequent news ratings",,,,405,1.6,0.484,3.16,0.421,raw data,panel
16,"Brashier, N. M., Pennycook, G., Berinsky, A. J., & Rand, D. G. (2021). Timing matters when correcting fake news. Proceedings of the National Academy of Sciences, 118(5), e2020043118. https://doi.org/10.1073/pnas.2020043118",Brashier 2021,yes,"they also test the long-term effects (1 week later) of their interventions - we do not consider this data; we do also not consider familiarization conditions (where participants were merely exposed to the same headlines before); we focus on the tags intervention, were ""true"" and ""false"" tags were put on items; we merge the ""before"" and ""during"" tag conditions, but exclude the ""after"" tag condition, since it can only possibly have a long term effect on the second wave. ","data correspond to experiment 1; values calculated based on data available on OSF (second, i.e. 'final' wave);
Two-wave panel design: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags. One week later, all participants judged the same 36 headlines for accuracy, this time with no veracity information.
weird: in their text, they write about the sample size: ""In two experiments (total N = 2,683)"". We find an overal sample size of 3268 (1612 experiment 1, 1656 experiment 2). This matches their pre-registration",yes,4,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,36,,0.5,title_picture,source,accuracy,participants evaluated the accuracy of these 36 headlines on a scale from 1 (not at all accurate) to 4 (very accurate).,1,0,4,treatment,positive,multiple_1weekbeforeaccuracytagafter_familiarization,"~1 week before participants received the following treatment: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags.; participants would see the same headlines they saw the week before, but without any tags",,,,346,1.36,0.454,3.19,0.513,raw data,panel
16,"Brashier, N. M., Pennycook, G., Berinsky, A. J., & Rand, D. G. (2021). Timing matters when correcting fake news. Proceedings of the National Academy of Sciences, 118(5), e2020043118. https://doi.org/10.1073/pnas.2020043118",Brashier 2021,yes,"they also test the long-term effects (1 week later) of their interventions - we do not consider this data; we do also not consider familiarization conditions (where participants were merely exposed to the same headlines before); we focus on the tags intervention, were ""true"" and ""false"" tags were put on items; we merge the ""before"" and ""during"" tag conditions, but exclude the ""after"" tag condition, since it can only possibly have a long term effect on the second wave. ","data correspond to experiment 2; values calculated based on data available on OSF (first, i.e. 'initial' wave);
Two-wave panel design: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags. One week later, all participants judged the same 36 headlines for accuracy, this time with no veracity information.
weird: in their text, they write about the sample size: ""In two experiments (total N = 2,683)"". We find an overal sample size of 3268 (1612 experiment 1, 1656 experiment 2). This matches their pre-registration",yes,5,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,36,,0.5,title_picture,source,accuracy,participants evaluated the accuracy of these 36 headlines on a scale from 1 (not at all accurate) to 4 (very accurate).,1,0,4,control,,,2,,,,406,1.7,0.686,2.95,0.436,raw data,panel
16,"Brashier, N. M., Pennycook, G., Berinsky, A. J., & Rand, D. G. (2021). Timing matters when correcting fake news. Proceedings of the National Academy of Sciences, 118(5), e2020043118. https://doi.org/10.1073/pnas.2020043118",Brashier 2021,yes,"they also test the long-term effects (1 week later) of their interventions - we do not consider this data; we do also not consider familiarization conditions (where participants were merely exposed to the same headlines before); we focus on the tags intervention, were ""true"" and ""false"" tags were put on items; we merge the ""before"" and ""during"" tag conditions, but exclude the ""after"" tag condition, since it can only possibly have a long term effect on the second wave. ","data correspond to experiment 2; values calculated based on data available on OSF (second, i.e. 'final' wave);
Two-wave panel design: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags. One week later, all participants judged the same 36 headlines for accuracy, this time with no veracity information.
weird: in their text, they write about the sample size: ""In two experiments (total N = 2,683)"". We find an overal sample size of 3268 (1612 experiment 1, 1656 experiment 2). This matches their pre-registration",yes,5,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,36,,0.5,title_picture,source,accuracy,participants evaluated the accuracy of these 36 headlines on a scale from 1 (not at all accurate) to 4 (very accurate).,1,0,4,treatment,neutral,familiarization,"in the second wave, participants would see the same headlines they saw the week before;
as far as we can tell, participants have not been given any feedback in the first wave - hence we code treatment_intention as neutral",,,,324,1.62,0.626,2.94,0.478,raw data,panel
16,"Brashier, N. M., Pennycook, G., Berinsky, A. J., & Rand, D. G. (2021). Timing matters when correcting fake news. Proceedings of the National Academy of Sciences, 118(5), e2020043118. https://doi.org/10.1073/pnas.2020043118",Brashier 2021,yes,"they also test the long-term effects (1 week later) of their interventions - we do not consider this data; we do also not consider familiarization conditions (where participants were merely exposed to the same headlines before); we focus on the tags intervention, were ""true"" and ""false"" tags were put on items; we merge the ""before"" and ""during"" tag conditions, but exclude the ""after"" tag condition, since it can only possibly have a long term effect on the second wave. ","data correspond to experiment 2; values calculated based on data available on OSF (first, i.e. 'initial' wave);
Two-wave panel design: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags. One week later, all participants judged the same 36 headlines for accuracy, this time with no veracity information.
weird: in their text, they write about the sample size: ""In two experiments (total N = 2,683)"". We find an overal sample size of 3268 (1612 experiment 1, 1656 experiment 2). This matches their pre-registration",yes,6,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,36,,0.5,title_picture,source,accuracy,participants evaluated the accuracy of these 36 headlines on a scale from 1 (not at all accurate) to 4 (very accurate).,1,0,4,treatment,positive,accuracy_tag_before,2,,,,411,1.51,0.685,3.34,0.493,raw data,panel
16,"Brashier, N. M., Pennycook, G., Berinsky, A. J., & Rand, D. G. (2021). Timing matters when correcting fake news. Proceedings of the National Academy of Sciences, 118(5), e2020043118. https://doi.org/10.1073/pnas.2020043118",Brashier 2021,yes,"they also test the long-term effects (1 week later) of their interventions - we do not consider this data; we do also not consider familiarization conditions (where participants were merely exposed to the same headlines before); we focus on the tags intervention, were ""true"" and ""false"" tags were put on items; we merge the ""before"" and ""during"" tag conditions, but exclude the ""after"" tag condition, since it can only possibly have a long term effect on the second wave. ","data correspond to experiment 2; values calculated based on data available on OSF (second, i.e. 'final' wave);
Two-wave panel design: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags. One week later, all participants judged the same 36 headlines for accuracy, this time with no veracity information.
weird: in their text, they write about the sample size: ""In two experiments (total N = 2,683)"". We find an overal sample size of 3268 (1612 experiment 1, 1656 experiment 2). This matches their pre-registration",yes,6,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,36,,0.5,title_picture,source,accuracy,participants evaluated the accuracy of these 36 headlines on a scale from 1 (not at all accurate) to 4 (very accurate).,1,0,4,treatment,positive,multiple_1weekbeforeaccuracytagbefore_familiarization,"~1 week before participants received the following treatment: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags.;
participants would see the same headlines they saw the week before, but without any tags",,,,326,1.58,0.658,3.03,0.506,raw data,panel
16,"Brashier, N. M., Pennycook, G., Berinsky, A. J., & Rand, D. G. (2021). Timing matters when correcting fake news. Proceedings of the National Academy of Sciences, 118(5), e2020043118. https://doi.org/10.1073/pnas.2020043118",Brashier 2021,yes,"they also test the long-term effects (1 week later) of their interventions - we do not consider this data; we do also not consider familiarization conditions (where participants were merely exposed to the same headlines before); we focus on the tags intervention, were ""true"" and ""false"" tags were put on items; we merge the ""before"" and ""during"" tag conditions, but exclude the ""after"" tag condition, since it can only possibly have a long term effect on the second wave. ","data correspond to experiment 2; values calculated based on data available on OSF (first, i.e. 'initial' wave);
Two-wave panel design: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags. One week later, all participants judged the same 36 headlines for accuracy, this time with no veracity information.
weird: in their text, they write about the sample size: ""In two experiments (total N = 2,683)"". We find an overal sample size of 3268 (1612 experiment 1, 1656 experiment 2). This matches their pre-registration",yes,7,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,36,,0.5,title_picture,source,accuracy,participants evaluated the accuracy of these 36 headlines on a scale from 1 (not at all accurate) to 4 (very accurate).,1,0,4,treatment,positive,accuracy_tag_during,2,,,,422,1.42,0.637,3.47,0.444,raw data,panel
16,"Brashier, N. M., Pennycook, G., Berinsky, A. J., & Rand, D. G. (2021). Timing matters when correcting fake news. Proceedings of the National Academy of Sciences, 118(5), e2020043118. https://doi.org/10.1073/pnas.2020043118",Brashier 2021,yes,"they also test the long-term effects (1 week later) of their interventions - we do not consider this data; we do also not consider familiarization conditions (where participants were merely exposed to the same headlines before); we focus on the tags intervention, were ""true"" and ""false"" tags were put on items; we merge the ""before"" and ""during"" tag conditions, but exclude the ""after"" tag condition, since it can only possibly have a long term effect on the second wave. ","data correspond to experiment 2; values calculated based on data available on OSF (second, i.e. 'final' wave);
Two-wave panel design: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags. One week later, all participants judged the same 36 headlines for accuracy, this time with no veracity information.
weird: in their text, they write about the sample size: ""In two experiments (total N = 2,683)"". We find an overal sample size of 3268 (1612 experiment 1, 1656 experiment 2). This matches their pre-registration",yes,7,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,36,,0.5,title_picture,source,accuracy,participants evaluated the accuracy of these 36 headlines on a scale from 1 (not at all accurate) to 4 (very accurate).,1,0,4,treatment,positive,multiple_1weekbeforeaccuracytagduring_familiarization,"~1 week before participants received the following treatment: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags.; participants would see the same headlines they saw the week before, but without any tags",,,,345,1.54,0.645,2.98,0.513,raw data,panel
16,"Brashier, N. M., Pennycook, G., Berinsky, A. J., & Rand, D. G. (2021). Timing matters when correcting fake news. Proceedings of the National Academy of Sciences, 118(5), e2020043118. https://doi.org/10.1073/pnas.2020043118",Brashier 2021,yes,"they also test the long-term effects (1 week later) of their interventions - we do not consider this data; we do also not consider familiarization conditions (where participants were merely exposed to the same headlines before); we focus on the tags intervention, were ""true"" and ""false"" tags were put on items; we merge the ""before"" and ""during"" tag conditions, but exclude the ""after"" tag condition, since it can only possibly have a long term effect on the second wave. ","data correspond to experiment 2; values calculated based on data available on OSF (first, i.e. 'initial' wave);
Two-wave panel design: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags. One week later, all participants judged the same 36 headlines for accuracy, this time with no veracity information.
weird: in their text, they write about the sample size: ""In two experiments (total N = 2,683)"". We find an overal sample size of 3268 (1612 experiment 1, 1656 experiment 2). This matches their pre-registration",yes,8,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,36,,0.5,title_picture,source,accuracy,participants evaluated the accuracy of these 36 headlines on a scale from 1 (not at all accurate) to 4 (very accurate).,1,0,4,treatment,positive,accuracy_tag_after,"In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags.;
We code positive here as a direction although participants received the tag ""after"" rating a news item, becasue there is reason to assume that it still affects participants subsequent news ratings",,,,417,1.7,0.653,3.16,0.451,raw data,panel
16,"Brashier, N. M., Pennycook, G., Berinsky, A. J., & Rand, D. G. (2021). Timing matters when correcting fake news. Proceedings of the National Academy of Sciences, 118(5), e2020043118. https://doi.org/10.1073/pnas.2020043118",Brashier 2021,yes,"they also test the long-term effects (1 week later) of their interventions - we do not consider this data; we do also not consider familiarization conditions (where participants were merely exposed to the same headlines before); we focus on the tags intervention, were ""true"" and ""false"" tags were put on items; we merge the ""before"" and ""during"" tag conditions, but exclude the ""after"" tag condition, since it can only possibly have a long term effect on the second wave. ","data correspond to experiment 2; values calculated based on data available on OSF (second, i.e. 'final' wave);
Two-wave panel design: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags. One week later, all participants judged the same 36 headlines for accuracy, this time with no veracity information.
weird: in their text, they write about the sample size: ""In two experiments (total N = 2,683)"". We find an overal sample size of 3268 (1612 experiment 1, 1656 experiment 2). This matches their pre-registration",yes,8,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,36,,0.5,title_picture,source,accuracy,participants evaluated the accuracy of these 36 headlines on a scale from 1 (not at all accurate) to 4 (very accurate).,1,0,4,treatment,positive,multiple_1weekbeforeaccuracytagafter_familiarization,"~1 week before participants received the following treatment: In the treatment conditions, participants saw “true” and “false” tags immediately before, during, or immediately after reading. In the control condition, participants rated the headlines alone, with no tags.; participants would see the same headlines they saw the week before, but without any tags",,,,338,1.49,0.677,3.25,0.51,raw data,panel
17,"Calvillo, D. P., & Smelter, T. J. (2020). An initial accuracy focus reduces the effect of prior exposure on perceived accuracy of news headlines. Cognitive Research: Principles and Implications, 5(1), 55. https://doi.org/10.1186/s41235-020-00257-y",Calvillo 2020,,,"data correspond to experiment 1, interest prime condition, new news items; values based on own calculations (cross-checked with means from table 1)",yes,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,anything,1,16,,0.5,title_picture,nosource,accuracy,"Immediately after initial ratings, participants rated the accuracy of all 32 headlines (for 16 they had made previous ratings and the other 16 were new) on a 4-point scale from not at all accurate to very accurate.",1,0,4,treatment,negative,interest_prime,"Some participants initially rated how interesting a subset of headlines were (interest_prime), whereas other participants rated how truthful they were (accuracy prime). All participants then rated the accuracy of a larger set of headlines that included the previously rated and new headlines.",,,,85,2.23,0.585,2.65,0.543,raw data,no
17,"Calvillo, D. P., & Smelter, T. J. (2020). An initial accuracy focus reduces the effect of prior exposure on perceived accuracy of news headlines. Cognitive Research: Principles and Implications, 5(1), 55. https://doi.org/10.1186/s41235-020-00257-y",Calvillo 2020,,,"data correspond to experiment 1, interest prime condition, familiarized news items; values based on own calculations (cross-checked with means from table 1)",yes,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,anything,2,16,,0.5,title_picture,nosource,accuracy,"Immediately after initial ratings, participants rated the accuracy of all 32 headlines (for 16 they had made previous ratings and the other 16 were new) on a 4-point scale from not at all accurate to very accurate.",1,0,4,treatment,negative,multiple_interestprime_familiarization,"Some participants initially rated how interesting a subset of headlines were (interest_prime), whereas other participants rated how truthful they were (accuracy prime). All participants then rated the accuracy of a larger set of headlines that included the previously rated and new headlines.",,,,85,2.3,0.604,2.87,0.496,raw data,no
17,"Calvillo, D. P., & Smelter, T. J. (2020). An initial accuracy focus reduces the effect of prior exposure on perceived accuracy of news headlines. Cognitive Research: Principles and Implications, 5(1), 55. https://doi.org/10.1186/s41235-020-00257-y",Calvillo 2020,,,"data correspond to experiment 1, accuracy/truthfulness prime condition, new news items; values based on own calculations (cross-checked with means from table 1)",yes,2,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,anything,1,16,,0.5,title_picture,nosource,accuracy,"Immediately after initial ratings, participants rated the accuracy of all 32 headlines (for 16 they had made previous ratings and the other 16 were new) on a 4-point scale from not at all accurate to very accurate.",1,0,4,treatment,positive,accuracy_prime,"Some participants initially rated how interesting a subset of headlines were (interest_prime), whereas other participants rated how truthful they were (accuracy prime). All participants then rated the accuracy of a larger set of headlines that included the previously rated and new headlines.",,,,87,2.27,0.593,2.76,0.521,raw data,no
17,"Calvillo, D. P., & Smelter, T. J. (2020). An initial accuracy focus reduces the effect of prior exposure on perceived accuracy of news headlines. Cognitive Research: Principles and Implications, 5(1), 55. https://doi.org/10.1186/s41235-020-00257-y",Calvillo 2020,,,"data correspond to experiment 1, accuracy/truthfulness prime condition, familiarized news items; values based on own calculations (cross-checked with means from table 1)",yes,2,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,anything,2,16,,0.5,title_picture,nosource,accuracy,"Immediately after initial ratings, participants rated the accuracy of all 32 headlines (for 16 they had made previous ratings and the other 16 were new) on a 4-point scale from not at all accurate to very accurate.",1,0,4,treatment,positive,multiple_accuracyprime_familiarization,"Some participants initially rated how interesting a subset of headlines were (interest_prime), whereas other participants rated how truthful they were (accuracy prime). All participants then rated the accuracy of a larger set of headlines that included the previously rated and new headlines.",,,,87,2.29,0.543,2.81,0.468,raw data,no
17,"Calvillo, D. P., & Smelter, T. J. (2020). An initial accuracy focus reduces the effect of prior exposure on perceived accuracy of news headlines. Cognitive Research: Principles and Implications, 5(1), 55. https://doi.org/10.1186/s41235-020-00257-y",Calvillo 2020,,,"data correspond to experiment 2, interest prime condition, new news items, politically concordant items; values based on own calculations ",yes,3,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_concordant,3,8,,0.5,title_picture,nosource,accuracy,"Immediately after initial ratings, participants rated the accuracy of all 32 headlines (for 16 they had made previous ratings and the other 16 were new) on a 4-point scale from not at all accurate to very accurate.",1,0,4,treatment,negative,interest_prime,"Some participants initially rated how interesting a subset of headlines were (interest_prime), whereas other participants rated how truthful they were (accuracy prime). All participants then rated the accuracy of a larger set of headlines that included the previously rated and new headlines.",,,,145,2.39,0.666,3.03,0.638,raw data,no
17,"Calvillo, D. P., & Smelter, T. J. (2020). An initial accuracy focus reduces the effect of prior exposure on perceived accuracy of news headlines. Cognitive Research: Principles and Implications, 5(1), 55. https://doi.org/10.1186/s41235-020-00257-y",Calvillo 2020,,,"data correspond to experiment 2, interest prime condition, new news items, politically discordant items; values based on own calculations ",yes,3,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_discordant,4,8,,0.5,title_picture,nosource,accuracy,"Immediately after initial ratings, participants rated the accuracy of all 32 headlines (for 16 they had made previous ratings and the other 16 were new) on a 4-point scale from not at all accurate to very accurate.",1,0,4,treatment,negative,interest_prime,"Some participants initially rated how interesting a subset of headlines were (interest_prime), whereas other participants rated how truthful they were (accuracy prime). All participants then rated the accuracy of a larger set of headlines that included the previously rated and new headlines.",,,,145,1.78,0.557,2.54,0.631,raw data,no
17,"Calvillo, D. P., & Smelter, T. J. (2020). An initial accuracy focus reduces the effect of prior exposure on perceived accuracy of news headlines. Cognitive Research: Principles and Implications, 5(1), 55. https://doi.org/10.1186/s41235-020-00257-y",Calvillo 2020,,,"data correspond to experiment 2, interest prime condition, familiarized news items, politically concordant items; values based on own calculations ",yes,3,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_concordant,5,8,,0.5,title_picture,nosource,accuracy,"Immediately after initial ratings, participants rated the accuracy of all 32 headlines (for 16 they had made previous ratings and the other 16 were new) on a 4-point scale from not at all accurate to very accurate.",1,0,4,treatment,negative,multiple_interestprime_familiarization,"Some participants initially rated how interesting a subset of headlines were (interest_prime), whereas other participants rated how truthful they were (accuracy prime). All participants then rated the accuracy of a larger set of headlines that included the previously rated and new headlines.",,,,145,2.62,0.685,3.16,0.51,raw data,no
17,"Calvillo, D. P., & Smelter, T. J. (2020). An initial accuracy focus reduces the effect of prior exposure on perceived accuracy of news headlines. Cognitive Research: Principles and Implications, 5(1), 55. https://doi.org/10.1186/s41235-020-00257-y",Calvillo 2020,,,"data correspond to experiment 2, interest prime condition, familiarized news items, politically discordant items; values based on own calculations ",yes,3,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_discordant,6,8,,0.5,title_picture,nosource,accuracy,"Immediately after initial ratings, participants rated the accuracy of all 32 headlines (for 16 they had made previous ratings and the other 16 were new) on a 4-point scale from not at all accurate to very accurate.",1,0,4,treatment,negative,multiple_interestprime_familiarization,"Some participants initially rated how interesting a subset of headlines were (interest_prime), whereas other participants rated how truthful they were (accuracy prime). All participants then rated the accuracy of a larger set of headlines that included the previously rated and new headlines.",,,,145,1.99,0.614,2.67,0.64,raw data,no
17,"Calvillo, D. P., & Smelter, T. J. (2020). An initial accuracy focus reduces the effect of prior exposure on perceived accuracy of news headlines. Cognitive Research: Principles and Implications, 5(1), 55. https://doi.org/10.1186/s41235-020-00257-y",Calvillo 2020,,,"data correspond to experiment 2, accuracy prime condition, new news items, politically concordant items; values based on own calculations ",yes,4,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_concordant,3,8,,0.5,title_picture,nosource,accuracy,"Immediately after initial ratings, participants rated the accuracy of all 32 headlines (for 16 they had made previous ratings and the other 16 were new) on a 4-point scale from not at all accurate to very accurate.",1,0,4,treatment,positive,accuracy_prime,"Some participants initially rated how interesting a subset of headlines were (interest_prime), whereas other participants rated how truthful they were (accuracy prime). All participants then rated the accuracy of a larger set of headlines that included the previously rated and new headlines.",,,,157,2.46,0.62,2.98,0.572,raw data,no
17,"Calvillo, D. P., & Smelter, T. J. (2020). An initial accuracy focus reduces the effect of prior exposure on perceived accuracy of news headlines. Cognitive Research: Principles and Implications, 5(1), 55. https://doi.org/10.1186/s41235-020-00257-y",Calvillo 2020,,,"data correspond to experiment 2, accuracy prime condition, new news items, politically discordant items; values based on own calculations ",yes,4,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_discordant,4,8,,0.5,title_picture,nosource,accuracy,"Immediately after initial ratings, participants rated the accuracy of all 32 headlines (for 16 they had made previous ratings and the other 16 were new) on a 4-point scale from not at all accurate to very accurate.",1,0,4,treatment,positive,accuracy_prime,"Some participants initially rated how interesting a subset of headlines were (interest_prime), whereas other participants rated how truthful they were (accuracy prime). All participants then rated the accuracy of a larger set of headlines that included the previously rated and new headlines.",,,,157,1.89,0.601,2.48,0.627,raw data,no
17,"Calvillo, D. P., & Smelter, T. J. (2020). An initial accuracy focus reduces the effect of prior exposure on perceived accuracy of news headlines. Cognitive Research: Principles and Implications, 5(1), 55. https://doi.org/10.1186/s41235-020-00257-y",Calvillo 2020,,,"data correspond to experiment 2, accuracy prime condition, familiarized news items, politically concordant items; values based on own calculations ",yes,4,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_concordant,5,8,,0.5,title_picture,nosource,accuracy,"Immediately after initial ratings, participants rated the accuracy of all 32 headlines (for 16 they had made previous ratings and the other 16 were new) on a 4-point scale from not at all accurate to very accurate.",1,0,4,treatment,positive,multiple_accuracyprime_familiarization,"Some participants initially rated how interesting a subset of headlines were (interest_prime), whereas other participants rated how truthful they were (accuracy prime). All participants then rated the accuracy of a larger set of headlines that included the previously rated and new headlines.",,,,157,2.51,0.601,3.03,0.64,raw data,no
17,"Calvillo, D. P., & Smelter, T. J. (2020). An initial accuracy focus reduces the effect of prior exposure on perceived accuracy of news headlines. Cognitive Research: Principles and Implications, 5(1), 55. https://doi.org/10.1186/s41235-020-00257-y",Calvillo 2020,,,"data correspond to experiment 2, accuracy prime condition, familiarized news items, politically discordant items; values based on own calculations ",yes,4,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_discordant,6,8,,0.5,title_picture,nosource,accuracy,"Immediately after initial ratings, participants rated the accuracy of all 32 headlines (for 16 they had made previous ratings and the other 16 were new) on a 4-point scale from not at all accurate to very accurate.",1,0,4,treatment,positive,multiple_interestprime_familiarization,"Some participants initially rated how interesting a subset of headlines were (interest_prime), whereas other participants rated how truthful they were (accuracy prime). All participants then rated the accuracy of a larger set of headlines that included the previously rated and new headlines.",,,,157,1.86,0.593,2.55,0.578,raw data,no
18,"Altay, S., Nielsen, R. K., & Fletcher, R. (2022). The impact of news media and digital platform use on awareness of and belief in COVID-19 misinformation [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/7tm3s",Altay 2022_b,,,W1,no,1,Brazil,within,yes,yes,"To avoid floor effects in the measure of belief, we used some of the most prominent and most plausible COVID-19 false claims. However, to avoid ceiling effects we did not ask about the most prominent and most plausible true claims, given that the public’s knowledge of basic COVID-19 facts (e.g., what an antibody test is, what the R0 number refers to, etc.) is high (Nielsen et al., 2020, 2021). Instead, we selected relatively niche COVID-19 facts.

From SI: We selected the COVID items to avoid floor and ceiling effects, that is, we excluded items that all participants, or none, have heard of or found accurate.",partly,,researchers,fact_checking,mainstream,covid,1,8,,0.5,title,nosource,accuracy,"we measured belief in the claim with the question: “How accurate or inaccurate is this claim?” (1) “Very inaccurate”, (2) “Inaccurate”, (3) “Slightly Inaccurate”, (4) “Don’t know”, (5) “Slightly accurate”, (6) “Accurate”, (7) “Very accurate”.",1,1,7,control,,,,,,,2004,3.67,1.58,4.22,1.34,raw data,
18,"Altay, S., Nielsen, R. K., & Fletcher, R. (2022). The impact of news media and digital platform use on awareness of and belief in COVID-19 misinformation [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/7tm3s",Altay 2022_b,,,W1,no,2,India,within,yes,yes,"To avoid floor effects in the measure of belief, we used some of the most prominent and most plausible COVID-19 false claims. However, to avoid ceiling effects we did not ask about the most prominent and most plausible true claims, given that the public’s knowledge of basic COVID-19 facts (e.g., what an antibody test is, what the R0 number refers to, etc.) is high (Nielsen et al., 2020, 2021). Instead, we selected relatively niche COVID-19 facts.

From SI: We selected the COVID items to avoid floor and ceiling effects, that is, we excluded items that all participants, or none, have heard of or found accurate.",partly,,researchers,fact_checking,mainstream,covid,2,8,,0.5,title,nosource,accuracy,"we measured belief in the claim with the question: “How accurate or inaccurate is this claim?” (1) “Very inaccurate”, (2) “Inaccurate”, (3) “Slightly Inaccurate”, (4) “Don’t know”, (5) “Slightly accurate”, (6) “Accurate”, (7) “Very accurate”.",1,1,7,control,,,,,,,2070,3.8,1.2,4.16,1.2,raw data,
18,"Altay, S., Nielsen, R. K., & Fletcher, R. (2022). The impact of news media and digital platform use on awareness of and belief in COVID-19 misinformation [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/7tm3s",Altay 2022_b,,,W1,no,3,UK,within,yes,yes,"To avoid floor effects in the measure of belief, we used some of the most prominent and most plausible COVID-19 false claims. However, to avoid ceiling effects we did not ask about the most prominent and most plausible true claims, given that the public’s knowledge of basic COVID-19 facts (e.g., what an antibody test is, what the R0 number refers to, etc.) is high (Nielsen et al., 2020, 2021). Instead, we selected relatively niche COVID-19 facts.

From SI: We selected the COVID items to avoid floor and ceiling effects, that is, we excluded items that all participants, or none, have heard of or found accurate.",partly,,researchers,fact_checking,mainstream,covid,3,8,,0.5,title,nosource,accuracy,"we measured belief in the claim with the question: “How accurate or inaccurate is this claim?” (1) “Very inaccurate”, (2) “Inaccurate”, (3) “Slightly Inaccurate”, (4) “Don’t know”, (5) “Slightly accurate”, (6) “Accurate”, (7) “Very accurate”.",1,1,7,control,,,,,,,2052,3.15,1.07,3.98,0.91,raw data,
18,"Altay, S., Nielsen, R. K., & Fletcher, R. (2022). The impact of news media and digital platform use on awareness of and belief in COVID-19 misinformation [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/7tm3s",Altay 2022_b,,,W2,no,1,Brazil,within,yes,yes,"To avoid floor effects in the measure of belief, we used some of the most prominent and most plausible COVID-19 false claims. However, to avoid ceiling effects we did not ask about the most prominent and most plausible true claims, given that the public’s knowledge of basic COVID-19 facts (e.g., what an antibody test is, what the R0 number refers to, etc.) is high (Nielsen et al., 2020, 2021). Instead, we selected relatively niche COVID-19 facts.

From SI: We selected the COVID items to avoid floor and ceiling effects, that is, we excluded items that all participants, or none, have heard of or found accurate.",partly,,researchers,fact_checking,mainstream,covid,1,8,,0.5,title,nosource,accuracy,"we measured belief in the claim with the question: “How accurate or inaccurate is this claim?” (1) “Very inaccurate”, (2) “Inaccurate”, (3) “Slightly Inaccurate”, (4) “Don’t know”, (5) “Slightly accurate”, (6) “Accurate”, (7) “Very accurate”.",1,1,7,control,,,,,,,1250,3.73,1.31,4.28,1.06,raw data,
18,"Altay, S., Nielsen, R. K., & Fletcher, R. (2022). The impact of news media and digital platform use on awareness of and belief in COVID-19 misinformation [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/7tm3s",Altay 2022_b,,,W2,no,2,India,within,yes,yes,"To avoid floor effects in the measure of belief, we used some of the most prominent and most plausible COVID-19 false claims. However, to avoid ceiling effects we did not ask about the most prominent and most plausible true claims, given that the public’s knowledge of basic COVID-19 facts (e.g., what an antibody test is, what the R0 number refers to, etc.) is high (Nielsen et al., 2020, 2021). Instead, we selected relatively niche COVID-19 facts.

From SI: We selected the COVID items to avoid floor and ceiling effects, that is, we excluded items that all participants, or none, have heard of or found accurate.",partly,,researchers,fact_checking,mainstream,covid,2,8,,0.5,title,nosource,accuracy,"we measured belief in the claim with the question: “How accurate or inaccurate is this claim?” (1) “Very inaccurate”, (2) “Inaccurate”, (3) “Slightly Inaccurate”, (4) “Don’t know”, (5) “Slightly accurate”, (6) “Accurate”, (7) “Very accurate”.",1,1,7,control,,,,,,,2070,3.9,0.99,4.21,0.88,raw data,
18,"Altay, S., Nielsen, R. K., & Fletcher, R. (2022). The impact of news media and digital platform use on awareness of and belief in COVID-19 misinformation [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/7tm3s",Altay 2022_b,,,W2,no,3,UK,within,yes,yes,"To avoid floor effects in the measure of belief, we used some of the most prominent and most plausible COVID-19 false claims. However, to avoid ceiling effects we did not ask about the most prominent and most plausible true claims, given that the public’s knowledge of basic COVID-19 facts (e.g., what an antibody test is, what the R0 number refers to, etc.) is high (Nielsen et al., 2020, 2021). Instead, we selected relatively niche COVID-19 facts.

From SI: We selected the COVID items to avoid floor and ceiling effects, that is, we excluded items that all participants, or none, have heard of or found accurate.",partly,,researchers,fact_checking,mainstream,covid,3,8,,0.5,title,nosource,accuracy,"we measured belief in the claim with the question: “How accurate or inaccurate is this claim?” (1) “Very inaccurate”, (2) “Inaccurate”, (3) “Slightly Inaccurate”, (4) “Don’t know”, (5) “Slightly accurate”, (6) “Accurate”, (7) “Very accurate”.",1,1,7,control,,,,,,,2052,3.2,0.97,3.97,0.69,raw data,
18,"Altay, S., Nielsen, R. K., & Fletcher, R. (2022). The impact of news media and digital platform use on awareness of and belief in COVID-19 misinformation [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/7tm3s",Altay 2022_b,,,W2 (new items),no,1,Brazil,within,yes,yes,"To avoid floor effects in the measure of belief, we used some of the most prominent and most plausible COVID-19 false claims. However, to avoid ceiling effects we did not ask about the most prominent and most plausible true claims, given that the public’s knowledge of basic COVID-19 facts (e.g., what an antibody test is, what the R0 number refers to, etc.) is high (Nielsen et al., 2020, 2021). Instead, we selected relatively niche COVID-19 facts.

From SI: We selected the COVID items to avoid floor and ceiling effects, that is, we excluded items that all participants, or none, have heard of or found accurate.",partly,,researchers,fact_checking,mainstream,covid,4,4,,0.5,title,nosource,accuracy,"we measured belief in the claim with the question: “How accurate or inaccurate is this claim?” (1) “Very inaccurate”, (2) “Inaccurate”, (3) “Slightly Inaccurate”, (4) “Don’t know”, (5) “Slightly accurate”, (6) “Accurate”, (7) “Very accurate”.",1,1,7,control,,,,,,,2004,3.73,1.31,4.28,1.06,raw data,
18,"Altay, S., Nielsen, R. K., & Fletcher, R. (2022). The impact of news media and digital platform use on awareness of and belief in COVID-19 misinformation [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/7tm3s",Altay 2022_b,,,W2 (new items),no,2,India,within,yes,yes,"To avoid floor effects in the measure of belief, we used some of the most prominent and most plausible COVID-19 false claims. However, to avoid ceiling effects we did not ask about the most prominent and most plausible true claims, given that the public’s knowledge of basic COVID-19 facts (e.g., what an antibody test is, what the R0 number refers to, etc.) is high (Nielsen et al., 2020, 2021). Instead, we selected relatively niche COVID-19 facts.

From SI: We selected the COVID items to avoid floor and ceiling effects, that is, we excluded items that all participants, or none, have heard of or found accurate.",partly,,researchers,fact_checking,mainstream,covid,5,4,,0.5,title,nosource,accuracy,"we measured belief in the claim with the question: “How accurate or inaccurate is this claim?” (1) “Very inaccurate”, (2) “Inaccurate”, (3) “Slightly Inaccurate”, (4) “Don’t know”, (5) “Slightly accurate”, (6) “Accurate”, (7) “Very accurate”.",1,1,7,control,,,,,,,2070,3.9,0.99,4.21,0.88,raw data,
18,"Altay, S., Nielsen, R. K., & Fletcher, R. (2022). The impact of news media and digital platform use on awareness of and belief in COVID-19 misinformation [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/7tm3s",Altay 2022_b,,,W2 (new items),no,3,UK,within,yes,yes,"To avoid floor effects in the measure of belief, we used some of the most prominent and most plausible COVID-19 false claims. However, to avoid ceiling effects we did not ask about the most prominent and most plausible true claims, given that the public’s knowledge of basic COVID-19 facts (e.g., what an antibody test is, what the R0 number refers to, etc.) is high (Nielsen et al., 2020, 2021). Instead, we selected relatively niche COVID-19 facts.

From SI: We selected the COVID items to avoid floor and ceiling effects, that is, we excluded items that all participants, or none, have heard of or found accurate.",partly,,researchers,fact_checking,mainstream,covid,6,4,,0.5,title,nosource,accuracy,"we measured belief in the claim with the question: “How accurate or inaccurate is this claim?” (1) “Very inaccurate”, (2) “Inaccurate”, (3) “Slightly Inaccurate”, (4) “Don’t know”, (5) “Slightly accurate”, (6) “Accurate”, (7) “Very accurate”.",1,1,7,control,,,,,,,2052,3.2,0.97,3.97,0.69,raw data,
19,"Badrinathan, S. (2021). Educative Interventions to Combat Misinformation: Evidence from a Field Experiment in India. American Political Science Review, 115(4), 1325–1341. https://doi.org/10.1017/S0003055421000459",Badrinathan 2021,yes,,"values taken from own calculations based on data;
we combined both treatment groups (following the author) because of similarity and non-distinguishable effects;
""The false stories included in the treatment group flyers were drawn from a pool of stories fact checked for accuracy by altnews.in and boomlive.in."";
From e-mail exchange, we know that true news were selected from ""mainstream as well as fact checking sites"" and that news were presented in format of ""headline + image in some cases"". ",yes,1,India,within,no,no,,original,,researchers,fact_checking,mainstream_fact_checking,politically_concordant,1,7,,0.1428571429,title_picture,nosource,accuracy,"the key primary dependent variable measured perceived accuracy of stories, with the following question: “Do you believe this news story is false?” (binary response, 1 if yes, 0 otherwise).",,,binary,control,,,,1,,,406,0.203,0.402,0.825,0.38,raw data,no
19,"Badrinathan, S. (2021). Educative Interventions to Combat Misinformation: Evidence from a Field Experiment in India. American Political Science Review, 115(4), 1325–1341. https://doi.org/10.1017/S0003055421000459",Badrinathan 2021,yes,,"values taken from own calculations based on data;
we combined both treatment groups (following the author) because of similarity and non-distinguishable effects;
""The false stories included in the treatment group flyers were drawn from a pool of stories fact checked for accuracy by altnews.in and boomlive.in."";
From e-mail exchange, we know that true news were selected from ""mainstream as well as fact checking sites"" and that news were presented in format of ""headline + image in some cases"". ",yes,1,India,within,no,no,,original,,researchers,fact_checking,mainstream_fact_checking,politically_discordant,2,7,,0.1428571429,title_picture,nosource,accuracy,"the key primary dependent variable measured perceived accuracy of stories, with the following question: “Do you believe this news story is false?” (binary response, 1 if yes, 0 otherwise).",,,binary,control,,,,2,,,406,0.158,0.364,0.901,0.298,raw data,no
19,"Badrinathan, S. (2021). Educative Interventions to Combat Misinformation: Evidence from a Field Experiment in India. American Political Science Review, 115(4), 1325–1341. https://doi.org/10.1017/S0003055421000459",Badrinathan 2021,yes,,"values taken from own calculations based on data;
we combined both treatment groups (following the author) because of similarity and non-distinguishable effects;
""The false stories included in the treatment group flyers were drawn from a pool of stories fact checked for accuracy by altnews.in and boomlive.in."";
From e-mail exchange, we know that true news were selected from ""mainstream as well as fact checking sites"" and that news were presented in format of ""headline + image in some cases"". ",yes,2,India,within,no,no,,original,,researchers,fact_checking,mainstream_fact_checking,politically_concordant,1,7,,0.1428571429,title_picture,nosource,accuracy,"the key primary dependent variable measured perceived accuracy of stories, with the following question: “Do you believe this news story is false?” (binary response, 1 if yes, 0 otherwise).",,,binary,treatment,positive,training,"Following the authors, we pool two treatment groups into a single one: ""both treatment groups received the pedagogical intervention. However, one group received corrections to four pro-BJP false stories and the other received corrections to four anti-BJP false stories. Besides differences in the stories that were factchecked, the tips on the flyer remained the same for both treatment groups.""; 
""Pedagogical intervention: Next, respondents went through a learning module to help inoculate against misinformation. This included an hour-long discussion on encouraging people to verify information along with concrete tools to do so.""",1,,,818,0.216,0.412,0.814,0.389,raw data,no
19,"Badrinathan, S. (2021). Educative Interventions to Combat Misinformation: Evidence from a Field Experiment in India. American Political Science Review, 115(4), 1325–1341. https://doi.org/10.1017/S0003055421000459",Badrinathan 2021,yes,,"values taken from own calculations based on data;
we combined both treatment groups (following the author) because of similarity and non-distinguishable effects;
""The false stories included in the treatment group flyers were drawn from a pool of stories fact checked for accuracy by altnews.in and boomlive.in."";
From e-mail exchange, we know that true news were selected from ""mainstream as well as fact checking sites"" and that news were presented in format of ""headline + image in some cases"". ",yes,2,India,within,no,no,,original,,researchers,fact_checking,mainstream_fact_checking,politically_discordant,2,7,,0.1428571429,title_picture,nosource,accuracy,"the key primary dependent variable measured perceived accuracy of stories, with the following question: “Do you believe this news story is false?” (binary response, 1 if yes, 0 otherwise).",1,1,binary,treatment,positive,training,"Following the authors, we pool two treatment groups into a single one: ""both treatment groups received the pedagogical intervention. However, one group received corrections to four pro-BJP false stories and the other received corrections to four anti-BJP false stories. Besides differences in the stories that were factchecked, the tips on the flyer remained the same for both treatment groups.""; 
""Pedagogical intervention: Next, respondents went through a learning module to help inoculate against misinformation. This included an hour-long discussion on encouraging people to verify information along with concrete tools to do so.""",2,,,818,0.154,0.361,0.908,0.289,raw data,no
20,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",Pennycook 2021,,,values calculated based on data on osf,yes,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,10,79,0.6202531646,title_picture,source,likelihood,"What is the likelihood that the above headline is true? 1. Extremely unlikely, 2. Moderately unlikely, 3. Slightly unlikely, 4. Slightly likely, 5. Moderately likely, 6. Extremely likely",1,1,6,control,,,,,,,2013,3.22,0.447,3.93,0.374,raw data,no
20,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",Pennycook 2021,,,values calculated based on data on osf,yes,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,political,2,10,146,0.5205479452,title_picture,source,likelihood,"What is the likelihood that the above headline is true? 1. Extremely unlikely, 2. Moderately unlikely, 3. Slightly unlikely, 4. Slightly likely, 5. Moderately likely, 6. Extremely likely",1,1,6,control,,,,,,,2013,2.96,0.43,3.79,0.399,raw data,no
21,"Roozenbeek, J., Maertens, R., Herzog, S. M., Geers, M., Kurvers, R., & Sultan, M. (2022). Susceptibility to misinformation is consistent across question framings and response modes and better explained by myside bias and partisanship than analytical thinking. Judgment and Decision Making, 17(3), 27.",Roozenbeek 2022,,,"data correspond to 6-point accuracy scale; data are technically to be excluded, because they made up headlines - BUT it was generated based on real headlines by an AI algorithm, so I decided to include it.
Values are taken from appendix, table S4; values are standardized on scale from 0 to 1 -- hence '1' in scale variable, put the original scale in the comment; only took the 20-Mist value for all scales; they define Fake News Score (FNS) as correctly classifiying fake news as fake news. To fill out our variable (fake news as accurate, in the sense that wrongly labeled as accurate) we thus calculate 1-FNS. We keep the FNS score SD value;
needed to look into their bloody R script to see how they calculated their values; 
they standardized as follows: 
Accuracy for true news = score -1 / scale_size-1
Accuracy for fake news (they operationalize this as correctly identifying fake as false) = scale_size-score/scale_size-1",yes,1,United States,within,yes,yes,"has been pre-tested in ""Maertens, R., Götz, F. M., Schneider, C. R., Roozenbeek, J., Kerr, J. R., Stieger, S., McClanahan, W. P., Drabot, K., & Linden, S. van der. (2021). The Misinformation Susceptibility Test (MIST): A psychometrically validated measure of news veracity discernment [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/gk68h""",recycled,"Maertens, R., Götz, F. M., Schneider, C. R., Roozenbeek, J., Kerr, J. R., Stieger, S., McClanahan, W. P., Drabot, K., & Linden, S. van der. (2021). The Misinformation Susceptibility Test (MIST): A psychometrically validated measure of news veracity discernment [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/gk68h",researchers_AIgenerated,AI_generated,mainstream,anything,1,20,,0.5,title,nosource,accuracy,"Values are standardized on scale from 0 to 1;
Original scale: Accuracy (6 pt.) (n = 326): “How accurate do you find this headline?”, 1 being “not at all” and 6 being “very” (Guess et al., 2020; Pennycook et al., 2020).",1,NA,1,control,,,,,,,326,0.25,0.18,0.69,0.13,paper,no
21,"Roozenbeek, J., Maertens, R., Herzog, S. M., Geers, M., Kurvers, R., & Sultan, M. (2022). Susceptibility to misinformation is consistent across question framings and response modes and better explained by myside bias and partisanship than analytical thinking. Judgment and Decision Making, 17(3), 27.",Roozenbeek 2022,,,"data correspond to 7-point accuracy scale; data are technically to be excluded, because they made up headlines - BUT it was generated based on real headlines by an AI algorithm, so I decided to include it.
Values are taken from appendix, table S4; values are standardized on scale from 0 to 1 -- hence '1' in scale variable, put the original scale in the comment; only took the 20-Mist value for all scales; they define Fake News Score (FNS) as correctly classifiying fake news as fake news. To fill out our variable (fake news as accurate, in the sense that wrongly labeled as accurate) we thus calculate 1-FNS. We keep the FNS score SD value;
needed to look into their bloody R script to see how they calculated their values; 
they standardized as follows: 
Accuracy for true news = score -1 / scale_size-1
Accuracy for fake news (they operationalize this as correctly identifying fake as false) = scale_size-score/scale_size-1",yes,2,United States,within,yes,yes,,recycled,"Maertens, R., Götz, F. M., Schneider, C. R., Roozenbeek, J., Kerr, J. R., Stieger, S., McClanahan, W. P., Drabot, K., & Linden, S. van der. (2021). The Misinformation Susceptibility Test (MIST): A psychometrically validated measure of news veracity discernment [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/gk68h",researchers_AIgenerated,AI_generated,mainstream,anything,1,20,,0.5,title,nosource,accuracy,"Values are standardized on scale from 0 to 1;
Original scale: Accuracy (7 pt.) (n = 336): “How accurate do you find this headline?”, 1 being “not at all” and 7 being “very”.",1,NA,1,control,,,,,,,336,0.26,0.18,0.68,0.12,paper,no
21,"Roozenbeek, J., Maertens, R., Herzog, S. M., Geers, M., Kurvers, R., & Sultan, M. (2022). Susceptibility to misinformation is consistent across question framings and response modes and better explained by myside bias and partisanship than analytical thinking. Judgment and Decision Making, 17(3), 27.",Roozenbeek 2022,,,"data correspond to 7-point manipulativeness scale; data are technically to be excluded, because they made up headlines - BUT it was generated based on real headlines by an AI algorithm, so I decided to include it.
Values are taken from appendix, table S4; values are standardized on scale from 0 to 1 -- hence '1' in scale variable, put the original scale in the comment; only took the 20-Mist value for all scales; they define Fake News Score (FNS) as correctly classifiying fake news as fake news. To fill out our variable (fake news as accurate, in the sense that wrongly labeled as accurate) we thus calculate 1-FNS. We keep the FNS score SD value;
needed to look into their bloody R script to see how they calculated their values; 
they standardized as follows: 
Accuracy for true news = score -1 / scale_size-1
Accuracy for fake news (they operationalize this as correctly identifying fake as false) = scale_size-score/scale_size-1",yes,3,United States,within,yes,yes,,recycled,"Maertens, R., Götz, F. M., Schneider, C. R., Roozenbeek, J., Kerr, J. R., Stieger, S., McClanahan, W. P., Drabot, K., & Linden, S. van der. (2021). The Misinformation Susceptibility Test (MIST): A psychometrically validated measure of news veracity discernment [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/gk68h",researchers_AIgenerated,AI_generated,mainstream,anything,1,20,,0.5,title,nosource,manipulativeness,"Values are standardized on scale from 0 to 1;
Original scale: Manipulativeness (7 pt.) (n = 330): “How manipulative do you find this headline?”, 1 being “not at all” and 7 being “very” (Basol, Roozenbeek, et al., 2021; Saleh, Roozenbeek, et al., 2021).",1,NA,1,control,,,,,,,330,0.22,0.15,0.66,0.18,paper,no
21,"Roozenbeek, J., Maertens, R., Herzog, S. M., Geers, M., Kurvers, R., & Sultan, M. (2022). Susceptibility to misinformation is consistent across question framings and response modes and better explained by myside bias and partisanship than analytical thinking. Judgment and Decision Making, 17(3), 27.",Roozenbeek 2022,,,"data correspond to 7-point reliability scale; data are technically to be excluded, because they made up headlines - BUT it was generated based on real headlines by an AI algorithm, so I decided to include it.
Values are taken from appendix, table S4; values are standardized on scale from 0 to 1 -- hence '1' in scale variable, put the original scale in the comment; only took the 20-Mist value for all scales; they define Fake News Score (FNS) as correctly classifiying fake news as fake news. To fill out our variable (fake news as accurate, in the sense that wrongly labeled as accurate) we thus calculate 1-FNS. We keep the FNS score SD value;
needed to look into their bloody R script to see how they calculated their values; 
they standardized as follows: 
Accuracy for true news = score -1 / scale_size-1
Accuracy for fake news (they operationalize this as correctly identifying fake as false) = scale_size-score/scale_size-1",yes,4,United States,within,yes,yes,,recycled,"Maertens, R., Götz, F. M., Schneider, C. R., Roozenbeek, J., Kerr, J. R., Stieger, S., McClanahan, W. P., Drabot, K., & Linden, S. van der. (2021). The Misinformation Susceptibility Test (MIST): A psychometrically validated measure of news veracity discernment [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/gk68h",researchers_AIgenerated,AI_generated,mainstream,anything,1,20,,0.5,title,nosource,reliability,"Values are standardized on scale from 0 to 1;
Original scale: Reliability (7 pt.) (n = 331): “How reliable do you find this headline?”, 1 being “not at all” and 7 being “very” (Basol et al., 2020; Roozenbeek & van der Linden, 2019).",1,NA,1,control,,,,,,,331,0.26,0.18,0.67,0.13,paper,no
21,"Roozenbeek, J., Maertens, R., Herzog, S. M., Geers, M., Kurvers, R., & Sultan, M. (2022). Susceptibility to misinformation is consistent across question framings and response modes and better explained by myside bias and partisanship than analytical thinking. Judgment and Decision Making, 17(3), 27.",Roozenbeek 2022,,,"data correspond to 7-point trustworthiness scale; data are technically to be excluded, because they made up headlines - BUT it was generated based on real headlines by an AI algorithm, so I decided to include it.
Values are taken from appendix, table S4; values are standardized on scale from 0 to 1 -- hence '1' in scale variable, put the original scale in the comment; only took the 20-Mist value for all scales; they define Fake News Score (FNS) as correctly classifiying fake news as fake news. To fill out our variable (fake news as accurate, in the sense that wrongly labeled as accurate) we thus calculate 1-FNS. We keep the FNS score SD value;
needed to look into their bloody R script to see how they calculated their values; 
they standardized as follows: 
Accuracy for true news = score -1 / scale_size-1
Accuracy for fake news (they operationalize this as correctly identifying fake as false) = scale_size-score/scale_size-1",yes,5,United States,within,yes,yes,,recycled,"Maertens, R., Götz, F. M., Schneider, C. R., Roozenbeek, J., Kerr, J. R., Stieger, S., McClanahan, W. P., Drabot, K., & Linden, S. van der. (2021). The Misinformation Susceptibility Test (MIST): A psychometrically validated measure of news veracity discernment [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/gk68h",researchers_AIgenerated,AI_generated,mainstream,anything,1,20,,0.5,title,nosource,trustwothiness,"Values are standardized on scale from 0 to 1;
Original scale: Trustworthiness (7 pt.) (n = 330): “How trustworthy do you find this headline?”, 1 being “not at all” and 7 being “very” (McGrew, 2020; Roozenbeek, van der Linden, et al., 2022).",1,NA,1,control,,,,,,,330,0.24,0.16,0.68,0.14,paper,no
21,"Roozenbeek, J., Maertens, R., Herzog, S. M., Geers, M., Kurvers, R., & Sultan, M. (2022). Susceptibility to misinformation is consistent across question framings and response modes and better explained by myside bias and partisanship than analytical thinking. Judgment and Decision Making, 17(3), 27.",Roozenbeek 2022,,,"data correspond to 6-point real-fake scale; data are technically to be excluded, because they made up headlines - BUT it was generated based on real headlines by an AI algorithm, so I decided to include it.
Values are taken from appendix, table S4; values are standardized on scale from 0 to 1 -- hence '1' in scale variable, put the original scale in the comment; only took the 20-Mist value for all scales; they define Fake News Score (FNS) as correctly classifiying fake news as fake news. To fill out our variable (fake news as accurate, in the sense that wrongly labeled as accurate) we thus calculate 1-FNS. We keep the FNS score SD value;
needed to look into their bloody R script to see how they calculated their values; 
they standardized as follows: 
Accuracy for true news = score -1 / scale_size-1
Accuracy for fake news (they operationalize this as correctly identifying fake as false) = scale_size-score/scale_size-1",yes,6,United States,within,yes,yes,,recycled,"Maertens, R., Götz, F. M., Schneider, C. R., Roozenbeek, J., Kerr, J. R., Stieger, S., McClanahan, W. P., Drabot, K., & Linden, S. van der. (2021). The Misinformation Susceptibility Test (MIST): A psychometrically validated measure of news veracity discernment [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/gk68h",researchers_AIgenerated,AI_generated,mainstream,anything,1,20,,0.5,title,nosource,real_fake,"Values are standardized on scale from 0 to 1;
Original scale: Real – Fake (6 pt.) (n = 315): “This headline is...”, 1 being “real” and 6 being “fake”.",1,NA,1,control,,,,,,,315,0.29,0.2,0.65,0.14,paper,no
21,"Roozenbeek, J., Maertens, R., Herzog, S. M., Geers, M., Kurvers, R., & Sultan, M. (2022). Susceptibility to misinformation is consistent across question framings and response modes and better explained by myside bias and partisanship than analytical thinking. Judgment and Decision Making, 17(3), 27.",Roozenbeek 2022,,,"data correspond to 7-point real-fake scale; data are technically to be excluded, because they made up headlines - BUT it was generated based on real headlines by an AI algorithm, so I decided to include it.
Values are taken from appendix, table S4; values are standardized on scale from 0 to 1 -- hence '1' in scale variable, put the original scale in the comment; only took the 20-Mist value for all scales; they define Fake News Score (FNS) as correctly classifiying fake news as fake news. To fill out our variable (fake news as accurate, in the sense that wrongly labeled as accurate) we thus calculate 1-FNS. We keep the FNS score SD value;
needed to look into their bloody R script to see how they calculated their values; 
they standardized as follows: 
Accuracy for true news = score -1 / scale_size-1
Accuracy for fake news (they operationalize this as correctly identifying fake as false) = scale_size-score/scale_size-1",yes,7,United States,within,yes,yes,,recycled,"Maertens, R., Götz, F. M., Schneider, C. R., Roozenbeek, J., Kerr, J. R., Stieger, S., McClanahan, W. P., Drabot, K., & Linden, S. van der. (2021). The Misinformation Susceptibility Test (MIST): A psychometrically validated measure of news veracity discernment [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/gk68h",researchers_AIgenerated,AI_generated,mainstream,anything,1,20,,0.5,title,nosource,real_fake,"Values are standardized on scale from 0 to 1;
Original scale: Real – Fake (7 pt.) (n = 316): “This headline is...”, 1 being “real” and 7 being “fake”.",1,NA,1,control,,,,,,,316,0.29,0.2,0.68,0.18,paper,no
21,"Roozenbeek, J., Maertens, R., Herzog, S. M., Geers, M., Kurvers, R., & Sultan, M. (2022). Susceptibility to misinformation is consistent across question framings and response modes and better explained by myside bias and partisanship than analytical thinking. Judgment and Decision Making, 17(3), 27.",Roozenbeek 2022,,,"data correspond to binary real-fake scale; data are technically to be excluded, because they made up headlines - BUT it was generated based on real headlines by an AI algorithm, so I decided to include it.
Values are taken from appendix, table S4; values are standardized on scale from 0 to 1 -- hence '1' in scale variable, put the original scale in the comment; only took the 20-Mist value for all scales; they define Fake News Score (FNS) as correctly classifiying fake news as fake news. To fill out our variable (fake news as accurate, in the sense that wrongly labeled as accurate) we thus calculate 1-FNS. We keep the FNS score SD value;
needed to look into their bloody R script to see how they calculated their values; 
they standardized as follows: 
Accuracy for true news = score -1 / scale_size-1
Accuracy for fake news (they operationalize this as correctly identifying fake as false) = scale_size-score/scale_size-1",yes,8,United States,within,yes,yes,,recycled,"Maertens, R., Götz, F. M., Schneider, C. R., Roozenbeek, J., Kerr, J. R., Stieger, S., McClanahan, W. P., Drabot, K., & Linden, S. van der. (2021). The Misinformation Susceptibility Test (MIST): A psychometrically validated measure of news veracity discernment [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/gk68h",researchers_AIgenerated,AI_generated,mainstream,anything,1,20,,0.5,title,nosource,real_fake,"Values are standardized on scale from 0 to 1;
Original scale: Real – Fake (Binary) (n = 338): “This headline is...”, real or fake as a binary judgment (Maertens, Götz, et al., 2022).",1,NA,binary,control,,,,,,,338,0.2,0.2,0.83,0.17,paper,no
22,"Maertens, R., Götz, F. M., Schneider, C. R., Roozenbeek, J., Kerr, J. R., Stieger, S., McClanahan, W. P., Drabot, K., & Linden, S. van der. (2021). The Misinformation Susceptibility Test (MIST): A psychometrically validated measure of news veracity discernment [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/gk68h",Maertens 2021,,,"data correspond to study 2, the US samples (sample 2a and 2b); values taken from supplement S15; only took the 20-Mist value for all scales;
data are technically to be excluded, because they made up headlines - BUT it was generated based on real headlines by an AI algorithm, so I decided to include it;
was not obvious to find out how they calculated their scores: their response scale was binary and they simply added up correct responses for true news (called 'r', 10 news items, thus score from 0 to 10). We divide the resulting score by 10, so that it corresponds to a 0 to 1 scale. This will make analysis later more straigthforward, as we enter this study as using a binary response scale ('1'), and all other values on that scale actually range between 0 and 1 and not between 0 and 10. We keep the 'f' score divided by 10 for the SD value. For fake news ('f') correctly identified news were counted, i.e. correclty identifying fake news as fake. To fill out our variable (fake news as accurate, in the sense that wrongly labeled as accurate) we thus calculate 1-'f'/10.;  ",no,1,United States,within,yes,yes,"has been pre-tested in study 1 ( 'These items were selected based on their discrimination and difficulty values, where we aimed to select a diverse set of items that have a high discrimination (a ≥ 2.00 for the MIST-20, a ≥ 3.00 for the MIST-8) but yet have a wide range of difficulties (b = [-0.50, 0.50], for each ability), while keeping the guessing parameter at 50% chance (c =.50)')",original,,researchers_AIgenerated,AI_generated,mainstream,,1,20,,0.5,title,,real_fake,"Values are standardized on scale from 0 to 1;
Original scale: Real – Fake (Binary) (n = 338): “This headline is...”, real or fake as a binary judgment (Maertens, Götz, et al., 2022).",1,NA,binary,control,,,,,,,3989,0.283,0.247,0.687,0.231,paper,no
22,"Maertens, R., Götz, F. M., Schneider, C. R., Roozenbeek, J., Kerr, J. R., Stieger, S., McClanahan, W. P., Drabot, K., & Linden, S. van der. (2021). The Misinformation Susceptibility Test (MIST): A psychometrically validated measure of news veracity discernment [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/gk68h",Maertens 2021,,,"data correspond to study 2, the UK samples (sample 2c and 2d); values taken from supplement S15; only took the 20-Mist value for all scales;
data are technically to be excluded, because they made up headlines - BUT it was generated based on real headlines by an AI algorithm, so I decided to include it;
was not obvious to find out how they calculated their scores: their response scale was binary and they simply added up correct responses for true news (called 'r', 10 news items, thus score from 0 to 10). We divide the resulting score by 10, so that it corresponds to a 0 to 1 scale. This will make analysis later more straigthforward, as we enter this study as using a binary response scale ('1'), and all other values on that scale actually range between 0 and 1 and not between 0 and 10. We keep the 'f' score divided by 10 for the SD value. For fake news ('f') correctly identified news were counted, i.e. correclty identifying fake news as fake. To fill out our variable (fake news as accurate, in the sense that wrongly labeled as accurate) we thus calculate 1-'f'/10.;  ",no,2,UK,within,yes,yes,,original,,researchers_AIgenerated,AI_generated,mainstream,,1,20,,0.5,title,,real_fake,"Values are standardized on scale from 0 to 1;
Original scale: Real – Fake (Binary) (n = 338): “This headline is...”, real or fake as a binary judgment (Maertens, Götz, et al., 2022).",1,NA,binary,control,,,,,,,2472,0.262,0.243,0.591,0.269,paper,no
23,"Ross, R. M., Rand, D. G., & Pennycook, G. (2021). Beyond “fake news”: Analytic thinking and the detection of false and hyperpartisan news headlines. Judgment and Decision Making, 16(2), 22.",Ross 2021,,,"data correspond to experiment 1, MTurk sample, accuracy treatment (as opposte to sharing treatment); values taken from appendix, table S1",yes,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,20,,0.5,title,nosource,accuracy,“Do you think this headline describes an event that actually happened in an accurate and unbiased way?” (response options: “yes” and “no”).,1,1,binary,control,,,,,,,502,0.23,0.24,0.72,0.22,paper,no
23,"Ross, R. M., Rand, D. G., & Pennycook, G. (2021). Beyond “fake news”: Analytic thinking and the detection of false and hyperpartisan news headlines. Judgment and Decision Making, 16(2), 22.",Ross 2021,,,"data correspond to experiment 2, Lucid sample, accuracy treatment (as opposte to sharing treatment); values taken from appendix, table S2",yes,2,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,20,,0.5,title,nosource,accuracy,“Do you think this headline describes an event that actually happened in an accurate and unbiased way?” (response options: “yes” and “no”).,1,1,binary,control,,,,,,,438,0.28,0.25,0.63,0.26,paper,no
24,"Dias, N., Pennycook, G., & Rand, D. G. (2020). Emphasizing publishers does not effectively reduce susceptibility to misinformation on social media. Harvard Kennedy School Misinformation Review. https://doi.org/10.37016/mr-2020-001",Dias 2020,yes,"for study 1, we merge the control condition (no source) and the link only condition to a single control condition, and treat the enhance source condition as the intervention","data correspond to study 1, no source condition; values taken from appendix, table S2 ('all' row);
only the salient source condition (logo banner of source website) is coded as treatment, because a source display is standard on e.g. facebook;
sample size corresponds to total sample size 562/3 (because three conditions)",yes,1,United States,within,yes,no,,recycled,"Pennycook, G., Bear, A., Collins, E. T., & Rand, D. G. (2020). The Implied Truth Effect: Attaching Warnings to a Subset of Fake News Headlines Increases Perceived Accuracy of Headlines Without Warnings. Management Science, 66(11), 4944–4957. https://doi.org/10.1287/mnsc.2019.3478",researchers,fact_checking,mainstream,politically_balanced,1,24,,0.5,title_picture_pitch,nosource,accuracy,our primary dependent measures were an accuracy rating (4-point scale from “Not at all accurate” to “Very accurate”),1,0,4,control,,,,1,,,187.3333333,1.67,0.42,2.57,0.52,paper,no
24,"Dias, N., Pennycook, G., & Rand, D. G. (2020). Emphasizing publishers does not effectively reduce susceptibility to misinformation on social media. Harvard Kennedy School Misinformation Review. https://doi.org/10.37016/mr-2020-001",Dias 2020,yes,"for study 1, we merge the control condition (no source) and the link only condition to a single control condition, and treat the enhance source condition as the intervention","data correspond to study 1, baseline (website only) condition; values taken from appendix, table S2 ('all' row);
only the salient source condition (logo banner of source website) is coded as treatment, because a source display is standard on e.g. facebook;
sample size corresponds to total sample size 562/3 (because three conditions)",yes,2,United States,within,yes,no,,recycled,"Pennycook, G., Bear, A., Collins, E. T., & Rand, D. G. (2020). The Implied Truth Effect: Attaching Warnings to a Subset of Fake News Headlines Increases Perceived Accuracy of Headlines Without Warnings. Management Science, 66(11), 4944–4957. https://doi.org/10.1287/mnsc.2019.3478",researchers,fact_checking,mainstream,politically_balanced,1,24,,0.5,title_picture_pitch,nosource,accuracy,our primary dependent measures were an accuracy rating (4-point scale from “Not at all accurate” to “Very accurate”),1,0,4,control,,,,1,,,187.3333333,1.62,0.41,2.53,0.45,paper,no
24,"Dias, N., Pennycook, G., & Rand, D. G. (2020). Emphasizing publishers does not effectively reduce susceptibility to misinformation on social media. Harvard Kennedy School Misinformation Review. https://doi.org/10.37016/mr-2020-001",Dias 2020,yes,"for study 1, we merge the control condition (no source) and the link only condition to a single control condition, and treat the enhance source condition as the intervention","data correspond to study 1, salient (logo banner) condition; values taken from appendix, table S2 ('all' row);
only the salient source condition (logo banner of source website) is coded as treatment, because a source display is standard on e.g. facebook;
sample size corresponds to total sample size 562/3 (because three conditions)",yes,3,United States,within,yes,no,,recycled,"Pennycook, G., Bear, A., Collins, E. T., & Rand, D. G. (2020). The Implied Truth Effect: Attaching Warnings to a Subset of Fake News Headlines Increases Perceived Accuracy of Headlines Without Warnings. Management Science, 66(11), 4944–4957. https://doi.org/10.1287/mnsc.2019.3478",researchers,fact_checking,mainstream,politically_balanced,1,24,,0.5,title_picture_pitch,nosource,accuracy,our primary dependent measures were an accuracy rating (4-point scale from “Not at all accurate” to “Very accurate”),1,0,4,treatment,positive,highlight_source,a logo-banner condition where a banner showing the publisher’s logo was appended to the bottom of the Facebook post (Figure 1). Publishers’ logos were screenshotted from their websites.,1,,,187.3333333,1.67,0.44,2.66,0.45,paper,no
24,"Dias, N., Pennycook, G., & Rand, D. G. (2020). Emphasizing publishers does not effectively reduce susceptibility to misinformation on social media. Harvard Kennedy School Misinformation Review. https://doi.org/10.37016/mr-2020-001",Dias 2020,yes,"for study 1, we merge the control condition (no source) and the link only condition to a single control condition, and treat the enhance source condition as the intervention","data correspond to study 2, baseline (website only) condition; values taken from appendix, table S3 ('all' row);
the salient source condition (logo banner of source website) is coded as treatment;
sample size corresponds to total sample size 1845/2 (because two conditions)",yes,4,United States,within,yes,no,,recycled,"Pennycook, G., Bear, A., Collins, E. T., & Rand, D. G. (2020). The Implied Truth Effect: Attaching Warnings to a Subset of Fake News Headlines Increases Perceived Accuracy of Headlines Without Warnings. Management Science, 66(11), 4944–4957. https://doi.org/10.1287/mnsc.2019.3478",researchers,fact_checking,mainstream,politically_balanced,1,24,,0.5,title_picture_pitch,nosource,accuracy,our primary dependent measures were an accuracy rating (4-point scale from “Not at all accurate” to “Very accurate”),1,0,4,control,,,,2,,,922.5,1.64,0.41,2.61,0.42,paper,no
24,"Dias, N., Pennycook, G., & Rand, D. G. (2020). Emphasizing publishers does not effectively reduce susceptibility to misinformation on social media. Harvard Kennedy School Misinformation Review. https://doi.org/10.37016/mr-2020-001",Dias 2020,yes,"for study 1, we merge the control condition (no source) and the link only condition to a single control condition, and treat the enhance source condition as the intervention","data correspond to study 2, salient source condition (logo banner of source website); values taken from appendix, table S3 ('all' row);
the salient source condition (logo banner of source website) is coded as treatment;
sample size corresponds to total sample size 1845/2 (because two conditions)",yes,5,United States,within,yes,no,,recycled,"Pennycook, G., Bear, A., Collins, E. T., & Rand, D. G. (2020). The Implied Truth Effect: Attaching Warnings to a Subset of Fake News Headlines Increases Perceived Accuracy of Headlines Without Warnings. Management Science, 66(11), 4944–4957. https://doi.org/10.1287/mnsc.2019.3478",researchers,fact_checking,mainstream,politically_balanced,1,24,,0.5,title_picture_pitch,nosource,accuracy,our primary dependent measures were an accuracy rating (4-point scale from “Not at all accurate” to “Very accurate”),1,0,4,treatment,positive,highlight_source,a logo-banner condition where a banner showing the publisher’s logo was appended to the bottom of the Facebook post (Figure 1). Publishers’ logos were screenshotted from their websites.,2,,,922.5,1.64,0.44,2.62,0.45,paper,no
25,"Chen, X., Pennycook, G., & Rand, D. (2023). What Makes News Sharable on Social Media? Journal of Quantitative Description: Digital Media, 3. https://doi.org/10.51685/jqd.2023.007",Chen 2021,,,"annoying: they don't even report the scale of the veracity question, had to check their survey (OSF file); no summary stats either, they are based on own calculations of their data;
data correspond to study 1; attention, two different samples aggregated; ",no,1,United States,within,yes,no,,original ,,researchers,fact_checking,mainstream,,1,10,140,,title_picture_pitch,source,accuracy,"Truth (“What is the likelihood that the above headline is true?”)
1 (extremely unlikely) to 6 (extremely likely)",1,1,6,control ,,,,,,,3991,2.37,1.42,3.5,1.21,raw data,no
25,"Chen, X., Pennycook, G., & Rand, D. (2023). What Makes News Sharable on Social Media? Journal of Quantitative Description: Digital Media, 3. https://doi.org/10.51685/jqd.2023.007",Chen 2021,,,"annoying: they don't even report the scale of the veracity question, had to check their survey (OSF file); no summary stats either, they are based on own calculations of their data;
data correspond to study 2; 
attention, news_ID of second study has been coded the same as study 1, because there were not 216 new headlines, but big overlap between study 1 and 2 (study 2 included a few more recent headlines, we don't know how many were changed)",no,2,United States,within,yes,no,,original ,,researchers,fact_checking,mainstream,,1,18,144,,title_picture_pitch,source,accuracy,"Truth (“What is the likelihood that the above headline is true?”)
1 (extremely unlikely) to 6 (extremely likely)",1,1,6,control ,,,,,,,1009,2.64,1.69,4,1.48,raw data,no
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 1, 'pre' condition (i.e. before news game intervention); values are calculated based on their data;
attention: self-selected sample;",yes,1,Europe/United States,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,6,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,control ,,,,,,,1771,2.39,1.09,5.37,1.33,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 1, 'post' condition (i.e. before news game intervention); values are calculated based on their data;
attention: self-selected sample; 
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition)",yes,1,Europe/United States,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,6,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,treatment ,positive,multiple_inoculationgame_familiarization,Go Viral! Game,,,,1771,1.93,1.06,5.34,1.54,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 2, 'pre' condition (i.e. before news game intervention), and 'control' conditino; values are calculated based on their data;
same `news_id` as study 1 because: 'Six of these 18 items were the same as those used in Study 1, the other 12 were selected using the same procedure as described in Study 1.'
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition)",yes,2,UK,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,18,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,control,,,,,,,257,2.62,0.973,4.91,0.995,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 2, 'pre' condition (i.e. before news game intervention), and 'GoViral!' condition; values are calculated based on their data;
same `news_id` as study 1 because: 'Six of these 18 items were the same as those used in Study 1, the other 12 were selected using the same procedure as described in Study 1.'
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition)",yes,3,UK,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,18,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,control,,,,,,,212,2.53,0.907,5.02,0.966,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 2, 'pre' condition (i.e. before news game intervention), and 'Infographics' condition; values are calculated based on their data;
same `news_id` as study 1 because: 'Six of these 18 items were the same as those used in Study 1, the other 12 were selected using the same procedure as described in Study 1.'
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition)",yes,4,UK,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,18,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,control,,,,,,,241,2.52,0.943,5.04,1.09,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 2, 'pre' condition (i.e. before news game intervention), and 'control' conditino; values are calculated based on their data;
same `news_id` as study 1 because: 'Six of these 18 items were the same as those used in Study 1, the other 12 were selected using the same procedure as described in Study 1.'
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition)",yes,5,France,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,18,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,control,,,,,,,215,2.97,0.897,4.7,1.04,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 2, 'pre' condition (i.e. before news game intervention), and 'GoViral!' condition; values are calculated based on their data;
same `news_id` as study 1 because: 'Six of these 18 items were the same as those used in Study 1, the other 12 were selected using the same procedure as described in Study 1.'
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition)",yes,6,France,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,18,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,control,,,,,,,207,2.74,0.897,4.94,1.03,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 2, 'pre' condition (i.e. before news game intervention), and 'Infographics' condition; values are calculated based on their data;
same `news_id` as study 1 because: 'Six of these 18 items were the same as those used in Study 1, the other 12 were selected using the same procedure as described in Study 1.'
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition)",yes,7,France,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,18,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,control,,,,,,,188,2.93,0.937,4.59,0.924,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 2, 'pre' condition (i.e. before news game intervention), and 'control' conditino; values are calculated based on their data;
same `news_id` as study 1 because: 'Six of these 18 items were the same as those used in Study 1, the other 12 were selected using the same procedure as described in Study 1.'
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition)",yes,8,Germany,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,18,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,control,,,,,,,182,2.86,0.893,4.79,1.01,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 2, 'pre' condition (i.e. before news game intervention), and 'GoViral!' condition; values are calculated based on their data;
same `news_id` as study 1 because: 'Six of these 18 items were the same as those used in Study 1, the other 12 were selected using the same procedure as described in Study 1.'
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition)",yes,9,Germany,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,18,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,control,,,,,,,113,2.67,0.904,5.13,0.944,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 2, 'pre' condition (i.e. before news game intervention), and 'Infographics' condition; values are calculated based on their data;
same `news_id` as study 1 because: 'Six of these 18 items were the same as those used in Study 1, the other 12 were selected using the same procedure as described in Study 1.'
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition)",yes,10,Germany,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,18,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,control,,,,,,,162,2.93,1,4.78,1.03,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 2, 'post' condition (i.e. before news game intervention), and 'control' conditino; values are calculated based on their data;
same `news_id` as study 1 because: 'Six of these 18 items were the same as those used in Study 1, the other 12 were selected using the same procedure as described in Study 1.'
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition);
playing tetris was the control condition in this study, but since people re-rated the same items they saw before, it is coded as treatment here",yes,2,UK,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,18,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,treatment,neutral,familiarization,"playing tetris was the control condition in this study; the tetris thing can be expected to be neutral; 
but since people re-rated the same items they saw before, it is coded as treatment here, and called it ""familiarized""; we code this as neutral since, as far as we now, participants weren't corrected",,,,257,2.53,1.07,4.78,1.21,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 2, 'post' condition (i.e. before news game intervention), and 'GoViral!' condition; values are calculated based on their data;
same `news_id` as study 1 because: 'Six of these 18 items were the same as those used in Study 1, the other 12 were selected using the same procedure as described in Study 1.'
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition)",yes,3,UK,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,18,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,treatment,positive,multiple_familiarization_inoculationgame,Go Viral! Game,,,,212,2.02,0.922,4.44,1.31,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 2, 'post' condition (i.e. before news game intervention), and 'Infographics' condition; values are calculated based on their data;
same `news_id` as study 1 because: 'Six of these 18 items were the same as those used in Study 1, the other 12 were selected using the same procedure as described in Study 1.'
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition)",yes,4,UK,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,18,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,treatment,positive,multiple_familiarization_litteracyinfographic,UNESCO infographic,,,,241,2.31,0.987,4.85,1.3,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 2, 'post' condition (i.e. before news game intervention), and 'control' conditino; values are calculated based on their data;
attention: news items were coded as entire new set of items, but: 'Six of these 18 items were the same as those used in Study 1, the other 12 were selected using the same procedure as described in Study 1.'
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition)",yes,5,France,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,18,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,treatment,neutral,familiarization,"playing tetris was the control condition in this study; the tetris thing can be expected to be neutral; 
but since people re-rated the same items they saw before, it is coded as treatment here, and called it ""familiarized""",,,,215,2.91,1.05,4.57,1.15,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 2, 'post' condition (i.e. before news game intervention), and 'GoViral!' condition; values are calculated based on their data;
same `news_id` as study 1 because: 'Six of these 18 items were the same as those used in Study 1, the other 12 were selected using the same procedure as described in Study 1.'
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition)",yes,6,France,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,18,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,treatment,positive,multiple_familiarization_inoculationgame,Go Viral! Game,,,,207,2.34,1.09,4.39,1.27,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 2, 'post' condition (i.e. before news game intervention), and 'Infographics' condition; values are calculated based on their data;
same `news_id` as study 1 because: 'Six of these 18 items were the same as those used in Study 1, the other 12 were selected using the same procedure as described in Study 1.'
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition)",yes,7,France,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,18,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,treatment,positive,multiple_familiarization_litteracyinfographic,UNESCO infographic,,,,188,2.8,1.01,4.45,1.1,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 2, 'post' condition (i.e. before news game intervention), and 'control' conditino; values are calculated based on their data;
same `news_id` as study 1 because: 'Six of these 18 items were the same as those used in Study 1, the other 12 were selected using the same procedure as described in Study 1.'
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition)",yes,8,Germany,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,18,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,treatment,neutral,familiarization,"playing tetris was the control condition in this study;
but since people re-rated the same items they saw before, it is coded as treatment here",,,,182,2.79,0.972,4.6,1.14,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 2, 'post' condition (i.e. before news game intervention), and 'GoViral!' condition; values are calculated based on their data;
same `news_id` as study 1 because: 'Six of these 18 items were the same as those used in Study 1, the other 12 were selected using the same procedure as described in Study 1.'
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition)",yes,9,Germany,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,18,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,treatment,positive,multiple_familiarization_inoculationgame,Go Viral! Game,,,,113,2.27,1.01,4.82,1.22,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 2, 'post' condition (i.e. before news game intervention), and 'Infographics' condition; values are calculated based on their data;
same `news_id` as study 1 because: 'Six of these 18 items were the same as those used in Study 1, the other 12 were selected using the same procedure as described in Study 1.'
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition)",yes,10,Germany,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,18,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,treatment,positive,multiple_familiarization_litteracyinfographic,UNESCO infographic,,,,162,2.77,1.07,4.71,1.09,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 2, 'followup' condition (i.e. before news game intervention), and 'control' condition; values are calculated based on their data;
A week later, UK participants who completed the initial study were reinvited to partake in a follow-up,10 in which they completed the same item rating task (with manipulativeness, confidence and willingness to share as outcome measures) for 12 new, previously unseen social media posts (6 real and 6 misinformation, or 2 misinformation posts per technique learned in Go Viral!).;
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition);
playing tetris was the control condition in this study - since participants rated new news items and tetris can be assumed to have no effect, we actually code this as a control condition",yes,2,UK,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,2,12,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,control,,,,,,,235,2.36,1.11,5.17,1.13,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 2, 'followup' condition (i.e. before news game intervention), and 'Go!Viral' condition; values are calculated based on their data;
A week later, UK participants who completed the initial study were reinvited to partake in a follow-up,10 in which they completed the same item rating task (with manipulativeness, confidence and willingness to share as outcome measures) for 12 new, previously unseen social media posts (6 real and 6 misinformation, or 2 misinformation posts per technique learned in Go Viral!).;
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition);
playing tetris was the control condition in this study - since participants rated new news items and tetris can be assumed to have no effect, we actually code this as a control condition",yes,3,UK,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,2,12,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,treatment,positive,1weekbefore_inoculationgame,"Go Viral! Game;
A week later, UK participants who completed the initial study were reinvited to partake in a follow-up,10 in which they completed the same item rating task (with manipulativeness, confidence and willingness to share as outcome measures) for 12 new, previously unseen social media posts (6 real and 6 misinformation, or 2 misinformation posts per technique learned in Go Viral!).",,,,151,2.04,1.05,5.18,1.17,raw data,panel
26,"Basol, M., Roozenbeek, J., Berriche, M., Uenal, F., McClanahan, W. P., & Linden, S. van der. (2021). Towards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation. Big Data & Society, 8(1), 205395172110138. https://doi.org/10.1177/20539517211013868",Basol 2021,yes,,"data correspond to study 2, 'followup' condition (i.e. before news game intervention), and 'Infographics' condition; values are calculated based on their data;
A week later, UK participants who completed the initial study were reinvited to partake in a follow-up,10 in which they completed the same item rating task (with manipulativeness, confidence and willingness to share as outcome measures) for 12 new, previously unseen social media posts (6 real and 6 misinformation, or 2 misinformation posts per technique learned in Go Viral!).;
attention: effect of inoculation game might be confounded, because researchers used the same news items again (participants already saw them in the pre condition);
playing tetris was the control condition in this study - since participants rated new news items and tetris can be assumed to have no effect, we actually code this as a control condition",yes,4,UK,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,2,12,,0.5,pitch,nosource,manipulativeness,"asked to rate the manipulativeness of each post on a 1–7 Likert scale (1 being ‘not at all’ and 7 being ‘very’, following Saleh et al., 2021).;
scale was reversed for the coding here to match the other scales (i.e. higher number = less manipulative)",1,0,7,treatment,positive,1weekbefore_litteracyinfographic,"UNESCO infographic;
A week later, UK participants who completed the initial study were reinvited to partake in a follow-up,10 in which they completed the same item rating task (with manipulativeness, confidence and willingness to share as outcome measures) for 12 new, previously unseen social media posts (6 real and 6 misinformation, or 2 misinformation posts per technique learned in Go Viral!).",,,,220,2.27,1.04,5.38,1.18,raw data,panel
27,"Sultan, M., Tump, A. N., Geers, M., Lorenz-Spreen, P., Herzog, S. M., & Kurvers, R. H. J. M. (2022). Time pressure reduces misinformation discrimination ability but does not alter response bias. Scientific Reports, 12(1), 22416. https://doi.org/10.1038/s41598-022-26209-8",Sultan 2022,yes,,"data correspond to control (no time pressure) condition, for politically incogruent items; values are calculated based on data on osf;
news items have been pre-selected so that they avoid items with very high or very low accuracy - shouldn't affect our results for comparing fake and true news since it touches both sides equally, but of course inflates the absolute error for both sides",no,1,United States,within,yes,yes,"We selected a sample of news headlines from a previously pretested bank of 225 173 headlines (Pennycook et al., 2021), comprising both factually accurate (taken from 174 mainstream sources) and inaccurate (as determined by third-party fact-checking websites 175 such as Snopes.com) headlines. The headlines were presented in Facebook format and 176 consisted of an image, a headline, a byline, and a source. From this bank, we first removed 177 headlines for which the large majority of original veracity judgements were either correct or 178 incorrect, removing headlines with accuracy values greater or less than 1.5 times the 179 interquartile range (IQR). We next removed headlines that were originally judged to be 180 neutral in terms of political valence, that is, between 3.4 and 3.6 on a 7-point partisanship 181 scale (measured using the question: ‘Assuming the above headline is entirely accurate, how 182 favourable would it be to Democrats versus Republicans?’). Of the remaining headlines, we 183 randomly selected 24 headlines from each of the four possible categories (i.e., true, 184 Republican-leaning; true, Democratic-leaning; false, Republican-leaning; false, 185 Democratic-leaning), giving a total of 96 headlines. 186 We reassessed these headlines in a subsequent test (N participants = 150) conducted to 187 determine whether their political valence had changed since the original study by Pennycook et al. (2021). We used Spearman’s rank correlation to compare the political 189 valence ratings in our test sample with those in the original sample; the results showed a 190 strong positive association (r = .83, p <.001; see Figure A1). Of the 96 remaining 191 headlines, we removed those that were close to the partisan divide in our test sample, using 192 a bigger divide (i.e., excluding headlines with values between 3.2 and 3.8) while still 193 maintaining enough headlines in each category. Finally, we removed headlines that were 194 often judged as familiar (values >40%). The final selection consisted of 64 headlines (for 195 histograms of political valences, see Figure A2), which were randomly distributed into two 196 balanced sets of 32 headlines (16 true and 16 false). Each category of 16 headlines 197 contained eight Democratic-leaning and eight Republican-leaning headlines.",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_discordant,1,32,64,0.5,title_picture_pitch,source,accuracy,"‘Do you think the above headline is accurate?’ (‘Yes’ or ‘No’; veracity measure; in the 201 following, we refer to these responses as ‘true’ or ‘false’, respectively);",1,1,binary,control,,,,,,,382,0.2,0.4,0.644,0.479,raw data,no
27,"Sultan, M., Tump, A. N., Geers, M., Lorenz-Spreen, P., Herzog, S. M., & Kurvers, R. H. J. M. (2022). Time pressure reduces misinformation discrimination ability but does not alter response bias. Scientific Reports, 12(1), 22416. https://doi.org/10.1038/s41598-022-26209-8",Sultan 2022,yes,,"data correspond to control (no time pressure) condition, for politically cogruent items; values are calculated based on data on osf;
news items have been pre-selected so that they avoid items with very high or very low accuracy - shouldn't affect our results for comparing fake and true news since it touches both sides equally, but of course inflates the absolute error for both sides",no,1,United States,within,yes,yes,"We selected a sample of news headlines from a previously pretested bank of 225 173 headlines (Pennycook et al., 2021), comprising both factually accurate (taken from 174 mainstream sources) and inaccurate (as determined by third-party fact-checking websites 175 such as Snopes.com) headlines. The headlines were presented in Facebook format and 176 consisted of an image, a headline, a byline, and a source. From this bank, we first removed 177 headlines for which the large majority of original veracity judgements were either correct or 178 incorrect, removing headlines with accuracy values greater or less than 1.5 times the 179 interquartile range (IQR). We next removed headlines that were originally judged to be 180 neutral in terms of political valence, that is, between 3.4 and 3.6 on a 7-point partisanship 181 scale (measured using the question: ‘Assuming the above headline is entirely accurate, how 182 favourable would it be to Democrats versus Republicans?’). Of the remaining headlines, we 183 randomly selected 24 headlines from each of the four possible categories (i.e., true, 184 Republican-leaning; true, Democratic-leaning; false, Republican-leaning; false, 185 Democratic-leaning), giving a total of 96 headlines. 186 We reassessed these headlines in a subsequent test (N participants = 150) conducted to 187 determine whether their political valence had changed since the original study by Pennycook et al. (2021). We used Spearman’s rank correlation to compare the political 189 valence ratings in our test sample with those in the original sample; the results showed a 190 strong positive association (r = .83, p <.001; see Figure A1). Of the 96 remaining 191 headlines, we removed those that were close to the partisan divide in our test sample, using 192 a bigger divide (i.e., excluding headlines with values between 3.2 and 3.8) while still 193 maintaining enough headlines in each category. Finally, we removed headlines that were 194 often judged as familiar (values >40%). The final selection consisted of 64 headlines (for 195 histograms of political valences, see Figure A2), which were randomly distributed into two 196 balanced sets of 32 headlines (16 true and 16 false). Each category of 16 headlines 197 contained eight Democratic-leaning and eight Republican-leaning headlines.",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_concordant,1,32,64,0.5,title_picture_pitch,source,accuracy,"‘Do you think the above headline is accurate?’ (‘Yes’ or ‘No’; veracity measure; in the 201 following, we refer to these responses as ‘true’ or ‘false’, respectively);",1,1,binary,control,,,,,,,382,0.248,0.432,0.711,0.454,raw data,no
27,"Sultan, M., Tump, A. N., Geers, M., Lorenz-Spreen, P., Herzog, S. M., & Kurvers, R. H. J. M. (2022). Time pressure reduces misinformation discrimination ability but does not alter response bias. Scientific Reports, 12(1), 22416. https://doi.org/10.1038/s41598-022-26209-8",Sultan 2022,yes,,"data correspond to treatment (time pressure) condition, for politically incogruent items; values are calculated based on data on osf;
news items have been pre-selected so that they avoid items with very high or very low accuracy - shouldn't affect our results for comparing fake and true news since it touches both sides equally, but of course inflates the absolute error for both sides",no,2,United States,within,yes,yes,"We selected a sample of news headlines from a previously pretested bank of 225 173 headlines (Pennycook et al., 2021), comprising both factually accurate (taken from 174 mainstream sources) and inaccurate (as determined by third-party fact-checking websites 175 such as Snopes.com) headlines. The headlines were presented in Facebook format and 176 consisted of an image, a headline, a byline, and a source. From this bank, we first removed 177 headlines for which the large majority of original veracity judgements were either correct or 178 incorrect, removing headlines with accuracy values greater or less than 1.5 times the 179 interquartile range (IQR). We next removed headlines that were originally judged to be 180 neutral in terms of political valence, that is, between 3.4 and 3.6 on a 7-point partisanship 181 scale (measured using the question: ‘Assuming the above headline is entirely accurate, how 182 favourable would it be to Democrats versus Republicans?’). Of the remaining headlines, we 183 randomly selected 24 headlines from each of the four possible categories (i.e., true, 184 Republican-leaning; true, Democratic-leaning; false, Republican-leaning; false, 185 Democratic-leaning), giving a total of 96 headlines. 186 We reassessed these headlines in a subsequent test (N participants = 150) conducted to 187 determine whether their political valence had changed since the original study by Pennycook et al. (2021). We used Spearman’s rank correlation to compare the political 189 valence ratings in our test sample with those in the original sample; the results showed a 190 strong positive association (r = .83, p <.001; see Figure A1). Of the 96 remaining 191 headlines, we removed those that were close to the partisan divide in our test sample, using 192 a bigger divide (i.e., excluding headlines with values between 3.2 and 3.8) while still 193 maintaining enough headlines in each category. Finally, we removed headlines that were 194 often judged as familiar (values >40%). The final selection consisted of 64 headlines (for 195 histograms of political valences, see Figure A2), which were randomly distributed into two 196 balanced sets of 32 headlines (16 true and 16 false). Each category of 16 headlines 197 contained eight Democratic-leaning and eight Republican-leaning headlines.",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_discordant,1,32,64,0.5,title_picture_pitch,source,accuracy,"‘Do you think the above headline is accurate?’ (‘Yes’ or ‘No’; veracity measure; in the 201 following, we refer to these responses as ‘true’ or ‘false’, respectively);",1,1,binary,treatment,,time_pressure,"In the time-pressure treatment, participants had to respond to the veracity question within 6 seconds, a time interval informed by a pilot study",,,,378,0.236,0.425,0.617,0.486,raw data,no
27,"Sultan, M., Tump, A. N., Geers, M., Lorenz-Spreen, P., Herzog, S. M., & Kurvers, R. H. J. M. (2022). Time pressure reduces misinformation discrimination ability but does not alter response bias. Scientific Reports, 12(1), 22416. https://doi.org/10.1038/s41598-022-26209-8",Sultan 2022,yes,,"data correspond to treatment (time pressure) condition, for politically cogruent items; values are calculated based on data on osf;
news items have been pre-selected so that they avoid items with very high or very low accuracy - shouldn't affect our results for comparing fake and true news since it touches both sides equally, but of course inflates the absolute error for both sides",no,2,United States,within,yes,yes,"We selected a sample of news headlines from a previously pretested bank of 225 173 headlines (Pennycook et al., 2021), comprising both factually accurate (taken from 174 mainstream sources) and inaccurate (as determined by third-party fact-checking websites 175 such as Snopes.com) headlines. The headlines were presented in Facebook format and 176 consisted of an image, a headline, a byline, and a source. From this bank, we first removed 177 headlines for which the large majority of original veracity judgements were either correct or 178 incorrect, removing headlines with accuracy values greater or less than 1.5 times the 179 interquartile range (IQR). We next removed headlines that were originally judged to be 180 neutral in terms of political valence, that is, between 3.4 and 3.6 on a 7-point partisanship 181 scale (measured using the question: ‘Assuming the above headline is entirely accurate, how 182 favourable would it be to Democrats versus Republicans?’). Of the remaining headlines, we 183 randomly selected 24 headlines from each of the four possible categories (i.e., true, 184 Republican-leaning; true, Democratic-leaning; false, Republican-leaning; false, 185 Democratic-leaning), giving a total of 96 headlines. 186 We reassessed these headlines in a subsequent test (N participants = 150) conducted to 187 determine whether their political valence had changed since the original study by Pennycook et al. (2021). We used Spearman’s rank correlation to compare the political 189 valence ratings in our test sample with those in the original sample; the results showed a 190 strong positive association (r = .83, p <.001; see Figure A1). Of the 96 remaining 191 headlines, we removed those that were close to the partisan divide in our test sample, using 192 a bigger divide (i.e., excluding headlines with values between 3.2 and 3.8) while still 193 maintaining enough headlines in each category. Finally, we removed headlines that were 194 often judged as familiar (values >40%). The final selection consisted of 64 headlines (for 195 histograms of political valences, see Figure A2), which were randomly distributed into two 196 balanced sets of 32 headlines (16 true and 16 false). Each category of 16 headlines 197 contained eight Democratic-leaning and eight Republican-leaning headlines.",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_concordant,1,32,64,0.5,title_picture_pitch,source,accuracy,"‘Do you think the above headline is accurate?’ (‘Yes’ or ‘No’; veracity measure; in the 201 following, we refer to these responses as ‘true’ or ‘false’, respectively);",1,1,binary,treatment,,time_pressure,"In the time-pressure treatment, participants had to respond to the veracity question within 6 seconds, a time interval informed by a pilot study",,,,378,0.293,0.455,0.695,0.461,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 1, 'experimental' condition (i.e. incentives to rate news as accurate), for politically concordant items; values are calculated based on their data;",yes,1,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_concordant,1,8,,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,treatment,,pay_for_accuracy,"Half of the participants were randomly assigned to theaccuracyincentivescondition. In this condition, participants were told they would receive a small bonus payment of up to one dollar based on how many correct answers they could provide regarding the accuracy of the articles. The other half of participants were assigned to acontrolconditionin which they were asked the same questions about accuracy and sharing without any incentive to be accurate.",,,,228,2.53,1.68,3.98,1.68,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 1, 'experimental' condition (i.e. incentives to rate news as accurate), for politically discordant items; values are calculated based on their data;",yes,1,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_discordant,2,8,,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,treatment,,pay_for_accuracy,"Half of the participants were randomly assigned to theaccuracyincentivescondition. In this condition, participants were told they would receive a small bonus payment of up to one dollar based on how many correct answers they could provide regarding the accuracy of the articles. The other half of participants were assigned to acontrolconditionin which they were asked the same questions about accuracy and sharing without any incentive to be accurate.",,,,228,1.88,1.31,3.29,1.75,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 1, 'control' condition (i.e.NO  incentives to rate news as accurate), for politically concordant items; values are calculated based on their data;",yes,2,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_concordant,1,8,,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,control,,,,,,,234,2.61,1.63,3.85,1.6,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 1, 'control' condition (i.e.NO  incentives to rate news as accurate), for politically discordant items; values are calculated based on their data;",yes,2,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_discordant,2,8,,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,control,,,,,,,234,1.72,1.1,2.92,1.63,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 2, 'accuracy' condition (i.e. monetary incentive to rate news as accurate), for politically concordant items; values are calculated based on their data;",yes,3,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_concordant,1,8,,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,treatment,,pay_for_accuracy,"Half of the participants were randomly assigned to theaccuracyincentivescondition. In this condition, participants were told they would receive a small bonus payment of up to one dollar based on how many correct answers they could provide regarding the accuracy of the articles. The other half of participants were assigned to acontrolconditionin which they were asked the same questions about accuracy and sharing without any incentive to be accurate.",,,,245,2.61,1.75,3.99,1.67,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 2, 'accuracy' condition (i.e. monetary incentive to rate news as accurate), for politically discordant items; values are calculated based on their data;",yes,3,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_discordant,2,8,,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,treatment,,pay_for_accuracy,"Half of the participants were randomly assigned to theaccuracyincentivescondition. In this condition, participants were told they would receive a small bonus payment of up to one dollar based on how many correct answers they could provide regarding the accuracy of the articles. The other half of participants were assigned to acontrolconditionin which they were asked the same questions about accuracy and sharing without any incentive to be accurate.",,,,245,1.94,1.4,3.45,1.8,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 2, 'control' condition (i.e.NO  incentives to rate news whatsoever), for politically concordant items; values are calculated based on their data;",yes,4,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_concordant,1,8,,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,control,,,,,,,257,2.69,1.69,3.74,1.68,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 2, 'control' condition (i.e.NO  incentives to rate news whatsoever), for politically discordant items; values are calculated based on their data;",yes,4,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_discordant,2,8,,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,control,,,,,,,257,1.9,1.31,2.9,1.62,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 2, 'social' condition (i.e. monetary incentive to estimate how much fellow party members would appreciate the news), for politically concordant items; values are calculated based on their data;",yes,5,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_concordant,1,8,,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,treatment,,pay_for_estimate_likeability_ofonesparty,"Making social ties salient: In the new socialincentivescondition, participants were rst asked before the experiment to report the political party with which they identify. Then, they were told that they would receive a bonus payment of up to $1.00 based on how accurately they identi ed information that would be liked by members of their political party if they shared it on social media. Bonuses were awarded based on how closely participants’ answers matched partisan alignment scores from a pre-test 48. Before each question about accuracy and sharing, participants were asked “If you shared this article on social media, how likely is it that it would receive a positive reaction from [your political party] (e.g., likes, shares, and positive comments)?”",,,,248,2.67,1.63,3.61,1.61,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 2, 'social' condition (i.e. monetary incentive to estimate how much fellow party members would appreciate the news), for politically discordant items; values are calculated based on their data;",yes,5,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_discordant,2,8,,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,treatment,,pay_for_estimate_likeability_ofonesparty,"Making social ties salient: In the new socialincentivescondition, participants were rst asked before the experiment to report the political party with which they identify. Then, they were told that they would receive a bonus payment of up to $1.00 based on how accurately they identi ed information that would be liked by members of their political party if they shared it on social media. Bonuses were awarded based on how closely participants’ answers matched partisan alignment scores from a pre-test 48. Before each question about accuracy and sharing, participants were asked “If you shared this article on social media, how likely is it that it would receive a positive reaction from [your political party] (e.g., likes, shares, and positive comments)?”",,,,248,1.88,1.27,2.77,1.63,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 2, 'mixed' condition (i.e. monetary incentive to estimate both accuracy AND how much fellow party members would appreciate the news), for politically concordant items; values are calculated based on their data;",yes,6,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_concordant,1,8,,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,treatment,,multiple_payforaccuracy_payforestimatelikeabilityofonesparty,"In the mixedincentivescondition, participants were rst given nancial incentives for both correctly identifying whether the article would be liked by a member of their political party, and were then asked about accuracy and given incentives for identifying whether the article was accurate.",,,,248,2.68,1.73,3.9,1.63,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 2, 'mixed' condition (i.e. monetary incentive to estimate both accuracy AND how much fellow party members would appreciate the news), for politically concordant items; values are calculated based on their data;",yes,6,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_discordant,2,8,,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,treatment,,multiple_payforaccuracy_payforestimatelikeabilityofonesparty,"In the mixedincentivescondition, participants were rst given nancial incentives for both correctly identifying whether the article would be liked by a member of their political party, and were then asked about accuracy and given incentives for identifying whether the article was accurate.",,,,248,1.97,1.46,3.19,1.76,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 3, 'accuracy (source) ' condition (i.e. monetary incentive to rate news as accurate + display of source), for politically concordant items; values are calculated based on their data;
same `news_id` as studies 1 and 2 because:  ""We once again used the same 16 pre-tested true and false news headlines in addition to eight extra true and false news items from the same pre-test. For consistency, we report the results of the 16 news items in the manuscript, but we also report the results for the full set of 24 items in theSupplementaryMaterials S9,which did not change our conclusions.""",yes,7,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_concordant,1,12,,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,treatment,,pay_for_accuracy,"Half of the participants were randomly assigned to theaccuracyincentivescondition. In this condition, participants were told they would receive a small bonus payment of up to one dollar based on how many correct answers they could provide regarding the accuracy of the articles. The other half of participants were assigned to acontrolconditionin which they were asked the same questions about accuracy and sharing without any incentive to be accurate.;
In addition to the accuracy incentive and control condition, participants were assigned to identical accuracy incentive and control conditionswithoutsourcecuespresent on the stimuli. In these conditions, the sources (e.g., “nytimes.com”) were greyed out, so participants could only make assessments of the stimuli based on the photo and headline alone",,,,229,2.71,1.76,4.29,1.7,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 3, 'accuracy (source) ' condition (i.e. monetary incentive to rate news as accurate + display of source), for politically discordant items; values are calculated based on their data;
same `news_id` as studies 1 and 2 because: ""We once again used the same 16 pre-tested true and false news headlines in addition to eight extra true and false news items from the same pre-test. For consistency, we report the results of the 16 news items in the manuscript, but we also report the results for the full set of 24 items in theSupplementaryMaterials S9,which did not change our conclusions.""",yes,7,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_discordant,2,12,,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,treatment,,pay_for_accuracy,"Half of the participants were randomly assigned to theaccuracyincentivescondition. In this condition, participants were told they would receive a small bonus payment of up to one dollar based on how many correct answers they could provide regarding the accuracy of the articles. The other half of participants were assigned to acontrolconditionin which they were asked the same questions about accuracy and sharing without any incentive to be accurate.;
In addition to the accuracy incentive and control condition, participants were assigned to identical accuracy incentive and control conditionswithoutsourcecuespresent on the stimuli. In these conditions, the sources (e.g., “nytimes.com”) were greyed out, so participants could only make assessments of the stimuli based on the photo and headline alone",,,,229,2.15,1.52,3.69,1.78,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 3, 'control (source) ' condition (i.e. NO monetary incentive to rate news as accurate + display of source), for politically concordant items; values are calculated based on their data;
same `news_id` as studies 1 and 2 because: ""We once again used the same 16 pre-tested true and false news headlines in addition to eight extra true and false news items from the same pre-test. For consistency, we report the results of the 16 news items in the manuscript, but we also report the results for the full set of 24 items in theSupplementaryMaterials S9,which did not change our conclusions.""",yes,8,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_concordant,1,12,,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,control,,,,,,,235,2.76,1.68,4.1,1.67,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 3, 'control (source) ' condition (i.e. NO monetary incentive to rate news as accurate + display of source), for politically discordant items; values are calculated based on their data;
same `news_id` as studies 1 and 2 because: ""We once again used the same 16 pre-tested true and false news headlines in addition to eight extra true and false news items from the same pre-test. For consistency, we report the results of the 16 news items in the manuscript, but we also report the results for the full set of 24 items in theSupplementaryMaterials S9,which did not change our conclusions.""",yes,8,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_discordant,2,12,,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,control,,,,,,,235,1.88,1.33,3.3,1.72,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 3, 'accuracy (NO source) ' condition (i.e. monetary incentive to rate news as accurate + NO display of source), for politically concordant items; values are calculated based on their data;
same `news_id` as studies 1 and 2 because: ""We once again used the same 16 pre-tested true and false news headlines in addition to eight extra true and false news items from the same pre-test. For consistency, we report the results of the 16 news items in the manuscript, but we also report the results for the full set of 24 items in theSupplementaryMaterials S9,which did not change our conclusions.""",yes,9,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_concordant,1,12,,0.5,title_picture,nosource,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,treatment,,pay_for_accuracy,"Half of the participants were randomly assigned to theaccuracyincentivescondition. In this condition, participants were told they would receive a small bonus payment of up to one dollar based on how many correct answers they could provide regarding the accuracy of the articles. The other half of participants were assigned to acontrolconditionin which they were asked the same questions about accuracy and sharing without any incentive to be accurate.;
In addition to the accuracy incentive and control condition, participants were assigned to identical accuracy incentive and control conditionswithoutsourcecuespresent on the stimuli. In these conditions, the sources (e.g., “nytimes.com”) were greyed out, so participants could only make assessments of the stimuli based on the photo and headline alone",,,,221,2.78,1.75,4.07,1.7,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 3, 'accuracy (NO source) ' condition (i.e. monetary incentive to rate news as accurate + NO display of source), for politically discordant items; values are calculated based on their data;
same `news_id` as studies 1 and 2 because: ""We once again used the same 16 pre-tested true and false news headlines in addition to eight extra true and false news items from the same pre-test. For consistency, we report the results of the 16 news items in the manuscript, but we also report the results for the full set of 24 items in theSupplementaryMaterials S9,which did not change our conclusions.""",yes,9,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_discordant,2,12,,0.5,title_picture,nosource,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,treatment,,pay_for_accuracy,"Half of the participants were randomly assigned to theaccuracyincentivescondition. In this condition, participants were told they would receive a small bonus payment of up to one dollar based on how many correct answers they could provide regarding the accuracy of the articles. The other half of participants were assigned to acontrolconditionin which they were asked the same questions about accuracy and sharing without any incentive to be accurate.;
In addition to the accuracy incentive and control condition, participants were assigned to identical accuracy incentive and control conditionswithoutsourcecuespresent on the stimuli. In these conditions, the sources (e.g., “nytimes.com”) were greyed out, so participants could only make assessments of the stimuli based on the photo and headline alone",,,,221,2.07,1.44,3.5,1.76,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 3, 'control (NO source)' condition (i.e. NO monetary incentive to rate news as accurate + NO display of source), for politically concordant items; values are calculated based on their data;
same `news_id` as studies 1 and 2 because: ""We once again used the same 16 pre-tested true and false news headlines in addition to eight extra true and false news items from the same pre-test. For consistency, we report the results of the 16 news items in the manuscript, but we also report the results for the full set of 24 items in theSupplementaryMaterials S9,which did not change our conclusions.""",yes,10,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_concordant,1,12,,0.5,title_picture,nosource,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,control,,,,,,,236,2.89,1.72,4.08,1.59,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 3, 'control (NO source)' condition (i.e. NO monetary incentive to rate news as accurate + NO display of source), for politically discordant items; values are calculated based on their data;
same `news_id` as studies 1 and 2 because:""We once again used the same 16 pre-tested true and false news headlines in addition to eight extra true and false news items from the same pre-test. For consistency, we report the results of the 16 news items in the manuscript, but we also report the results for the full set of 24 items in theSupplementaryMaterials S9,which did not change our conclusions.""",yes,10,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_discordant,2,12,,0.5,title_picture,nosource,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,control,,,,,,,236,2.14,1.45,3.25,1.71,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 4, 'control' condition (i.e. NO monetary incentive to rate news as accurate), for politically concordant items; values are calculated based on their data;
attention: weirdly, in the paper (including supplements) they only report 3 studies. But they did a fourth one, data is available, and also analysis code and pre-registration;  it is thus included here;
it seems that the study meant to extend findings from study one (financial accuracy incentives vs. control), and compare financial incentives to a non-financial accuracy motivation - since we don't know what this treamtement condition consists of, however, we will only report data for control and financial conditions (which we can reasonably assume to be the same as those reported in the paper - the authors themselves use this data in the integrative analysis they do, BUT DONT REPORT IT AT ALL!)
attention: although coded as such here, I am not certain that the news items used are the same 16 as in the first study (but it seems reasonable to assume that, all other studies at least included the same 16 items)",yes,11,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_concordant,1,8,,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,control,,,,,,,341,2.53,1.69,3.68,1.71,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 4, 'control' condition (i.e. NO monetary incentive to rate news as accurate), for politically discordant items; values are calculated based on their data;
attention: weirdly, in the paper (including supplements) they only report 3 studies. But they did a fourth one, data is available, and also analysis code and pre-registration;  it is thus included here;
it seems that the study meant to extend findings from study one (financial accuracy incentives vs. control), and compare financial incentives to a non-financial accuracy motivation - since we don't know what this treamtement condition consists of, however, we will only report data for control and financial conditions (which we can reasonably assume to be the same as those reported in the paper - the authors themselves use this data in the integrative analysis they do, BUT DONT REPORT IT AT ALL!)
attention: although coded as such here, I am not certain that the news items used are the same 16 as in the first study (but it seems reasonable to assume that, all other studies at least included the same 16 items)",yes,11,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_discordant,2,8,,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,control,,,,,,,341,1.72,1.2,2.76,1.66,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 4, 'accuracy (financial)' condition (i.e. monetary incentive to rate news as accurate), for politically concordant items; values are calculated based on their data;
attention: weirdly, in the paper (including supplements) they only report 3 studies. But they did a fourth one, data is available, and also analysis code and pre-registration;  it is thus included here;
it seems that the study meant to extend findings from study one (financial accuracy incentives vs. control), and compare financial incentives to a non-financial accuracy motivation - since we don't know what this treamtement condition consists of, however, we will only report data for control and financial conditions (which we can reasonably assume to be the same as those reported in the paper - the authors themselves use this data in the integrative analysis they do, BUT DONT REPORT IT AT ALL!)
attention: although coded as such here, I am not certain that the news items used are the same 16 as in the first study (but it seems reasonable to assume that, all other studies at least included the same 16 items)",yes,12,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_concordant,1,8,,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,treatment,,pay_for_accuracy,"Half of the participants were randomly assigned to theaccuracyincentivescondition. In this condition, participants were told they would receive a small bonus payment of up to one dollar based on how many correct answers they could provide regarding the accuracy of the articles. The other half of participants were assigned to acontrolconditionin which they were asked the same questions about accuracy and sharing without any incentive to be accurate.",,,,323,2.5,1.68,3.84,1.7,raw data,no
28,"Rathje, S., Roozenbeek, J., Van Bavel, J.J. et al. Accuracy and social motivations shape judgements of (mis)information. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01540-w",Rathje 2023,yes,,"data correspond to study 4, 'accuracy (financial)' condition (i.e. monetary incentive to rate news as accurate), for politically discordant items; values are calculated based on their data;
attention: weirdly, in the paper (including supplements) they only report 3 studies. But they did a fourth one, data is available, and also analysis code and pre-registration;  it is thus included here;
it seems that the study meant to extend findings from study one (financial accuracy incentives vs. control), and compare financial incentives to a non-financial accuracy motivation - since we don't know what this treamtement condition consists of, however, we will only report data for control and financial conditions (which we can reasonably assume to be the same as those reported in the paper - the authors themselves use this data in the integrative analysis they do, BUT DONT REPORT IT AT ALL!)
attention: although coded as such here, I am not certain that the news items used are the same 16 as in the first study (but it seems reasonable to assume that, all other studies at least included the same 16 items)",yes,12,United States,within,yes,yes,"They did something a bit special normally, when people want to look at whether partisan content influences accuracy perceptions, items are only pre-tested to which extent they are partisan; here, however, they went further, picking those that partisans from either side rated as more accurate than the other side - in other words, they should find that concordance influences accuracy perceptions in the control condition, because that's how they selected their stimuli in the first place; because they are testing an intervention, it doesn't matter much for them - but it might be relevant for analysis we might make. Here's the selection procedure:
""were 16 pre-tested true and false news headlines from a large pre-tested sample of 225 news headlines60. In total, eight of these news headlines were false, and eight of the news headlines were true. Because we were interested in whether accuracy incentives would reduce partisan bias, we speci cally selected headlines that had a sizable gap in perceived accuracy between Republicans and Democrats as reported in the pre-test, as well as headlines that were not outdated (the pre-test was conducted a few months before the rst experiment). Speci cally, we chose eight headlines (four false and four true) that Democrats rated as more accurate than Republicans in the pre-test, and eight headlines (four false and four true) that Republicans rated as more accurate than Democrats.""",recycled,"Pennycook, G., Binnendyk, J., Newton, C., & Rand, D. G. (2021). A Practical Guide to Doing Behavioral Research on Fake News and Misinformation. Collabra: Psychology, 7(1), 25293. https://doi.org/10.1525/collabra.25293",researchers,fact_checking,mainstream,politically_discordant,2,8,,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” on a scale from 1 (“extremely inaccurate”) to 6 (“extremely accurate”",1,1,6,treatment,,pay_for_accuracy,"Half of the participants were randomly assigned to theaccuracyincentivescondition. In this condition, participants were told they would receive a small bonus payment of up to one dollar based on how many correct answers they could provide regarding the accuracy of the articles. The other half of participants were assigned to acontrolconditionin which they were asked the same questions about accuracy and sharing without any incentive to be accurate.",,,,323,1.8,1.27,3.2,1.74,raw data,no
29,"Pehlivanoglu, D., Lin, T., Deceus, F., Heemskerk, A., Ebner, N. C., & Cahill, B. S. (2021). The role of analytical reasoning and source credibility on the evaluation of real and fake full-length news articles. Cognitive Research: Principles and Implications, 6(1), 24. https://doi.org/10.1186/s41235-021-00292-3",Pehlivanoglu 2021,,,"data correspond to study 1; values calculated based on their data; 
Attention: we only looked at a subset (half, to be precise) of their observations (we excluded those news items that were matched with an unrealistic source, e.g. when fake news were said to come from new york times, or when true news came from Liberty Writers News (non credible));
This resulted in a de-facto between participant design (with regard to the factor veracity, i.e. participants either only saw 'realistic' true news or only saw 'realistic' fake news, with regard to the source);
Further details in the analysis code;
Attention: undergraduate sample, recruited via ""Department of Psychology’s SONA system"" - no idea what the heck that is, but since they are all from the states I put US sample",yes,1,United States,between,yes,no,,original,,researchers,fact_checking,mainstream,,1,12,,0.5,Full_articles,source,accuracy," accuracy (Is this news article real or fake?; response option: Real vs. Fake),",1,1,binary,control,,,,,,,292,0.297,0.457,0.829,0.377,raw data,no
29,"Pehlivanoglu, D., Lin, T., Deceus, F., Heemskerk, A., Ebner, N. C., & Cahill, B. S. (2021). The role of analytical reasoning and source credibility on the evaluation of real and fake full-length news articles. Cognitive Research: Principles and Implications, 6(1), 24. https://doi.org/10.1186/s41235-021-00292-3",Pehlivanoglu 2021,,,"data correspond to study 1; values calculated based on their data; 
Attention: we only looked at a subset (half, to be precise) of their observations (we excluded those news items that were matched with an unrealistic source, e.g. when fake news were said to come from new york times, or when true news came from Liberty Writers News (non credible));
This resulted in a de-facto between participant design (with regard to the factor veracity, i.e. participants either only saw 'realistic' true news or only saw 'realistic' fake news, with regard to the source);
Further details in the analysis code;
Attention: undergraduate sample, recruited via ""Department of Psychology’s SONA system"" - no idea what the heck that is, but since they are all from the states I put US sample",yes,1,United States,between,yes,no,,original,,researchers,fact_checking,mainstream,,1,12,,0.5,Full_articles,source,credibility,"perceived credibility (How credible do you find this news article?; response option: 1 (Not at all credible) to 10 (Completely credible)),",1,1,10,control,,,,,,,292,5.56,2.22,8.15,1.9,raw data,no
29,"Pehlivanoglu, D., Lin, T., Deceus, F., Heemskerk, A., Ebner, N. C., & Cahill, B. S. (2021). The role of analytical reasoning and source credibility on the evaluation of real and fake full-length news articles. Cognitive Research: Principles and Implications, 6(1), 24. https://doi.org/10.1186/s41235-021-00292-3",Pehlivanoglu 2021,,,"data correspond to study 2; values calculated based on their data; 
Attention: we only looked at a subset (half, to be precise) of their observations (we excluded those news items that were matched with an unrealistic source, e.g. when fake news were said to come from new york times, or when true news came from Liberty Writers News (non credible));
This resulted in a de-facto between participant design (with regard to the factor veracity, i.e. participants either only saw 'realistic' true news or only saw 'realistic' fake news, with regard to the source);
Further details in the analysis code;
Attention: undergraduate sample, recruited via ""Department of Psychology’s SONA system"" - no idea what the heck that is, but since they are all from the states I put US sample",yes,2,United States,between,yes,no,,original,,researchers,fact_checking,mainstream,,1,12,,0.5,Full_articles,source,accuracy," accuracy (Is this news article real or fake?; response option: Real vs. Fake),",1,1,binary,control,,,,,,,357,0.265,0.442,0.803,0.398,raw data,no
29,"Pehlivanoglu, D., Lin, T., Deceus, F., Heemskerk, A., Ebner, N. C., & Cahill, B. S. (2021). The role of analytical reasoning and source credibility on the evaluation of real and fake full-length news articles. Cognitive Research: Principles and Implications, 6(1), 24. https://doi.org/10.1186/s41235-021-00292-3",Pehlivanoglu 2021,,,"data correspond to study 2; values calculated based on their data; 
Attention: we only looked at a subset (half, to be precise) of their observations (we excluded those news items that were matched with an unrealistic source, e.g. when fake news were said to come from new york times, or when true news came from Liberty Writers News (non credible));
This resulted in a de-facto between participant design (with regard to the factor veracity, i.e. participants either only saw 'realistic' true news or only saw 'realistic' fake news, with regard to the source);
Further details in the analysis code;
Attention: undergraduate sample, recruited via ""Department of Psychology’s SONA system"" - no idea what the heck that is, but since they are all from the states I put US sample",yes,2,United States,between,yes,no,,original,,researchers,fact_checking,mainstream,,1,12,,0.5,Full_articles,source,credibility,"perceived credibility (How credible do you find this news article?; response option: 1 (Not at all credible) to 10 (Completely credible)),",1,1,10,control,,,,,,,357,5.71,2.26,8.34,1.88,raw data,no
30,"Arechar, A. A., Allen, J., Berinsky, A. J., Cole, R., Epstein, Z., Garimella, K., Gully, A., Lu, J. G., Ross, R. M., Stagnaro, M. N., Zhang, Y., Pennycook, G., & Rand, D. G. (2023). Understanding and combatting misinformation across 16 countries on six continents. Nature Human Behaviour, 7(9), 1502–1513. https://doi.org/10.1038/s41562-023-01641-6",Arechar 2022,,,"data correspond to 'accuracy condition'; values in the paper are only displayed in fig. 1, upon request authors sent means and standard deviations;
sample sizes are taken from supplementary material, table S1; Only in 'accuracy condition' participants rated accuracy - since this was only one of four conditions that participants got randomly assigned to, we divide sample size by 4;
attention: original scale was from 1 to 6; upon request via e-mail, they explained they transposed this as follows to a scale from 0 to 1: ""This is how it was done: rating=(rating-1)/5,This way, resulting values went from 1,2,3,4,5,6 to 0,.2,.4,.6,.8,1""",no,1,Argentina,within,yes,yes,"seems as if fake news had been selected to not appear too true and true news to not appear too fake (fig. S1, supplementary material); so the potential bias from this should bias fake and true news equally (i.e. both errors should be underestimated);
""Specifically, we started with a list of 69 true and false headlines gathered from various sources online. Of those, we discarded 9 that involved a particular country or public figure (e.g. Donald Trump), as the relevance of those headlines was likely to vary considerably across countries (this was further confirmed by a group of researchers, native from the countries selected, expressly contacted to get feedback on such headlines). We then conducted a pilot survey using participants from the United States in which we measured the accuracy ratings and sharing intentions for each of the 60 headlines (see Fig S1). Based on these pre-test ratings, we choose a set of 30 false headlines and 15 true headlines that were clearly differentiated and reasonably representative.""",original,,researchers,fact_checking,mainstream,covid,1,20,45,0.5,title,,accuracy,"We asked them to assess either the accuracy of a headline in the Accuracy condition (“To the best of your knowledge, is the above headline accurate?” 6-point Likert scale)",1,1,1,control,,,,,,,510,0.305984,0.331981,0.583454,0.327866,authors,no
30,"Arechar, A. A., Allen, J., Berinsky, A. J., Cole, R., Epstein, Z., Garimella, K., Gully, A., Lu, J. G., Ross, R. M., Stagnaro, M. N., Zhang, Y., Pennycook, G., & Rand, D. G. (2023). Understanding and combatting misinformation across 16 countries on six continents. Nature Human Behaviour, 7(9), 1502–1513. https://doi.org/10.1038/s41562-023-01641-6",Arechar 2022,,,"data correspond to 'accuracy condition'; values in the paper are only displayed in fig. 1, upon request authors sent means and standard deviations;
sample sizes are taken from supplementary material, table S1; Only in 'accuracy condition' participants rated accuracy - since this was only one of four conditions that participants got randomly assigned to, we divide sample size by 4;
attention: original scale was from 1 to 6; upon request via e-mail, they explained they transposed this as follows to a scale from 0 to 1: ""This is how it was done: rating=(rating-1)/5,This way, resulting values went from 1,2,3,4,5,6 to 0,.2,.4,.6,.8,1""",no,2,Australia,within,yes,yes,"seems as if fake news had been selected to not appear too true and true news to not appear too fake (fig. S1, supplementary material); so the potential bias from this should bias fake and true news equally (i.e. both errors should be underestimated);
""Specifically, we started with a list of 69 true and false headlines gathered from various sources online. Of those, we discarded 9 that involved a particular country or public figure (e.g. Donald Trump), as the relevance of those headlines was likely to vary considerably across countries (this was further confirmed by a group of researchers, native from the countries selected, expressly contacted to get feedback on such headlines). We then conducted a pilot survey using participants from the United States in which we measured the accuracy ratings and sharing intentions for each of the 60 headlines (see Fig S1). Based on these pre-test ratings, we choose a set of 30 false headlines and 15 true headlines that were clearly differentiated and reasonably representative.""",original,,researchers,fact_checking,mainstream,covid,1,20,45,0.5,title,,accuracy,"We asked them to assess either the accuracy of a headline in the Accuracy condition (“To the best of your knowledge, is the above headline accurate?” 6-point Likert scale)",1,1,1,control,,,,,,,520,0.255109,0.310199,0.55154,0.327053,authors,no
30,"Arechar, A. A., Allen, J., Berinsky, A. J., Cole, R., Epstein, Z., Garimella, K., Gully, A., Lu, J. G., Ross, R. M., Stagnaro, M. N., Zhang, Y., Pennycook, G., & Rand, D. G. (2023). Understanding and combatting misinformation across 16 countries on six continents. Nature Human Behaviour, 7(9), 1502–1513. https://doi.org/10.1038/s41562-023-01641-6",Arechar 2022,,,"data correspond to 'accuracy condition'; values in the paper are only displayed in fig. 1, upon request authors sent means and standard deviations;
sample sizes are taken from supplementary material, table S1; Only in 'accuracy condition' participants rated accuracy - since this was only one of four conditions that participants got randomly assigned to, we divide sample size by 4;
attention: original scale was from 1 to 6; upon request via e-mail, they explained they transposed this as follows to a scale from 0 to 1: ""This is how it was done: rating=(rating-1)/5,This way, resulting values went from 1,2,3,4,5,6 to 0,.2,.4,.6,.8,1""",no,3,Brazil,within,yes,yes,"seems as if fake news had been selected to not appear too true and true news to not appear too fake (fig. S1, supplementary material); so the potential bias from this should bias fake and true news equally (i.e. both errors should be underestimated);
""Specifically, we started with a list of 69 true and false headlines gathered from various sources online. Of those, we discarded 9 that involved a particular country or public figure (e.g. Donald Trump), as the relevance of those headlines was likely to vary considerably across countries (this was further confirmed by a group of researchers, native from the countries selected, expressly contacted to get feedback on such headlines). We then conducted a pilot survey using participants from the United States in which we measured the accuracy ratings and sharing intentions for each of the 60 headlines (see Fig S1). Based on these pre-test ratings, we choose a set of 30 false headlines and 15 true headlines that were clearly differentiated and reasonably representative.""",original,,researchers,fact_checking,mainstream,covid,1,20,45,0.5,title,,accuracy,"We asked them to assess either the accuracy of a headline in the Accuracy condition (“To the best of your knowledge, is the above headline accurate?” 6-point Likert scale)",1,1,1,control,,,,,,,539,0.218559,0.327226,0.556099,0.374934,authors,no
30,"Arechar, A. A., Allen, J., Berinsky, A. J., Cole, R., Epstein, Z., Garimella, K., Gully, A., Lu, J. G., Ross, R. M., Stagnaro, M. N., Zhang, Y., Pennycook, G., & Rand, D. G. (2023). Understanding and combatting misinformation across 16 countries on six continents. Nature Human Behaviour, 7(9), 1502–1513. https://doi.org/10.1038/s41562-023-01641-6",Arechar 2022,,,"data correspond to 'accuracy condition'; values in the paper are only displayed in fig. 1, upon request authors sent means and standard deviations;
sample sizes are taken from supplementary material, table S1; Only in 'accuracy condition' participants rated accuracy - since this was only one of four conditions that participants got randomly assigned to, we divide sample size by 4;
attention: original scale was from 1 to 6; upon request via e-mail, they explained they transposed this as follows to a scale from 0 to 1: ""This is how it was done: rating=(rating-1)/5,This way, resulting values went from 1,2,3,4,5,6 to 0,.2,.4,.6,.8,1""",no,4,China,within,yes,yes,"seems as if fake news had been selected to not appear too true and true news to not appear too fake (fig. S1, supplementary material); so the potential bias from this should bias fake and true news equally (i.e. both errors should be underestimated);
""Specifically, we started with a list of 69 true and false headlines gathered from various sources online. Of those, we discarded 9 that involved a particular country or public figure (e.g. Donald Trump), as the relevance of those headlines was likely to vary considerably across countries (this was further confirmed by a group of researchers, native from the countries selected, expressly contacted to get feedback on such headlines). We then conducted a pilot survey using participants from the United States in which we measured the accuracy ratings and sharing intentions for each of the 60 headlines (see Fig S1). Based on these pre-test ratings, we choose a set of 30 false headlines and 15 true headlines that were clearly differentiated and reasonably representative.""",original,,researchers,fact_checking,mainstream,covid,1,20,45,0.5,title,,accuracy,"We asked them to assess either the accuracy of a headline in the Accuracy condition (“To the best of your knowledge, is the above headline accurate?” 6-point Likert scale)",1,1,1,control,,,,,,,573,0.329315,0.29353,0.529857,0.282602,authors,no
30,"Arechar, A. A., Allen, J., Berinsky, A. J., Cole, R., Epstein, Z., Garimella, K., Gully, A., Lu, J. G., Ross, R. M., Stagnaro, M. N., Zhang, Y., Pennycook, G., & Rand, D. G. (2023). Understanding and combatting misinformation across 16 countries on six continents. Nature Human Behaviour, 7(9), 1502–1513. https://doi.org/10.1038/s41562-023-01641-6",Arechar 2022,,,"data correspond to 'accuracy condition'; values in the paper are only displayed in fig. 1, upon request authors sent means and standard deviations;
sample sizes are taken from supplementary material, table S1; Only in 'accuracy condition' participants rated accuracy - since this was only one of four conditions that participants got randomly assigned to, we divide sample size by 4;
attention: original scale was from 1 to 6; upon request via e-mail, they explained they transposed this as follows to a scale from 0 to 1: ""This is how it was done: rating=(rating-1)/5,This way, resulting values went from 1,2,3,4,5,6 to 0,.2,.4,.6,.8,1""",no,5,Egypt,within,yes,yes,"seems as if fake news had been selected to not appear too true and true news to not appear too fake (fig. S1, supplementary material); so the potential bias from this should bias fake and true news equally (i.e. both errors should be underestimated);
""Specifically, we started with a list of 69 true and false headlines gathered from various sources online. Of those, we discarded 9 that involved a particular country or public figure (e.g. Donald Trump), as the relevance of those headlines was likely to vary considerably across countries (this was further confirmed by a group of researchers, native from the countries selected, expressly contacted to get feedback on such headlines). We then conducted a pilot survey using participants from the United States in which we measured the accuracy ratings and sharing intentions for each of the 60 headlines (see Fig S1). Based on these pre-test ratings, we choose a set of 30 false headlines and 15 true headlines that were clearly differentiated and reasonably representative.""",original,,researchers,fact_checking,mainstream,covid,1,20,45,0.5,title,,accuracy,"We asked them to assess either the accuracy of a headline in the Accuracy condition (“To the best of your knowledge, is the above headline accurate?” 6-point Likert scale)",1,1,1,control,,,,,,,523,0.35903,0.334136,0.601242,0.326358,authors,no
30,"Arechar, A. A., Allen, J., Berinsky, A. J., Cole, R., Epstein, Z., Garimella, K., Gully, A., Lu, J. G., Ross, R. M., Stagnaro, M. N., Zhang, Y., Pennycook, G., & Rand, D. G. (2023). Understanding and combatting misinformation across 16 countries on six continents. Nature Human Behaviour, 7(9), 1502–1513. https://doi.org/10.1038/s41562-023-01641-6",Arechar 2022,,,"data correspond to 'accuracy condition'; values in the paper are only displayed in fig. 1, upon request authors sent means and standard deviations;
sample sizes are taken from supplementary material, table S1; Only in 'accuracy condition' participants rated accuracy - since this was only one of four conditions that participants got randomly assigned to, we divide sample size by 4;
attention: original scale was from 1 to 6; upon request via e-mail, they explained they transposed this as follows to a scale from 0 to 1: ""This is how it was done: rating=(rating-1)/5,This way, resulting values went from 1,2,3,4,5,6 to 0,.2,.4,.6,.8,1""",no,6,Spain,within,yes,yes,"seems as if fake news had been selected to not appear too true and true news to not appear too fake (fig. S1, supplementary material); so the potential bias from this should bias fake and true news equally (i.e. both errors should be underestimated);
""Specifically, we started with a list of 69 true and false headlines gathered from various sources online. Of those, we discarded 9 that involved a particular country or public figure (e.g. Donald Trump), as the relevance of those headlines was likely to vary considerably across countries (this was further confirmed by a group of researchers, native from the countries selected, expressly contacted to get feedback on such headlines). We then conducted a pilot survey using participants from the United States in which we measured the accuracy ratings and sharing intentions for each of the 60 headlines (see Fig S1). Based on these pre-test ratings, we choose a set of 30 false headlines and 15 true headlines that were clearly differentiated and reasonably representative.""",original,,researchers,fact_checking,mainstream,covid,1,20,45,0.5,title,,accuracy,"We asked them to assess either the accuracy of a headline in the Accuracy condition (“To the best of your knowledge, is the above headline accurate?” 6-point Likert scale)",1,1,1,control,,,,,,,517,0.288364,0.326443,0.566909,0.327663,authors,no
30,"Arechar, A. A., Allen, J., Berinsky, A. J., Cole, R., Epstein, Z., Garimella, K., Gully, A., Lu, J. G., Ross, R. M., Stagnaro, M. N., Zhang, Y., Pennycook, G., & Rand, D. G. (2023). Understanding and combatting misinformation across 16 countries on six continents. Nature Human Behaviour, 7(9), 1502–1513. https://doi.org/10.1038/s41562-023-01641-6",Arechar 2022,,,"data correspond to 'accuracy condition'; values in the paper are only displayed in fig. 1, upon request authors sent means and standard deviations;
sample sizes are taken from supplementary material, table S1; Only in 'accuracy condition' participants rated accuracy - since this was only one of four conditions that participants got randomly assigned to, we divide sample size by 4;
attention: original scale was from 1 to 6; upon request via e-mail, they explained they transposed this as follows to a scale from 0 to 1: ""This is how it was done: rating=(rating-1)/5,This way, resulting values went from 1,2,3,4,5,6 to 0,.2,.4,.6,.8,1""",no,7,India,within,yes,yes,"seems as if fake news had been selected to not appear too true and true news to not appear too fake (fig. S1, supplementary material); so the potential bias from this should bias fake and true news equally (i.e. both errors should be underestimated);
""Specifically, we started with a list of 69 true and false headlines gathered from various sources online. Of those, we discarded 9 that involved a particular country or public figure (e.g. Donald Trump), as the relevance of those headlines was likely to vary considerably across countries (this was further confirmed by a group of researchers, native from the countries selected, expressly contacted to get feedback on such headlines). We then conducted a pilot survey using participants from the United States in which we measured the accuracy ratings and sharing intentions for each of the 60 headlines (see Fig S1). Based on these pre-test ratings, we choose a set of 30 false headlines and 15 true headlines that were clearly differentiated and reasonably representative.""",original,,researchers,fact_checking,mainstream,covid,1,20,45,0.5,title,,accuracy,"We asked them to assess either the accuracy of a headline in the Accuracy condition (“To the best of your knowledge, is the above headline accurate?” 6-point Likert scale)",1,1,1,control,,,,,,,526,0.47453,0.359023,0.635196,0.321575,authors,no
30,"Arechar, A. A., Allen, J., Berinsky, A. J., Cole, R., Epstein, Z., Garimella, K., Gully, A., Lu, J. G., Ross, R. M., Stagnaro, M. N., Zhang, Y., Pennycook, G., & Rand, D. G. (2023). Understanding and combatting misinformation across 16 countries on six continents. Nature Human Behaviour, 7(9), 1502–1513. https://doi.org/10.1038/s41562-023-01641-6",Arechar 2022,,,"data correspond to 'accuracy condition'; values in the paper are only displayed in fig. 1, upon request authors sent means and standard deviations;
sample sizes are taken from supplementary material, table S1; Only in 'accuracy condition' participants rated accuracy - since this was only one of four conditions that participants got randomly assigned to, we divide sample size by 4;
attention: original scale was from 1 to 6; upon request via e-mail, they explained they transposed this as follows to a scale from 0 to 1: ""This is how it was done: rating=(rating-1)/5,This way, resulting values went from 1,2,3,4,5,6 to 0,.2,.4,.6,.8,1""",no,8,Italy,within,yes,yes,"seems as if fake news had been selected to not appear too true and true news to not appear too fake (fig. S1, supplementary material); so the potential bias from this should bias fake and true news equally (i.e. both errors should be underestimated);
""Specifically, we started with a list of 69 true and false headlines gathered from various sources online. Of those, we discarded 9 that involved a particular country or public figure (e.g. Donald Trump), as the relevance of those headlines was likely to vary considerably across countries (this was further confirmed by a group of researchers, native from the countries selected, expressly contacted to get feedback on such headlines). We then conducted a pilot survey using participants from the United States in which we measured the accuracy ratings and sharing intentions for each of the 60 headlines (see Fig S1). Based on these pre-test ratings, we choose a set of 30 false headlines and 15 true headlines that were clearly differentiated and reasonably representative.""",original,,researchers,fact_checking,mainstream,covid,1,20,45,0.5,title,,accuracy,"We asked them to assess either the accuracy of a headline in the Accuracy condition (“To the best of your knowledge, is the above headline accurate?” 6-point Likert scale)",1,1,1,control,,,,,,,521,0.212875,0.285332,0.538796,0.34089,authors,no
30,"Arechar, A. A., Allen, J., Berinsky, A. J., Cole, R., Epstein, Z., Garimella, K., Gully, A., Lu, J. G., Ross, R. M., Stagnaro, M. N., Zhang, Y., Pennycook, G., & Rand, D. G. (2023). Understanding and combatting misinformation across 16 countries on six continents. Nature Human Behaviour, 7(9), 1502–1513. https://doi.org/10.1038/s41562-023-01641-6",Arechar 2022,,,"data correspond to 'accuracy condition'; values in the paper are only displayed in fig. 1, upon request authors sent means and standard deviations;
sample sizes are taken from supplementary material, table S1; Only in 'accuracy condition' participants rated accuracy - since this was only one of four conditions that participants got randomly assigned to, we divide sample size by 4;
attention: original scale was from 1 to 6; upon request via e-mail, they explained they transposed this as follows to a scale from 0 to 1: ""This is how it was done: rating=(rating-1)/5,This way, resulting values went from 1,2,3,4,5,6 to 0,.2,.4,.6,.8,1""",no,9,Mexico,within,yes,yes,"seems as if fake news had been selected to not appear too true and true news to not appear too fake (fig. S1, supplementary material); so the potential bias from this should bias fake and true news equally (i.e. both errors should be underestimated);
""Specifically, we started with a list of 69 true and false headlines gathered from various sources online. Of those, we discarded 9 that involved a particular country or public figure (e.g. Donald Trump), as the relevance of those headlines was likely to vary considerably across countries (this was further confirmed by a group of researchers, native from the countries selected, expressly contacted to get feedback on such headlines). We then conducted a pilot survey using participants from the United States in which we measured the accuracy ratings and sharing intentions for each of the 60 headlines (see Fig S1). Based on these pre-test ratings, we choose a set of 30 false headlines and 15 true headlines that were clearly differentiated and reasonably representative.""",original,,researchers,fact_checking,mainstream,covid,1,20,45,0.5,title,,accuracy,"We asked them to assess either the accuracy of a headline in the Accuracy condition (“To the best of your knowledge, is the above headline accurate?” 6-point Likert scale)",1,1,1,control,,,,,,,509,0.319597,0.344106,0.576529,0.336654,authors,no
30,"Arechar, A. A., Allen, J., Berinsky, A. J., Cole, R., Epstein, Z., Garimella, K., Gully, A., Lu, J. G., Ross, R. M., Stagnaro, M. N., Zhang, Y., Pennycook, G., & Rand, D. G. (2023). Understanding and combatting misinformation across 16 countries on six continents. Nature Human Behaviour, 7(9), 1502–1513. https://doi.org/10.1038/s41562-023-01641-6",Arechar 2022,,,"data correspond to 'accuracy condition'; values in the paper are only displayed in fig. 1, upon request authors sent means and standard deviations;
sample sizes are taken from supplementary material, table S1; Only in 'accuracy condition' participants rated accuracy - since this was only one of four conditions that participants got randomly assigned to, we divide sample size by 4;
attention: original scale was from 1 to 6; upon request via e-mail, they explained they transposed this as follows to a scale from 0 to 1: ""This is how it was done: rating=(rating-1)/5,This way, resulting values went from 1,2,3,4,5,6 to 0,.2,.4,.6,.8,1""",no,10,Nigeria,within,yes,yes,"seems as if fake news had been selected to not appear too true and true news to not appear too fake (fig. S1, supplementary material); so the potential bias from this should bias fake and true news equally (i.e. both errors should be underestimated);
""Specifically, we started with a list of 69 true and false headlines gathered from various sources online. Of those, we discarded 9 that involved a particular country or public figure (e.g. Donald Trump), as the relevance of those headlines was likely to vary considerably across countries (this was further confirmed by a group of researchers, native from the countries selected, expressly contacted to get feedback on such headlines). We then conducted a pilot survey using participants from the United States in which we measured the accuracy ratings and sharing intentions for each of the 60 headlines (see Fig S1). Based on these pre-test ratings, we choose a set of 30 false headlines and 15 true headlines that were clearly differentiated and reasonably representative.""",original,,researchers,fact_checking,mainstream,covid,1,20,45,0.5,title,,accuracy,"We asked them to assess either the accuracy of a headline in the Accuracy condition (“To the best of your knowledge, is the above headline accurate?” 6-point Likert scale)",1,1,1,control,,,,,,,530,0.363151,0.349342,0.589266,0.341725,authors,no
30,"Arechar, A. A., Allen, J., Berinsky, A. J., Cole, R., Epstein, Z., Garimella, K., Gully, A., Lu, J. G., Ross, R. M., Stagnaro, M. N., Zhang, Y., Pennycook, G., & Rand, D. G. (2023). Understanding and combatting misinformation across 16 countries on six continents. Nature Human Behaviour, 7(9), 1502–1513. https://doi.org/10.1038/s41562-023-01641-6",Arechar 2022,,,"data correspond to 'accuracy condition'; values in the paper are only displayed in fig. 1, upon request authors sent means and standard deviations;
sample sizes are taken from supplementary material, table S1; Only in 'accuracy condition' participants rated accuracy - since this was only one of four conditions that participants got randomly assigned to, we divide sample size by 4;
attention: original scale was from 1 to 6; upon request via e-mail, they explained they transposed this as follows to a scale from 0 to 1: ""This is how it was done: rating=(rating-1)/5,This way, resulting values went from 1,2,3,4,5,6 to 0,.2,.4,.6,.8,1""",no,11,Philippines,within,yes,yes,"seems as if fake news had been selected to not appear too true and true news to not appear too fake (fig. S1, supplementary material); so the potential bias from this should bias fake and true news equally (i.e. both errors should be underestimated);
""Specifically, we started with a list of 69 true and false headlines gathered from various sources online. Of those, we discarded 9 that involved a particular country or public figure (e.g. Donald Trump), as the relevance of those headlines was likely to vary considerably across countries (this was further confirmed by a group of researchers, native from the countries selected, expressly contacted to get feedback on such headlines). We then conducted a pilot survey using participants from the United States in which we measured the accuracy ratings and sharing intentions for each of the 60 headlines (see Fig S1). Based on these pre-test ratings, we choose a set of 30 false headlines and 15 true headlines that were clearly differentiated and reasonably representative.""",original,,researchers,fact_checking,mainstream,covid,1,20,45,0.5,title,,accuracy,"We asked them to assess either the accuracy of a headline in the Accuracy condition (“To the best of your knowledge, is the above headline accurate?” 6-point Likert scale)",1,1,1,control,,,,,,,546,0.329582,0.333733,0.607715,0.332361,authors,no
30,"Arechar, A. A., Allen, J., Berinsky, A. J., Cole, R., Epstein, Z., Garimella, K., Gully, A., Lu, J. G., Ross, R. M., Stagnaro, M. N., Zhang, Y., Pennycook, G., & Rand, D. G. (2023). Understanding and combatting misinformation across 16 countries on six continents. Nature Human Behaviour, 7(9), 1502–1513. https://doi.org/10.1038/s41562-023-01641-6",Arechar 2022,,,"data correspond to 'accuracy condition'; values in the paper are only displayed in fig. 1, upon request authors sent means and standard deviations;
sample sizes are taken from supplementary material, table S1; Only in 'accuracy condition' participants rated accuracy - since this was only one of four conditions that participants got randomly assigned to, we divide sample size by 4;
attention: original scale was from 1 to 6; upon request via e-mail, they explained they transposed this as follows to a scale from 0 to 1: ""This is how it was done: rating=(rating-1)/5,This way, resulting values went from 1,2,3,4,5,6 to 0,.2,.4,.6,.8,1""",no,12,Russia,within,yes,yes,"seems as if fake news had been selected to not appear too true and true news to not appear too fake (fig. S1, supplementary material); so the potential bias from this should bias fake and true news equally (i.e. both errors should be underestimated);
""Specifically, we started with a list of 69 true and false headlines gathered from various sources online. Of those, we discarded 9 that involved a particular country or public figure (e.g. Donald Trump), as the relevance of those headlines was likely to vary considerably across countries (this was further confirmed by a group of researchers, native from the countries selected, expressly contacted to get feedback on such headlines). We then conducted a pilot survey using participants from the United States in which we measured the accuracy ratings and sharing intentions for each of the 60 headlines (see Fig S1). Based on these pre-test ratings, we choose a set of 30 false headlines and 15 true headlines that were clearly differentiated and reasonably representative.""",original,,researchers,fact_checking,mainstream,covid,1,20,45,0.5,title,,accuracy,"We asked them to assess either the accuracy of a headline in the Accuracy condition (“To the best of your knowledge, is the above headline accurate?” 6-point Likert scale)",1,1,1,control,,,,,,,516,0.315435,0.244673,0.556754,0.253776,authors,no
30,"Arechar, A. A., Allen, J., Berinsky, A. J., Cole, R., Epstein, Z., Garimella, K., Gully, A., Lu, J. G., Ross, R. M., Stagnaro, M. N., Zhang, Y., Pennycook, G., & Rand, D. G. (2023). Understanding and combatting misinformation across 16 countries on six continents. Nature Human Behaviour, 7(9), 1502–1513. https://doi.org/10.1038/s41562-023-01641-6",Arechar 2022,,,"data correspond to 'accuracy condition'; values in the paper are only displayed in fig. 1, upon request authors sent means and standard deviations;
sample sizes are taken from supplementary material, table S1; Only in 'accuracy condition' participants rated accuracy - since this was only one of four conditions that participants got randomly assigned to, we divide sample size by 4;
attention: original scale was from 1 to 6; upon request via e-mail, they explained they transposed this as follows to a scale from 0 to 1: ""This is how it was done: rating=(rating-1)/5,This way, resulting values went from 1,2,3,4,5,6 to 0,.2,.4,.6,.8,1""",no,13,Saudi Arabia,within,yes,yes,"seems as if fake news had been selected to not appear too true and true news to not appear too fake (fig. S1, supplementary material); so the potential bias from this should bias fake and true news equally (i.e. both errors should be underestimated);
""Specifically, we started with a list of 69 true and false headlines gathered from various sources online. Of those, we discarded 9 that involved a particular country or public figure (e.g. Donald Trump), as the relevance of those headlines was likely to vary considerably across countries (this was further confirmed by a group of researchers, native from the countries selected, expressly contacted to get feedback on such headlines). We then conducted a pilot survey using participants from the United States in which we measured the accuracy ratings and sharing intentions for each of the 60 headlines (see Fig S1). Based on these pre-test ratings, we choose a set of 30 false headlines and 15 true headlines that were clearly differentiated and reasonably representative.""",original,,researchers,fact_checking,mainstream,covid,1,20,45,0.5,title,,accuracy,"We asked them to assess either the accuracy of a headline in the Accuracy condition (“To the best of your knowledge, is the above headline accurate?” 6-point Likert scale)",1,1,1,control,,,,,,,482,0.350115,0.326133,0.542672,0.326199,authors,no
30,"Arechar, A. A., Allen, J., Berinsky, A. J., Cole, R., Epstein, Z., Garimella, K., Gully, A., Lu, J. G., Ross, R. M., Stagnaro, M. N., Zhang, Y., Pennycook, G., & Rand, D. G. (2023). Understanding and combatting misinformation across 16 countries on six continents. Nature Human Behaviour, 7(9), 1502–1513. https://doi.org/10.1038/s41562-023-01641-6",Arechar 2022,,,"data correspond to 'accuracy condition'; values in the paper are only displayed in fig. 1, upon request authors sent means and standard deviations;
sample sizes are taken from supplementary material, table S1; Only in 'accuracy condition' participants rated accuracy - since this was only one of four conditions that participants got randomly assigned to, we divide sample size by 4;
attention: original scale was from 1 to 6; upon request via e-mail, they explained they transposed this as follows to a scale from 0 to 1: ""This is how it was done: rating=(rating-1)/5,This way, resulting values went from 1,2,3,4,5,6 to 0,.2,.4,.6,.8,1""",no,14,UK,within,yes,yes,"seems as if fake news had been selected to not appear too true and true news to not appear too fake (fig. S1, supplementary material); so the potential bias from this should bias fake and true news equally (i.e. both errors should be underestimated);
""Specifically, we started with a list of 69 true and false headlines gathered from various sources online. Of those, we discarded 9 that involved a particular country or public figure (e.g. Donald Trump), as the relevance of those headlines was likely to vary considerably across countries (this was further confirmed by a group of researchers, native from the countries selected, expressly contacted to get feedback on such headlines). We then conducted a pilot survey using participants from the United States in which we measured the accuracy ratings and sharing intentions for each of the 60 headlines (see Fig S1). Based on these pre-test ratings, we choose a set of 30 false headlines and 15 true headlines that were clearly differentiated and reasonably representative.""",original,,researchers,fact_checking,mainstream,covid,1,20,45,0.5,title,,accuracy,"We asked them to assess either the accuracy of a headline in the Accuracy condition (“To the best of your knowledge, is the above headline accurate?” 6-point Likert scale)",1,1,1,control,,,,,,,520,0.195027,0.270954,0.590117,0.317161,authors,no
30,"Arechar, A. A., Allen, J., Berinsky, A. J., Cole, R., Epstein, Z., Garimella, K., Gully, A., Lu, J. G., Ross, R. M., Stagnaro, M. N., Zhang, Y., Pennycook, G., & Rand, D. G. (2023). Understanding and combatting misinformation across 16 countries on six continents. Nature Human Behaviour, 7(9), 1502–1513. https://doi.org/10.1038/s41562-023-01641-6",Arechar 2022,,,"data correspond to 'accuracy condition'; values in the paper are only displayed in fig. 1, upon request authors sent means and standard deviations;
sample sizes are taken from supplementary material, table S1; Only in 'accuracy condition' participants rated accuracy - since this was only one of four conditions that participants got randomly assigned to, we divide sample size by 4;
attention: original scale was from 1 to 6; upon request via e-mail, they explained they transposed this as follows to a scale from 0 to 1: ""This is how it was done: rating=(rating-1)/5,This way, resulting values went from 1,2,3,4,5,6 to 0,.2,.4,.6,.8,1""",no,15,United States,within,yes,yes,"seems as if fake news had been selected to not appear too true and true news to not appear too fake (fig. S1, supplementary material); so the potential bias from this should bias fake and true news equally (i.e. both errors should be underestimated);
""Specifically, we started with a list of 69 true and false headlines gathered from various sources online. Of those, we discarded 9 that involved a particular country or public figure (e.g. Donald Trump), as the relevance of those headlines was likely to vary considerably across countries (this was further confirmed by a group of researchers, native from the countries selected, expressly contacted to get feedback on such headlines). We then conducted a pilot survey using participants from the United States in which we measured the accuracy ratings and sharing intentions for each of the 60 headlines (see Fig S1). Based on these pre-test ratings, we choose a set of 30 false headlines and 15 true headlines that were clearly differentiated and reasonably representative.""",original,,researchers,fact_checking,mainstream,covid,1,20,45,0.5,title,,accuracy,"We asked them to assess either the accuracy of a headline in the Accuracy condition (“To the best of your knowledge, is the above headline accurate?” 6-point Likert scale)",1,1,1,control,,,,,,,522,0.288856,0.327485,0.581097,0.323315,authors,no
30,"Arechar, A. A., Allen, J., Berinsky, A. J., Cole, R., Epstein, Z., Garimella, K., Gully, A., Lu, J. G., Ross, R. M., Stagnaro, M. N., Zhang, Y., Pennycook, G., & Rand, D. G. (2023). Understanding and combatting misinformation across 16 countries on six continents. Nature Human Behaviour, 7(9), 1502–1513. https://doi.org/10.1038/s41562-023-01641-6",Arechar 2022,,,"data correspond to 'accuracy condition'; values in the paper are only displayed in fig. 1, upon request authors sent means and standard deviations;
sample sizes are taken from supplementary material, table S1; Only in 'accuracy condition' participants rated accuracy - since this was only one of four conditions that participants got randomly assigned to, we divide sample size by 4;
attention: original scale was from 1 to 6; upon request via e-mail, they explained they transposed this as follows to a scale from 0 to 1: ""This is how it was done: rating=(rating-1)/5,This way, resulting values went from 1,2,3,4,5,6 to 0,.2,.4,.6,.8,1""",no,16,South Africa,within,yes,yes,"seems as if fake news had been selected to not appear too true and true news to not appear too fake (fig. S1, supplementary material); so the potential bias from this should bias fake and true news equally (i.e. both errors should be underestimated);
""Specifically, we started with a list of 69 true and false headlines gathered from various sources online. Of those, we discarded 9 that involved a particular country or public figure (e.g. Donald Trump), as the relevance of those headlines was likely to vary considerably across countries (this was further confirmed by a group of researchers, native from the countries selected, expressly contacted to get feedback on such headlines). We then conducted a pilot survey using participants from the United States in which we measured the accuracy ratings and sharing intentions for each of the 60 headlines (see Fig S1). Based on these pre-test ratings, we choose a set of 30 false headlines and 15 true headlines that were clearly differentiated and reasonably representative.""",original,,researchers,fact_checking,mainstream,covid,1,20,45,0.5,title,,accuracy,"We asked them to assess either the accuracy of a headline in the Accuracy condition (“To the best of your knowledge, is the above headline accurate?” 6-point Likert scale)",1,1,1,control,,,,,,,517,0.280302,0.32174,0.581557,0.339087,authors,no
31,"Hlatky, R. (2024). Unintended Consequences? Russian Disinformation and Public Opinion. OSF. https://doi.org/10.31219/osf.io/85vmt",Hlatky n.d.,,,"data correspond to the the two between conditions 'fake' and 'true'; values correspond to table 3, upon request authors sent standard deviations and sample size per condition",no,1,Slovakia,within,yes,no,,original,,researchers,fact_checking,mainstream,identity_related,1,8,,0.5,title_picture,,accuracy,Respondents indicated whether a given headline was true; whether they would “share the headline on social media; whether the headline was familiar to them; and whether the headline confirmed their previous beliefs (all on 1-4 scale).,NA,NA,4,control,,,,,,,651,1.87,0.6945381,2.19,0.6276497,authors,no
31,"Hlatky, R. (2024). Unintended Consequences? Russian Disinformation and Public Opinion. OSF. https://doi.org/10.31219/osf.io/85vmt",Hlatky n.d.,,,"data correspond to the the within condition 'true + false'; values correspond to table 3, upon request authors sent standard deviations and sample size per condition",no,2,Slovakia,within,yes,no,,original,,researchers,fact_checking,mainstream,identity_related,1,8,,0.5,title_picture,,accuracy,Respondents indicated whether a given headline was true; whether they would “share the headline on social media; whether the headline was familiar to them; and whether the headline confirmed their previous beliefs (all on 1-4 scale).,NA,NA,4,control,,,,,,,310,1.93,0.7031596,2.2,0.6568336,authors,no
32,"Lyons, B., Montgomery, J., & Reifler, J. (2023). Partisanship and older Americans’ engagement with dubious political news. OSF. https://doi.org/10.31219/osf.io/etb89",Lyons 2022,yes,,"data correspond to 'june/july' sample, wave 1; 
values for first waves of survey 1 and 2 ('june/july' and 'Oct./Nov.')are taken from table 1 in paper, values for second waves of surveys 1 and 2, as well as both waves of survey three ('Nov./Dec.') are taken from correspondence with authors ;
it was important to get in touch with the authors since (i) the paper did not differentiate wave 2 results between familiarized items from wave 1 and new items and (ii) it was not clear when and to whom additional treatments were administered; 
from exchange with the author via e-mail, we know that: ""Yes, w2 means respond to 
all ratings (all 12 headlines). Respondents saw 6 of the 12 in w1, then 
all 12 in w2. The 6 they saw in w1 were randomly drawn from within each 
""bin"" (eg 1 of 2 possible false pro-Democrat, 1 of 2 possible false 
pro-Republican, 2 of 4 possible mainstream pro-D, 2 of 4 possible 
mainstream pro-R."" ;
from another exchange with the author we know that two of the three surveys we integrate here administered a treatement to everybody: 
""yes that's right. treatment was given in w1 of all surveys. only survey 3 has a control due to the programming error."";
news headlines for survey 2 and 3 are identical (see appendix);  
attention: pdf from twitter, doesn't appear anywhere, no pre-print, not even on the author's homepage;",no,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,6,,0.5,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,treatment,positive,literacy,,,,,1718,1.68,0.62,2.69,0.64,authors,
32,"Lyons, B., Montgomery, J., & Reifler, J. (2023). Partisanship and older Americans’ engagement with dubious political news. OSF. https://doi.org/10.31219/osf.io/etb89",Lyons 2022,yes,,"data correspond to 'june/july' sample, wave 2, familiarized news items; 
values for first waves of survey 1 and 2 ('june/july' and 'Oct./Nov.')are taken from table 1 in paper, values for second waves of surveys 1 and 2, as well as both waves of survey three ('Nov./Dec.') are taken from correspondence with authors ;
it was important to get in touch with the authors since (i) the paper did not differentiate wave 2 results between familiarized items from wave 1 and new items and (ii) it was not clear when and to whom additional treatments were administered; 
from exchange with the author via e-mail, we know that: ""Yes, w2 means respond to 
all ratings (all 12 headlines). Respondents saw 6 of the 12 in w1, then 
all 12 in w2. The 6 they saw in w1 were randomly drawn from within each 
""bin"" (eg 1 of 2 possible false pro-Democrat, 1 of 2 possible false 
pro-Republican, 2 of 4 possible mainstream pro-D, 2 of 4 possible 
mainstream pro-R."" ;
from another exchange with the author we know that two of the three surveys we integrate here administered a treatement to everybody: 
""yes that's right. treatment was given in w1 of all surveys. only survey 3 has a control due to the programming error."";
news headlines for survey 2 and 3 are identical (see appendix);  
attention: pdf from twitter, doesn't appear anywhere, no pre-print, not even on the author's homepage;",no,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,1,6,,0.5,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,treatment,positive,multiple_1monthbeforeliteracy_familiarization,,,,,1499,2.038731,0.9817144,2.801803,0.9880499,authors,
32,"Lyons, B., Montgomery, J., & Reifler, J. (2023). Partisanship and older Americans’ engagement with dubious political news. OSF. https://doi.org/10.31219/osf.io/etb89",Lyons 2022,yes,,"data correspond to 'june/july' sample, wave 2, new news items; 
values for first waves of survey 1 and 2 ('june/july' and 'Oct./Nov.')are taken from table 1 in paper, values for second waves of surveys 1 and 2, as well as both waves of survey three ('Nov./Dec.') are taken from correspondence with authors ;
it was important to get in touch with the authors since (i) the paper did not differentiate wave 2 results between familiarized items from wave 1 and new items and (ii) it was not clear when and to whom additional treatments were administered; 
from exchange with the author via e-mail, we know that: ""Yes, w2 means respond to 
all ratings (all 12 headlines). Respondents saw 6 of the 12 in w1, then 
all 12 in w2. The 6 they saw in w1 were randomly drawn from within each 
""bin"" (eg 1 of 2 possible false pro-Democrat, 1 of 2 possible false 
pro-Republican, 2 of 4 possible mainstream pro-D, 2 of 4 possible 
mainstream pro-R."" ;
from another exchange with the author we know that two of the three surveys we integrate here administered a treatement to everybody: 
""yes that's right. treatment was given in w1 of all surveys. only survey 3 has a control due to the programming error."";
news headlines for survey 2 and 3 are identical (see appendix);  
attention: pdf from twitter, doesn't appear anywhere, no pre-print, not even on the author's homepage;",no,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,2,6,,0.5,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,treatment,positive,1monthbefore_literacy,,,,,1499,1.880348,0.9019397,2.707081,0.9975935,authors,
32,"Lyons, B., Montgomery, J., & Reifler, J. (2023). Partisanship and older Americans’ engagement with dubious political news. OSF. https://doi.org/10.31219/osf.io/etb89",Lyons 2022,yes,,"data correspond to 'Oct./Nov.' sample, wave 1; 
values for first waves of survey 1 and 2 ('june/july' and 'Oct./Nov.')are taken from table 1 in paper, values for second waves of surveys 1 and 2, as well as both waves of survey three ('Nov./Dec.') are taken from correspondence with authors ;
it was important to get in touch with the authors since (i) the paper did not differentiate wave 2 results between familiarized items from wave 1 and new items and (ii) it was not clear when and to whom additional treatments were administered; 
from exchange with the author via e-mail, we know that: ""Yes, w2 means respond to 
all ratings (all 12 headlines). Respondents saw 6 of the 12 in w1, then 
all 12 in w2. The 6 they saw in w1 were randomly drawn from within each 
""bin"" (eg 1 of 2 possible false pro-Democrat, 1 of 2 possible false 
pro-Republican, 2 of 4 possible mainstream pro-D, 2 of 4 possible 
mainstream pro-R."" ;
from another exchange with the author we know that two of the three surveys we integrate here administered a treatement to everybody: 
""yes that's right. treatment was given in w1 of all surveys. only survey 3 has a control due to the programming error."";
news headlines for survey 2 and 3 are identical (see appendix);  
attention: pdf from twitter, doesn't appear anywhere, no pre-print, not even on the author's homepage;",no,2,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,3,6,,0.5,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,treatment,positive,literacy,,,,,3378,1.76,0.68,2.59,0.59,authors,
32,"Lyons, B., Montgomery, J., & Reifler, J. (2023). Partisanship and older Americans’ engagement with dubious political news. OSF. https://doi.org/10.31219/osf.io/etb89",Lyons 2022,yes,,"data correspond to 'Oct./Nov.' sample, wave 2, familiarized news items; 
values for first waves of survey 1 and 2 ('june/july' and 'Oct./Nov.')are taken from table 1 in paper, values for second waves of surveys 1 and 2, as well as both waves of survey three ('Nov./Dec.') are taken from correspondence with authors ;
it was important to get in touch with the authors since (i) the paper did not differentiate wave 2 results between familiarized items from wave 1 and new items and (ii) it was not clear when and to whom additional treatments were administered; 
from exchange with the author via e-mail, we know that: ""Yes, w2 means respond to 
all ratings (all 12 headlines). Respondents saw 6 of the 12 in w1, then 
all 12 in w2. The 6 they saw in w1 were randomly drawn from within each 
""bin"" (eg 1 of 2 possible false pro-Democrat, 1 of 2 possible false 
pro-Republican, 2 of 4 possible mainstream pro-D, 2 of 4 possible 
mainstream pro-R."" ;
from another exchange with the author we know that two of the three surveys we integrate here administered a treatement to everybody: 
""yes that's right. treatment was given in w1 of all surveys. only survey 3 has a control due to the programming error."";
news headlines for survey 2 and 3 are identical (see appendix);  
attention: pdf from twitter, doesn't appear anywhere, no pre-print, not even on the author's homepage;",no,2,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,3,6,,0.5,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,treatment,positive,multiple_1monthbeforeliteracy_familiarization,,,,,2948,1.939441,0.9763524,2.73705,1.012479,authors,
32,"Lyons, B., Montgomery, J., & Reifler, J. (2023). Partisanship and older Americans’ engagement with dubious political news. OSF. https://doi.org/10.31219/osf.io/etb89",Lyons 2022,yes,,"data correspond to 'Oct./Nov.' sample, wave 2, new news items; 
values for first waves of survey 1 and 2 ('june/july' and 'Oct./Nov.')are taken from table 1 in paper, values for second waves of surveys 1 and 2, as well as both waves of survey three ('Nov./Dec.') are taken from correspondence with authors ;
it was important to get in touch with the authors since (i) the paper did not differentiate wave 2 results between familiarized items from wave 1 and new items and (ii) it was not clear when and to whom additional treatments were administered; 
from exchange with the author via e-mail, we know that: ""Yes, w2 means respond to 
all ratings (all 12 headlines). Respondents saw 6 of the 12 in w1, then 
all 12 in w2. The 6 they saw in w1 were randomly drawn from within each 
""bin"" (eg 1 of 2 possible false pro-Democrat, 1 of 2 possible false 
pro-Republican, 2 of 4 possible mainstream pro-D, 2 of 4 possible 
mainstream pro-R."" ;
from another exchange with the author we know that two of the three surveys we integrate here administered a treatement to everybody: 
""yes that's right. treatment was given in w1 of all surveys. only survey 3 has a control due to the programming error."";
news headlines for survey 2 and 3 are identical (see appendix);  
attention: pdf from twitter, doesn't appear anywhere, no pre-print, not even on the author's homepage;",no,2,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,4,6,,0.5,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,treatment,positive,1monthbefore_literacy,,,,,2948,1.861992,0.9409798,2.620338,1.015016,authors,
32,"Lyons, B., Montgomery, J., & Reifler, J. (2023). Partisanship and older Americans’ engagement with dubious political news. OSF. https://doi.org/10.31219/osf.io/etb89",Lyons 2022,yes,,"data correspond to 'Nov./Dec.' sample, wave 1, control group; 
values for first waves of survey 1 and 2 ('june/july' and 'Oct./Nov.')are taken from table 1 in paper, values for second waves of surveys 1 and 2, as well as both waves of survey three ('Nov./Dec.') are taken from correspondence with authors ;
it was important to get in touch with the authors since (i) the paper did not differentiate wave 2 results between familiarized items from wave 1 and new items and (ii) it was not clear when and to whom additional treatments were administered; 
from exchange with the author via e-mail, we know that: ""Yes, w2 means respond to 
all ratings (all 12 headlines). Respondents saw 6 of the 12 in w1, then 
all 12 in w2. The 6 they saw in w1 were randomly drawn from within each 
""bin"" (eg 1 of 2 possible false pro-Democrat, 1 of 2 possible false 
pro-Republican, 2 of 4 possible mainstream pro-D, 2 of 4 possible 
mainstream pro-R."" ;
from another exchange with the author we know that two of the three surveys we integrate here administered a treatement to everybody: 
""yes that's right. treatment was given in w1 of all surveys. only survey 3 has a control due to the programming error."";
news headlines for survey 2 and 3 are identical (see appendix);  
attention: pdf from twitter, doesn't appear anywhere, no pre-print, not even on the author's homepage;",no,3,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,3,6,,0.5,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,control,,,,,,,2453.5,2.029963,0.975813,2.581142,0.9868082,authors,
32,"Lyons, B., Montgomery, J., & Reifler, J. (2023). Partisanship and older Americans’ engagement with dubious political news. OSF. https://doi.org/10.31219/osf.io/etb89",Lyons 2022,yes,,"data correspond to 'Nov./Dec.' sample, wave 1, treatment group; 
values for first waves of survey 1 and 2 ('june/july' and 'Oct./Nov.')are taken from table 1 in paper, values for second waves of surveys 1 and 2, as well as both waves of survey three ('Nov./Dec.') are taken from correspondence with authors ;
it was important to get in touch with the authors since (i) the paper did not differentiate wave 2 results between familiarized items from wave 1 and new items and (ii) it was not clear when and to whom additional treatments were administered; 
from exchange with the author via e-mail, we know that: ""Yes, w2 means respond to 
all ratings (all 12 headlines). Respondents saw 6 of the 12 in w1, then 
all 12 in w2. The 6 they saw in w1 were randomly drawn from within each 
""bin"" (eg 1 of 2 possible false pro-Democrat, 1 of 2 possible false 
pro-Republican, 2 of 4 possible mainstream pro-D, 2 of 4 possible 
mainstream pro-R."" ;
from another exchange with the author we know that two of the three surveys we integrate here administered a treatement to everybody: 
""yes that's right. treatment was given in w1 of all surveys. only survey 3 has a control due to the programming error."";
news headlines for survey 2 and 3 are identical (see appendix);  
attention: pdf from twitter, doesn't appear anywhere, no pre-print, not even on the author's homepage;",no,4,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,3,6,,0.5,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,treatment,positive,literacy,,,,,2453.5,1.836152,0.9425255,2.533884,1.033577,authors,
32,"Lyons, B., Montgomery, J., & Reifler, J. (2023). Partisanship and older Americans’ engagement with dubious political news. OSF. https://doi.org/10.31219/osf.io/etb89",Lyons 2022,yes,,"data correspond to 'Nov./Dec.' sample, wave 2, control group, familiarized news items; 
note that we rely on sample sizes reported in paper for control + treatment group (hence divide by 2), which means that for wave 2 we assume equal attrition between treatment and control group; 
values for first waves of survey 1 and 2 ('june/july' and 'Oct./Nov.')are taken from table 1 in paper, values for second waves of surveys 1 and 2, as well as both waves of survey three ('Nov./Dec.') are taken from correspondence with authors ;
it was important to get in touch with the authors since (i) the paper did not differentiate wave 2 results between familiarized items from wave 1 and new items and (ii) it was not clear when and to whom additional treatments were administered; 
from exchange with the author via e-mail, we know that: ""Yes, w2 means respond to 
all ratings (all 12 headlines). Respondents saw 6 of the 12 in w1, then 
all 12 in w2. The 6 they saw in w1 were randomly drawn from within each 
""bin"" (eg 1 of 2 possible false pro-Democrat, 1 of 2 possible false 
pro-Republican, 2 of 4 possible mainstream pro-D, 2 of 4 possible 
mainstream pro-R."" ;
from another exchange with the author we know that two of the three surveys we integrate here administered a treatement to everybody: 
""yes that's right. treatment was given in w1 of all surveys. only survey 3 has a control due to the programming error."";
news headlines for survey 2 and 3 are identical (see appendix);  
attention: pdf from twitter, doesn't appear anywhere, no pre-print, not even on the author's homepage;",no,3,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,3,6,,0.5,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,treatment,neutral,familiarization,"as far as we can tell, participants have not been given any feedback in the first wave - hence we code treatment_intention as neutral",,,,2141.5,2.089888,1.001928,2.683687,0.9852887,authors,
32,"Lyons, B., Montgomery, J., & Reifler, J. (2023). Partisanship and older Americans’ engagement with dubious political news. OSF. https://doi.org/10.31219/osf.io/etb89",Lyons 2022,yes,,"data correspond to 'Nov./Dec.' sample, wave 2, treatment group, familiarized news items; 
note that we rely on sample sizes reported in paper for control + treatment group (hence divide by 2), which means that for wave 2 we assume equal attrition between treatment and control group; 
values for first waves of survey 1 and 2 ('june/july' and 'Oct./Nov.')are taken from table 1 in paper, values for second waves of surveys 1 and 2, as well as both waves of survey three ('Nov./Dec.') are taken from correspondence with authors ;
it was important to get in touch with the authors since (i) the paper did not differentiate wave 2 results between familiarized items from wave 1 and new items and (ii) it was not clear when and to whom additional treatments were administered; 
from exchange with the author via e-mail, we know that: ""Yes, w2 means respond to 
all ratings (all 12 headlines). Respondents saw 6 of the 12 in w1, then 
all 12 in w2. The 6 they saw in w1 were randomly drawn from within each 
""bin"" (eg 1 of 2 possible false pro-Democrat, 1 of 2 possible false 
pro-Republican, 2 of 4 possible mainstream pro-D, 2 of 4 possible 
mainstream pro-R."" ;
from another exchange with the author we know that two of the three surveys we integrate here administered a treatement to everybody: 
""yes that's right. treatment was given in w1 of all surveys. only survey 3 has a control due to the programming error."";
news headlines for survey 2 and 3 are identical (see appendix);  
attention: pdf from twitter, doesn't appear anywhere, no pre-print, not even on the author's homepage;",no,4,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,3,6,,0.5,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,treatment,positive,multiple_1monthbeforeliteracy_familiarization,,,,,2141.5,1.993937,0.9700245,2.654734,0.987069,authors,
32,"Lyons, B., Montgomery, J., & Reifler, J. (2023). Partisanship and older Americans’ engagement with dubious political news. OSF. https://doi.org/10.31219/osf.io/etb89",Lyons 2022,yes,,"data correspond to 'Nov./Dec.' sample, wave 2, control group, new news items; 
note that we rely on sample sizes reported in paper for control + treatment group (hence divide by 2), which means that for wave 2 we assume equal attrition between treatment and control group; 
values for first waves of survey 1 and 2 ('june/july' and 'Oct./Nov.')are taken from table 1 in paper, values for second waves of surveys 1 and 2, as well as both waves of survey three ('Nov./Dec.') are taken from correspondence with authors ;
it was important to get in touch with the authors since (i) the paper did not differentiate wave 2 results between familiarized items from wave 1 and new items and (ii) it was not clear when and to whom additional treatments were administered; 
from exchange with the author via e-mail, we know that: ""Yes, w2 means respond to 
all ratings (all 12 headlines). Respondents saw 6 of the 12 in w1, then 
all 12 in w2. The 6 they saw in w1 were randomly drawn from within each 
""bin"" (eg 1 of 2 possible false pro-Democrat, 1 of 2 possible false 
pro-Republican, 2 of 4 possible mainstream pro-D, 2 of 4 possible 
mainstream pro-R."" ;
from another exchange with the author we know that two of the three surveys we integrate here administered a treatement to everybody: 
""yes that's right. treatment was given in w1 of all surveys. only survey 3 has a control due to the programming error."";
news headlines for survey 2 and 3 are identical (see appendix);  
attention: pdf from twitter, doesn't appear anywhere, no pre-print, not even on the author's homepage;",no,3,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,4,6,,0.5,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,control,,,,,,,2141.5,2.000937,0.9707666,2.595458,0.989402,authors,
32,"Lyons, B., Montgomery, J., & Reifler, J. (2023). Partisanship and older Americans’ engagement with dubious political news. OSF. https://doi.org/10.31219/osf.io/etb89",Lyons 2022,yes,,"data correspond to 'Nov./Dec.' sample, wave 2, treatment group, familiarized news items; 
note that we rely on sample sizes reported in paper for control + treatment group (hence divide by 2), which means that for wave 2 we assume equal attrition between treatment and control group; 
values for first waves of survey 1 and 2 ('june/july' and 'Oct./Nov.')are taken from table 1 in paper, values for second waves of surveys 1 and 2, as well as both waves of survey three ('Nov./Dec.') are taken from correspondence with authors ;
it was important to get in touch with the authors since (i) the paper did not differentiate wave 2 results between familiarized items from wave 1 and new items and (ii) it was not clear when and to whom additional treatments were administered; 
from exchange with the author via e-mail, we know that: ""Yes, w2 means respond to 
all ratings (all 12 headlines). Respondents saw 6 of the 12 in w1, then 
all 12 in w2. The 6 they saw in w1 were randomly drawn from within each 
""bin"" (eg 1 of 2 possible false pro-Democrat, 1 of 2 possible false 
pro-Republican, 2 of 4 possible mainstream pro-D, 2 of 4 possible 
mainstream pro-R."" ;
from another exchange with the author we know that two of the three surveys we integrate here administered a treatement to everybody: 
""yes that's right. treatment was given in w1 of all surveys. only survey 3 has a control due to the programming error."";
news headlines for survey 2 and 3 are identical (see appendix);  
attention: pdf from twitter, doesn't appear anywhere, no pre-print, not even on the author's homepage;",no,4,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_balanced,4,6,,0.5,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,treatment,positive,1monthbefore_literacy,,,,,2141.5,1.937296,0.9437592,2.5665,0.9949049,authors,
33,"OECD. (2022). An international effort using behavioural science to tackle the spread of misinformation (OECD Public Governance Policy Papers 21; OECD Public Governance Policy Papers, Vol. 21). https://doi.org/10.1787/b7709d4f-en",Public Governance Policy Paper 2022,,,Authors sent the numbers by email,no,1,Canada,within,yes,no,,original,,researchers,fact_checking,mainstream,covid,1,14,,0.5,title_picture,source,accuracy,"To the best of your knowledge, is this claim in the above headline accurate?’  4-point scale ranging from ‘not at all accurate’ to ‘very accurate’,",1,0,4,control,,,,,,,282,1.732,0.519,2.601,0.469,authors,no
34,"Orosz, G., Paskuj, B., Faragó, L., & Krekó, P. (2023). A prosocial fake news intervention with durable effects. Scientific Reports, 13(1), 3958. https://doi.org/10.1038/s41598-023-30867-7",Orosz 2022,yes,,,yes,1,Hungary,within,yes,no,,original,,researchers,fact_checking,mainstream,half_pol_half_not_pol,1,16,,0.5,title_picture,source,accuracy,not at all accurate/not very accurate/somewhat accurate/very accurate,1,0,4,control,,,,,,,412,1.97,0.49,2.5,0.41,paper,panel
34,"Orosz, G., Paskuj, B., Faragó, L., & Krekó, P. (2023). A prosocial fake news intervention with durable effects. Scientific Reports, 13(1), 3958. https://doi.org/10.1038/s41598-023-30867-7",Orosz 2022,yes,,follow-up four weeks later,yes,1,Hungary,within,yes,no,,original,,researchers,fact_checking,mainstream,half_pol_half_not_pol,2,16,,0.5,title_picture,source,accuracy,not at all accurate/not very accurate/somewhat accurate/very accurate,1,0,4,control,,,,,,,286,1.96,0.41,2.52,0.48,paper,panel
34,"Orosz, G., Paskuj, B., Faragó, L., & Krekó, P. (2023). A prosocial fake news intervention with durable effects. Scientific Reports, 13(1), 3958. https://doi.org/10.1038/s41598-023-30867-7",Orosz 2022,yes,,,yes,2,Hungary,within,yes,no,,original,,researchers,fact_checking,mainstream,half_pol_half_not_pol,1,16,,0.5,title_picture,source,accuracy,not at all accurate/not very accurate/somewhat accurate/very accurate,1,0,4,treatment,positive,literacy,Participants reviewed six scientifically supported strategies (all adapted from Guess et al.22) with peer testimonials to spot online misinformation (skepticism for headlines; looking beyond fear- mongering; inspecting the source of news; checking the evidence; triangulation; considering if the story is a joke; see an example in Figure 2). They were then requested to write a brief letter to a close family member in which they summarize the six strategies and were asked to reflect on the best arguments and advice that would convince their relatives to implement these strategies in their everyday life.,,,,389,1.81,0.49,2.49,0.43,paper,panel
34,"Orosz, G., Paskuj, B., Faragó, L., & Krekó, P. (2023). A prosocial fake news intervention with durable effects. Scientific Reports, 13(1), 3958. https://doi.org/10.1038/s41598-023-30867-7",Orosz 2022,yes,,follow-up four weeks later; the treatment is: Participants reviewed six scientifically supported strategies (all adapted from Guess et al.22) with peer testimonials to spot online misinformation (skepticism for headlines; looking beyond fear- mongering; inspecting the source of news; checking the evidence; triangulation; considering if the story is a joke; see an example in Figure 2). They were then requested to write a brief letter to a close family member in which they summarize the six strategies and were asked to reflect on the best arguments and advice that would convince their relatives to implement these strategies in their everyday life.,yes,2,Hungary,within,yes,no,,original,,researchers,fact_checking,mainstream,half_pol_half_not_pol,2,16,,0.5,title_picture,source,accuracy,not at all accurate/not very accurate/somewhat accurate/very accurate,1,0,4,treatment,positive,1monthbefore_literacy,1 month before: Participants reviewed six scientifically supported strategies (all adapted from Guess et al.22) with peer testimonials to spot online misinformation (skepticism for headlines; looking beyond fear- mongering; inspecting the source of news; checking the evidence; triangulation; considering if the story is a joke; see an example in Figure 2). They were then requested to write a brief letter to a close family member in which they summarize the six strategies and were asked to reflect on the best arguments and advice that would convince their relatives to implement these strategies in their everyday life.,,,,291,1.86,0.44,2.49,0.47,paper,panel
35,"Muda, R., Pennycook, G., Hamerski, D., & Białek, M. (2023). People are worse at detecting fake news in their foreign language. Journal of Experimental Psychology: Applied, 29(4), 712–724. https://doi.org/10.1037/xap0000475",Muda 2021,yes,,Authors sent the numbers by email,yes,1,Poland,within,yes,no,,original,,researchers,fact_checking,mainstream,general,1,8,,0.5,title_picture,source,accuracy,1 – Extremely unbelievable; 7 – Extremely believable,1,1,7,control,,,,,,,177,3.22,0.5,4.88,0.5,authors,no
35,"Muda, R., Pennycook, G., Hamerski, D., & Białek, M. (2023). People are worse at detecting fake news in their foreign language. Journal of Experimental Psychology: Applied, 29(4), 712–724. https://doi.org/10.1037/xap0000475",Muda 2021,yes,,Authors sent the numbers by email,yes,2,Poland,within,yes,no,,original,,researchers,fact_checking,mainstream,general,2,8,,0.5,title_picture,source,accuracy,1 – Extremely unbelievable; 7 – Extremely believable,1,1,7,treatment,negative,foreign_language,Neg treatment = news in foreign language,,,,123,3.51,0.5,4.69,0.5,authors,no
35,"Muda, R., Pennycook, G., Hamerski, D., & Białek, M. (2023). People are worse at detecting fake news in their foreign language. Journal of Experimental Psychology: Applied, 29(4), 712–724. https://doi.org/10.1037/xap0000475",Muda 2021,yes,,Authors sent the numbers by email,yes,3,Poland,within,yes,no,,original,,researchers,fact_checking,mainstream,general,3,8,,0.5,title_picture,source,accuracy,to judge their believability (YES/NO),1,1,binary,control,,,,,,,141,0.327,0.469,0.741,0.438,authors,no
35,"Muda, R., Pennycook, G., Hamerski, D., & Białek, M. (2023). People are worse at detecting fake news in their foreign language. Journal of Experimental Psychology: Applied, 29(4), 712–724. https://doi.org/10.1037/xap0000475",Muda 2021,yes,,Authors sent the numbers by email,yes,4,Poland,within,yes,no,,original,,researchers,fact_checking,mainstream,general,4,8,,0.5,title_picture,source,accuracy,to judge their believability (YES/NO),1,1,binary,treatment,negative,foreign_language,Neg treatment = news in foreign language,,,,129,0.376,0.485,0.73,0.444,authors,no
36,"Gottlieb, J., Adida, C., & Moussa, R. (2022). Reducing Misinformation in a Polarized Context: Experimental Evidence from Côte d’Ivoire. OSF Preprints. https://doi.org/10.31219/osf.io/6x4wy",Gottlieb 2022,yes,,"Note that in this paper, half of the sample 1-2-3-4, were treated with digital litteracy, the other was not. Here we merge these groups, because digital litteracy had no effect, and that's how the authors designed the study. We are not here to judge. And I don't think it makes a difference anyways.",no,1,Ivory Coast,within,yes,no,,original,,local NGO,Social media (NGO),Social media (NGO),pro vs anti government,1,12,,0.33,title_picture (from real SM),source,accuracy,Do you believe this news story is false?,1,1,1,control,,,,,,,763,0.514,0.272,0.546,0.311,authors,no
36,"Gottlieb, J., Adida, C., & Moussa, R. (2022). Reducing Misinformation in a Polarized Context: Experimental Evidence from Côte d’Ivoire. OSF Preprints. https://doi.org/10.31219/osf.io/6x4wy",Gottlieb 2022,yes,,Authors sent the numbers by email,no,2,Ivory Coast,within,yes,no,,original,,local NGO,Social media (NGO),Social media (NGO),pro vs anti government,1,12,,0.33,title_picture (from real SM),source,accuracy,Do you believe this news story is false?,1,1,1,treatment,positive,empathy,"A script, read by an actor, described a life challenge faced by a member of the outgroup. Outgroup identity was conveyed via the surname and the village of origin of the reader and his or her partner. Participants randomly assigned to this condition heard the script for the member of the outgroup. The gender of the narrator matched the gender of the respondent",,,,361,0.507,0.261,0.571,0.316,authors,no
36,"Gottlieb, J., Adida, C., & Moussa, R. (2022). Reducing Misinformation in a Polarized Context: Experimental Evidence from Côte d’Ivoire. OSF Preprints. https://doi.org/10.31219/osf.io/6x4wy",Gottlieb 2022,yes,,Authors sent the numbers by email,no,3,Ivory Coast,within,yes,no,,original,,local NGO,Social media (NGO),Social media (NGO),pro vs anti government,1,12,,0.33,title_picture (from real SM),source,accuracy,Do you believe this news story is false?,1,1,1,treatment,positive,Norms,"Two focus group conversations (one focus group of 5-6 members of the Northern identity group; one focus group of 5-6 members of the Southern identity group), facilitated by professional enumerators, presented a discussion of people’s everyday positive experiences and interactions with members of the outgroup. Par- ticipants randomly assigned to this condition heard excerpts of this conversation among members of their ingroup",,,,376,0.536,0.284,0.543,0.328,authors,no
36,"Gottlieb, J., Adida, C., & Moussa, R. (2022). Reducing Misinformation in a Polarized Context: Experimental Evidence from Côte d’Ivoire. OSF Preprints. https://doi.org/10.31219/osf.io/6x4wy",Gottlieb 2022,yes,,Authors sent the numbers by email,no,4,Ivory Coast,within,yes,no,,original,,local NGO,Social media (NGO),Social media (NGO),pro vs anti government,1,12,,0.33,title_picture (from real SM),source,accuracy,Do you believe this news story is false?,1,1,1,treatment,positive,Popularity,"""A famous comedian with a heavy social media presence delivered a message about being a positive influencer, and how altruism and positivity have been at the root of his success. We chose a comedian who purposefully does not self-identify with either group",,,,391,0.518,0.273,0.559,0.329,authors,no
36,"Gottlieb, J., Adida, C., & Moussa, R. (2022). Reducing Misinformation in a Polarized Context: Experimental Evidence from Côte d’Ivoire. OSF Preprints. https://doi.org/10.31219/osf.io/6x4wy",Gottlieb 2022,yes,,Authors sent the numbers by email,no,5,Ivory Coast,within,yes,no,,original,,local NGO,Social media (NGO),Social media (NGO),pro vs anti government,1,12,,0.33,title_picture (from real SM),source,accuracy,Do you believe this news story is false?,1,1,1,control,,,,,,,397,0.509,0.267,0.534,0.31,authors,no
36,"Gottlieb, J., Adida, C., & Moussa, R. (2022). Reducing Misinformation in a Polarized Context: Experimental Evidence from Côte d’Ivoire. OSF Preprints. https://doi.org/10.31219/osf.io/6x4wy",Gottlieb 2022,yes,,Authors sent the numbers by email,no,6,Ivory Coast,within,yes,no,,original,,local NGO,Social media (NGO),Social media (NGO),pro vs anti government,1,12,,0.33,title_picture (from real SM),source,accuracy,Do you believe this news story is false?,1,1,1,treatment,positive,Digital litteracy ,a standard digital literacy intervention (providing information about what misinformation is and how it polarizes society),,,,366,0.518,0.28,0.558,0.311,authors,no
37,"Erlich, A., & Garner, C. (2023). Is pro-Kremlin Disinformation Effective? Evidence from Ukraine. The International Journal of Press/Politics, 28(1), 5–28. https://doi.org/10.1177/19401612211045221",Erlich 2023,,,"data correspond to study 1; values calculated based on their data to be able to differentiate between different types of groups; values cross-checked with their appendix table;
we averaged fake news news across the 'pro-kremelin' and the 'undermining Ukraine' groups; descriptive stats;
not explicitly clear how the fake news were displayed - 'title' only and 'no source' are coded based on best guesses from appendix;
regarding `news_pool`: ""In Study 1, we tested respondents’ belief in 98 claims divided between our 16 cells, of which 79 were disinformation claims identified by EUD and 19 were true stories."" Since we group by `news_family`, we divide this newspool by the amount of news_family groups (4). ",yes,1,Ukraine,within,yes,no,,original,,researchers,fact_checking,mainstream,economic,1,4,24.5,0.25,title,no_source,accuracy,respondents were asked whether they thought the story was true or false on a six-point scale from completely true (1) to completely false (6).,1,1,6,control,,,,,,,1974,2.69,1.53,3.58,1.4,raw data,no
37,"Erlich, A., & Garner, C. (2023). Is pro-Kremlin Disinformation Effective? Evidence from Ukraine. The International Journal of Press/Politics, 28(1), 5–28. https://doi.org/10.1177/19401612211045221",Erlich 2023,,,"data correspond to study 1; values calculated based on their data to be able to differentiate between different types of groups; values cross-checked with their appendix table;
we averaged fake news news across the 'pro-kremelin' and the 'undermining Ukraine' groups; descriptive stats;
not explicitly clear how the fake news were displayed - 'title' only and 'no source' are coded based on best guesses from appendix;
regarding `news_pool`: ""In Study 1, we tested respondents’ belief in 98 claims divided between our 16 cells, of which 79 were disinformation claims identified by EUD and 19 were true stories."" Since we group by `news_family`, we divide this newspool by the amount of news_family groups (4). ",yes,1,Ukraine,within,yes,no,,original,,researchers,fact_checking,mainstream,historical,2,4,24.5,0.25,title,no_source,accuracy,respondents were asked whether they thought the story was true or false on a six-point scale from completely true (1) to completely false (6).,1,1,6,control,,,,,,,1974,2.42,1.36,4.18,1.34,raw data,no
37,"Erlich, A., & Garner, C. (2023). Is pro-Kremlin Disinformation Effective? Evidence from Ukraine. The International Journal of Press/Politics, 28(1), 5–28. https://doi.org/10.1177/19401612211045221",Erlich 2023,,,"data correspond to study 1; values calculated based on their data to be able to differentiate between different types of groups; values cross-checked with their appendix table;
we averaged fake news news across the 'pro-kremelin' and the 'undermining Ukraine' groups; descriptive stats;
not explicitly clear how the fake news were displayed - 'title' only and 'no source' are coded based on best guesses from appendix;
regarding `news_pool`: ""In Study 1, we tested respondents’ belief in 98 claims divided between our 16 cells, of which 79 were disinformation claims identified by EUD and 19 were true stories."" Since we group by `news_family`, we divide this newspool by the amount of news_family groups (4). ",yes,1,Ukraine,within,yes,no,,original,,researchers,fact_checking,mainstream,military,3,4,24.5,0.25,title,no_source,accuracy,respondents were asked whether they thought the story was true or false on a six-point scale from completely true (1) to completely false (6).,1,1,6,control,,,,,,,1974,2.43,1.48,4.14,1.57,raw data,no
37,"Erlich, A., & Garner, C. (2023). Is pro-Kremlin Disinformation Effective? Evidence from Ukraine. The International Journal of Press/Politics, 28(1), 5–28. https://doi.org/10.1177/19401612211045221",Erlich 2023,,,"data correspond to study 1; values calculated based on their data to be able to differentiate between different types of groups; values cross-checked with their appendix table;
we averaged fake news news across the 'pro-kremelin' and the 'undermining Ukraine' groups; descriptive stats;
not explicitly clear how the fake news were displayed - 'title' only and 'no source' are coded based on best guesses from appendix;
regarding `news_pool`: ""In Study 1, we tested respondents’ belief in 98 claims divided between our 16 cells, of which 79 were disinformation claims identified by EUD and 19 were true stories."" Since we group by `news_family`, we divide this newspool by the amount of news_family groups (4). ",yes,1,Ukraine,within,yes,no,,original,,researchers,fact_checking,mainstream,political ,4,4,24.5,0.25,title,no_source,accuracy,respondents were asked whether they thought the story was true or false on a six-point scale from completely true (1) to completely false (6).,1,1,6,control,,,,,,,1974,2.4,1.43,4.38,1.5,raw data,no
37,"Erlich, A., & Garner, C. (2023). Is pro-Kremlin Disinformation Effective? Evidence from Ukraine. The International Journal of Press/Politics, 28(1), 5–28. https://doi.org/10.1177/19401612211045221",Erlich 2023,,,"data correspond to study 2; values calculated based on their data to be able to differentiate between different types of groups; values cross-checked with their appendix table;
As in study 1, respondents answered 1 question per cell (i.e. 16). However, in addition to that, respondents were randomly selected to evaluate all of three possible stories in one cell, hence evaluating 18 stories in total. We will ignore this, and just report as if they had evaluated 16. 
we averaged fake news news across the 'pro-kremelin' and the 'undermining Ukraine' groups; descriptive stats;
not explicitly clear how the fake news were displayed - 'title' only and 'no source' are coded based on best guesses from appendix;
regarding `news_pool`: ""Given the face-to-face nature of the study and time constraints, we chose only 48 stories on which to concentrate in this study—with three stories in each of the 16 cells, which maintained coverage on all three disinformation strategies, true stories, and all four topics. Additionally, respondents were randomly selected to choose all three stories in one cell, evaluating 18 stories in total."" Since we group by `news_family`, we divide this newspool by the amount of news_family groups (4). ",yes,2,Ukraine,within,no,no,,original,,researchers,fact_checking,mainstream,economic,1,4,12,0.25,title,no_source,accuracy,"Study 2 deviated in the outcome variable in that a mid-point “don’t know”(4) in the scale is a possible outcome, making it a seven-point (1-7) scale rather than a six-point (1-6) scale.",1,1,7,control,,,,,,,9474,3.49,1.87,3.54,1.87,raw data,no
37,"Erlich, A., & Garner, C. (2023). Is pro-Kremlin Disinformation Effective? Evidence from Ukraine. The International Journal of Press/Politics, 28(1), 5–28. https://doi.org/10.1177/19401612211045221",Erlich 2023,,,"data correspond to study 2; values calculated based on their data to be able to differentiate between different types of groups; values cross-checked with their appendix table;
As in study 1, respondents answered 1 question per cell (i.e. 16). However, in addition to that, respondents were randomly selected to evaluate all of three possible stories in one cell, hence evaluating 18 stories in total. We will ignore this, and just report as if they had evaluated 16. 
we averaged fake news news across the 'pro-kremelin' and the 'undermining Ukraine' groups; descriptive stats;
not explicitly clear how the fake news were displayed - 'title' only and 'no source' are coded based on best guesses from appendix;
regarding `news_pool`: ""Given the face-to-face nature of the study 
and time constraints, we chose only 48 stories on which to concentrate 
in this study—with three stories in each of the 16 cells, which 
maintained coverage on all three disinformation strategies, true 
stories, and all four topics. Additionally, respondents were randomly 
selected to choose all three stories in one cell, evaluating 18 stories 
in total."" Since we group by `news_family`, we divide this newspool by 
the amount of news_family groups (4). ",yes,2,Ukraine,within,no,no,,original,,researchers,fact_checking,mainstream,historical,2,4,12,0.25,title,no_source,accuracy,"Study 2 deviated in the outcome variable in that a mid-point “don’t know”(4) in the scale is a possible outcome, making it a seven-point (1-7) scale rather than a six-point (1-6) scale.",1,1,7,control,,,,,,,9474,2.95,1.72,4.35,1.62,raw data,no
37,"Erlich, A., & Garner, C. (2023). Is pro-Kremlin Disinformation Effective? Evidence from Ukraine. The International Journal of Press/Politics, 28(1), 5–28. https://doi.org/10.1177/19401612211045221",Erlich 2023,,,"data correspond to study 2; values calculated based on their data to be able to differentiate between different types of groups; values cross-checked with their appendix table;
As in study 1, respondents answered 1 question per cell (i.e. 16). However, in addition to that, respondents were randomly selected to evaluate all of three possible stories in one cell, hence evaluating 18 stories in total. We will ignore this, and just report as if they had evaluated 16. 
we averaged fake news news across the 'pro-kremelin' and the 'undermining Ukraine' groups; descriptive stats;
not explicitly clear how the fake news were displayed - 'title' only and 'no source' are coded based on best guesses from appendix;
regarding `news_pool`: ""Given the face-to-face nature of the study 
and time constraints, we chose only 48 stories on which to concentrate 
in this study—with three stories in each of the 16 cells, which 
maintained coverage on all three disinformation strategies, true 
stories, and all four topics. Additionally, respondents were randomly 
selected to choose all three stories in one cell, evaluating 18 stories 
in total."" Since we group by `news_family`, we divide this newspool by 
the amount of news_family groups (4). ",yes,2,Ukraine,within,no,no,,original,,researchers,fact_checking,mainstream,military,3,4,12,0.25,title,no_source,accuracy,"Study 2 deviated in the outcome variable in that a mid-point “don’t know”(4) in the scale is a possible outcome, making it a seven-point (1-7) scale rather than a six-point (1-6) scale.",1,1,7,control,,,,,,,9474,3.21,1.85,4.34,1.84,raw data,no
37,"Erlich, A., & Garner, C. (2023). Is pro-Kremlin Disinformation Effective? Evidence from Ukraine. The International Journal of Press/Politics, 28(1), 5–28. https://doi.org/10.1177/19401612211045221",Erlich 2023,,,"data correspond to study 2; values calculated based on their data to be able to differentiate between different types of groups; values cross-checked with their appendix table;
As in study 1, respondents answered 1 question per cell (i.e. 16). However, in addition to that, respondents were randomly selected to evaluate all of three possible stories in one cell, hence evaluating 18 stories in total. We will ignore this, and just report as if they had evaluated 16. 
we averaged fake news news across the 'pro-kremelin' and the 'undermining Ukraine' groups; descriptive stats;
not explicitly clear how the fake news were displayed - 'title' only and 'no source' are coded based on best guesses from appendix;
regarding `news_pool`: ""Given the face-to-face nature of the study 
and time constraints, we chose only 48 stories on which to concentrate 
in this study—with three stories in each of the 16 cells, which 
maintained coverage on all three disinformation strategies, true 
stories, and all four topics. Additionally, respondents were randomly 
selected to choose all three stories in one cell, evaluating 18 stories 
in total."" Since we group by `news_family`, we divide this newspool by 
the amount of news_family groups (4). ",yes,2,Ukraine,within,no,no,,original,,researchers,fact_checking,mainstream,political,4,4,12,0.25,title,no_source,accuracy,"Study 2 deviated in the outcome variable in that a mid-point “don’t know”(4) in the scale is a possible outcome, making it a seven-point (1-7) scale rather than a six-point (1-6) scale.",1,1,7,control,,,,,,,9474,3.25,1.8,4.8,1.82,raw data,no
38,"Ali, A., & Qazi, I. A. (2022). Digital Literacy and Vulnerability to Misinformation: Evidence from Facebook Users in Pakistan. Journal of Quantitative Description: Digital Media, 2.",Ali 2022,,,Data was obtained via email,yes,1,Pakistan,within,yes,no,,original,,researchers,fact_checking,fact_checking,general,1,6,,0.5,title_picture + AUDIO ,source,accuracy,"After viewing and hearing each news story, we ask whether they recalled seeing the
news before. We then ask questions related to their beliefs about whether the news is true or not (“Right now, do you think that this statement is true?”)",1,1,binary,control,,,,,,,674,0.22,0.41,0.43,0.94,authors,
39,"Altay, S., Lyons, B. A., & Modirrousta-Galian, A. (2024). Exposure to Higher Rates of False News Erodes Media Trust and Fuels Overconfidence. Mass Communication and Society, 1–25. https://doi.org/10.1080/15205436.2024.2382776",Altay 2023,,,"data correspond to pretest, value obtained from authors",no,1,US,within,yes,yes,"We selected true headlines from high and low prominence mainstream news sources. We selected quite random true headlines. For false headlines we selected any fact-checked false headlines we could find. We maximized discernment (we kept the most true headlines and the most false headlines); but as can be seen in S1 & S2, discernment is actually the same in the pre-test & S1-S2. ",original,,researchers,fact_checking,mainstream,general,1,20,109,0.57,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,control,,,,,,,100,1.62,0.81,2.88,0.87,raw data,
39,"Altay, S., Lyons, B. A., & Modirrousta-Galian, A. (2024). Exposure to Higher Rates of False News Erodes Media Trust and Fuels Overconfidence. Mass Communication and Society, 1–25. https://doi.org/10.1080/15205436.2024.2382776",Altay 2023,,,"data correspond to study 1 , ""False"" condition; values calculated based on raw data",no,2,US,within,yes,yes,"We selected true headlines from high and low prominence mainstream news sources. We selected quite random true headlines. For false headlines we selected any fact-checked false headlines we could find. We maximized discernment (we kept the most true headlines and the most false headlines); but as can be seen in S1 & S2, discernment is actually the same in the pre-test & S1-S2. ",original,,researchers,fact_checking,mainstream,general,1,18,84,0.33,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,control,,,,,,0.33,327,1.59,0.813,2.9,0.891,raw data,
39,"Altay, S., Lyons, B. A., & Modirrousta-Galian, A. (2024). Exposure to Higher Rates of False News Erodes Media Trust and Fuels Overconfidence. Mass Communication and Society, 1–25. https://doi.org/10.1080/15205436.2024.2382776",Altay 2023,,,"data correspond to study 1 , ""Mix"" condition; values calculated based on raw data",no,3,US,within,yes,yes,"We selected true headlines from high and low prominence mainstream news sources. We selected quite random true headlines. For false headlines we selected any fact-checked false headlines we could find. We maximized discernment (we kept the most true headlines and the most false headlines); but as can be seen in S1 & S2, discernment is actually the same in the pre-test & S1-S2. ",original,,researchers,fact_checking,mainstream,general,1,18,84,0.5,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,control,,,,,,0.5,330,1.59,0.839,2.95,0.88,raw data,
39,"Altay, S., Lyons, B. A., & Modirrousta-Galian, A. (2024). Exposure to Higher Rates of False News Erodes Media Trust and Fuels Overconfidence. Mass Communication and Society, 1–25. https://doi.org/10.1080/15205436.2024.2382776",Altay 2023,,,"data correspond to study 1 , ""True"" condition; values calculated based on raw data",no,4,US,within,yes,yes,"We selected true headlines from high and low prominence mainstream news sources. We selected quite random true headlines. For false headlines we selected any fact-checked false headlines we could find. We maximized discernment (we kept the most true headlines and the most false headlines); but as can be seen in S1 & S2, discernment is actually the same in the pre-test & S1-S2. ",original,,researchers,fact_checking,mainstream,general,1,18,84,0.66,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,control,,,,,,0.66,328,1.57,0.8,2.93,0.852,raw data,
39,"Altay, S., Lyons, B. A., & Modirrousta-Galian, A. (2024). Exposure to Higher Rates of False News Erodes Media Trust and Fuels Overconfidence. Mass Communication and Society, 1–25. https://doi.org/10.1080/15205436.2024.2382776",Altay 2023,,,"data correspond to study 2 , ""Strong False"" condition; values calculated based on raw data",no,5,US,within,yes,yes,"We selected true headlines from high and low prominence mainstream news sources. We selected quite random true headlines. For false headlines we selected any fact-checked false headlines we could find. We maximized discernment (we kept the most true headlines and the most false headlines); but as can be seen in S1 & S2, discernment is actually the same in the pre-test & S1-S2. ",original,,researchers,fact_checking,mainstream,general,1,18,84,0.83,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,control,,,,,,0.17,353,1.66,0.863,2.91,0.899,raw data,
39,"Altay, S., Lyons, B. A., & Modirrousta-Galian, A. (2024). Exposure to Higher Rates of False News Erodes Media Trust and Fuels Overconfidence. Mass Communication and Society, 1–25. https://doi.org/10.1080/15205436.2024.2382776",Altay 2023,,,"data correspond to study 2 , ""False"" condition; values calculated based on raw data",no,6,US,within,yes,yes,"We selected true headlines from high and low prominence mainstream news sources. We selected quite random true headlines. For false headlines we selected any fact-checked false headlines we could find. We maximized discernment (we kept the most true headlines and the most false headlines); but as can be seen in S1 & S2, discernment is actually the same in the pre-test & S1-S2. ",original,,researchers,fact_checking,mainstream,general,1,18,84,0.66,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,control,,,,,,0.33,345,1.65,0.836,2.92,0.838,raw data,
39,"Altay, S., Lyons, B. A., & Modirrousta-Galian, A. (2024). Exposure to Higher Rates of False News Erodes Media Trust and Fuels Overconfidence. Mass Communication and Society, 1–25. https://doi.org/10.1080/15205436.2024.2382776",Altay 2023,,,"data correspond to study 2 , ""Mix condition; values calculated based on raw data",no,7,US,within,yes,yes,"We selected true headlines from high and low prominence mainstream news sources. We selected quite random true headlines. For false headlines we selected any fact-checked false headlines we could find. We maximized discernment (we kept the most true headlines and the most false headlines); but as can be seen in S1 & S2, discernment is actually the same in the pre-test & S1-S2. ",original,,researchers,fact_checking,mainstream,general,1,18,84,0.5,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,control,,,,,,0.5,356,1.64,0.851,2.88,0.853,raw data,
39,"Altay, S., Lyons, B. A., & Modirrousta-Galian, A. (2024). Exposure to Higher Rates of False News Erodes Media Trust and Fuels Overconfidence. Mass Communication and Society, 1–25. https://doi.org/10.1080/15205436.2024.2382776",Altay 2023,,,"data correspond to study 2 , ""True"" condition; values calculated based on raw data",no,8,US,within,yes,yes,"We selected true headlines from high and low prominence mainstream news sources. We selected quite random true headlines. For false headlines we selected any fact-checked false headlines we could find. We maximized discernment (we kept the most true headlines and the most false headlines); but as can be seen in S1 & S2, discernment is actually the same in the pre-test & S1-S2. ",original,,researchers,fact_checking,mainstream,general,1,18,84,0.33,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,control,,,,,,0.66,348,1.69,0.87,2.91,0.852,raw data,
39,"Altay, S., Lyons, B. A., & Modirrousta-Galian, A. (2024). Exposure to Higher Rates of False News Erodes Media Trust and Fuels Overconfidence. Mass Communication and Society, 1–25. https://doi.org/10.1080/15205436.2024.2382776",Altay 2023,,,"data correspond to study 2 , ""Strong True"" condition; values calculated based on raw data",no,9,US,within,yes,yes,"We selected true headlines from high and low prominence mainstream news sources. We selected quite random true headlines. For false headlines we selected any fact-checked false headlines we could find. We maximized discernment (we kept the most true headlines and the most false headlines); but as can be seen in S1 & S2, discernment is actually the same in the pre-test & S1-S2. ",original,,researchers,fact_checking,mainstream,general,1,18,84,0.17,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,control,,,,,,0.83,349,1.73,0.89,2.89,0.845,raw data,
40,"Faragó, L., Krekó, P., & Orosz, G. (2023). Hungarian, lazy, and biased: The role of analytic thinking and partisanship in fake news discernment on a Hungarian representative sample. Scientific Reports, 13(1), 178. https://doi.org/10.1038/s41598-022-26724-8",Farago 2023,,,"data is taken from supplemental information, table S1",yes,1,Hungary,within,yes,no,,original,,researchers,fact_checking,mainstream,general,1,10,,0.5,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,control,,,,,,,991,1.9,0.53,2.37,0.56,paper,no
40,"Faragó, L., Krekó, P., & Orosz, G. (2023). Hungarian, lazy, and biased: The role of analytic thinking and partisanship in fake news discernment on a Hungarian representative sample. Scientific Reports, 13(1), 178. https://doi.org/10.1038/s41598-022-26724-8",Farago 2023,,,"data is taken from supplemental information, table S1;
Political is in this case Pro-Orban ",yes,1,Hungary,within,yes,no,,original,,researchers,fact_checking,mainstream,Political_pro_gov,2,10,,0.5,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,control,,,,,,,991,1.97,0.66,2.22,0.59,paper,no
40,"Faragó, L., Krekó, P., & Orosz, G. (2023). Hungarian, lazy, and biased: The role of analytic thinking and partisanship in fake news discernment on a Hungarian representative sample. Scientific Reports, 13(1), 178. https://doi.org/10.1038/s41598-022-26724-8",Farago 2023,,,"data is taken from supplemental information, table S1;
Political is in this case Anti-Orban ",yes,1,Hungary,within,yes,no,,original,,researchers,fact_checking,mainstream,Political_anti_gov,3,10,,0.5,title_picture,source,accuracy,"News headline evaluations To the best of your knowledge, how accurate is the claim in the above headline? -Not at all accurate (1) -Not very accurate (2) -Somewhat accurate (3) -Very accurate (4)",1,0,4,control,,,,,,,991,2.28,0.63,2.54,0.7,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 1, values taken from supplemental doc (Appendix C; conservative sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,1,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_concordant,1,5,,0.4,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,treatment,positive,media_literacy_video,priming-video (i.e. watching a 3-minute media literacy video about “fake news”),,,,64,3.82,1.07,4.24,1.24,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 1, values taken from supplemental doc (Appendix C; conservative sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,1,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_discordant,2,5,,0.4,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,treatment,positive,media_literacy_video,priming-video (i.e. watching a 3-minute media literacy video about “fake news”),,,,64,4.03,0.98,4.07,1.08,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 1, values taken from supplemental doc (Appendix C; conservative sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,2,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_concordant,1,5,,0.4,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,treatment,positive,priming_question_recall_fake,"in the priming-question condition were asked if they had seen or heard “fake news,” and if so, through which channel",,,,64,4.07,1.16,4.29,1.28,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 1, values taken from supplemental doc (Appendix C; conservative sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,2,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_discordant,2,5,,0.4,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,treatment,positive,priming_question_recall_fake,"in the priming-question condition were asked if they had seen or heard “fake news,” and if so, through which channel",,,,64,3.95,0.88,3.82,0.98,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 1, values taken from supplemental doc (Appendix C; conservative sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,3,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_concordant,1,5,,0.4,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,control,,,,,,,64,4.7,1.06,5.1,1.07,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 1, values taken from supplemental doc (Appendix C; conservative sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,3,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_discordant,2,5,,0.4,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,control,,,,,,,64,4.5,1.05,4.22,1.05,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 1, values taken from supplemental doc (Appendix C; liberal sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,4,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_discordant,1,5,,0.4,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,treatment,positive,media_literacy_video,priming-video (i.e. watching a 3-minute media literacy video about “fake news”),,,,64,3.33,1.2,3.72,1.19,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 1, values taken from supplemental doc (Appendix C; liberal sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,4,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_concordant,2,5,,0.4,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,treatment,positive,media_literacy_video,priming-video (i.e. watching a 3-minute media literacy video about “fake news”),,,,64,4.22,1.01,4.47,1.11,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 1, values taken from supplemental doc (Appendix C; liberal sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,5,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_discordant,1,5,,0.4,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,treatment,positive,priming_question_recall_fake,"in the priming-question condition were asked if they had seen or heard “fake news,” and if so, through which channel",,,,64,3.24,1.29,3.64,1.29,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 1, values taken from supplemental doc (Appendix C; liberal sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,5,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_concordant,2,5,,0.4,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,treatment,positive,priming_question_recall_fake,"in the priming-question condition were asked if they had seen or heard “fake news,” and if so, through which channel",,,,64,4.28,1.17,4.67,0.99,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 1, values taken from supplemental doc (Appendix C; liberal sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,6,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_discordant,1,5,,0.4,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,control,,,,,,,64,3.95,1.24,4.13,1.33,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 1, values taken from supplemental doc (Appendix C; liberal sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,6,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_concordant,2,5,,0.4,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,control,,,,,,,64,4.69,0.93,4.54,1.16,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 2, values taken from supplemental doc (Appendix E; conservative sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,7,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_concordant,3,4,,0.5,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,treatment,positive,media_literacy_video,"identical to those of Study 1, except that those in the priming-video condition watched one of the two 2.5 min video clips randomly assigned to them, which emphasized the harms of fake news and the importance of media literacy (see Appendix A for the script; Appendix E for descriptive statistics)",,,,100,4.34,1.17,4.09,1.18,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 2, values taken from supplemental doc (Appendix E; conservative sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,7,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_discordant,4,4,,0.5,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,treatment,positive,media_literacy_video,"identical to those of Study 1, except that those in the priming-video condition watched one of the two 2.5 min video clips randomly assigned to them, which emphasized the harms of fake news and the importance of media literacy (see Appendix A for the script; Appendix E for descriptive statistics)",,,,100,3.16,1.41,3.31,1.2,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 2, values taken from supplemental doc (Appendix E; conservative sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,8,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_concordant,3,4,,0.5,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,treatment,positive,priming_question_recall_fake,"in the priming-question condition were asked if they had seen or heard “fake news,” and if so, through which channel",,,,100,3.97,1.28,4.14,1.21,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 2, values taken from supplemental doc (Appendix E; conservative sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,8,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_discordant,4,4,,0.5,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,treatment,positive,priming_question_recall_fake,"in the priming-question condition were asked if they had seen or heard “fake news,” and if so, through which channel",,,,100,3.17,1.27,3.37,1.22,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 2, values taken from supplemental doc (Appendix E; conservative sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,9,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_concordant,3,4,,0.5,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,control,,,,,,,100,4.52,1.27,4.63,1.3,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 2, values taken from supplemental doc (Appendix E; conservative sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,9,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_discordant,4,4,,0.5,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,control,,,,,,,100,3.59,1.51,3.59,1.48,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 2, values taken from supplemental doc (Appendix E; liberal sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,10,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_discordant,3,4,,0.5,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,treatment,positive,media_literacy_video,"identical to those of Study 1, except that those in the priming-video condition watched one of the two 2.5 min video clips randomly assigned to them, which emphasized the harms of fake news and the importance of media literacy (see Appendix A for the script; Appendix E for descriptive statistics)",,,,100,3.28,1.12,3.29,1.17,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 2, values taken from supplemental doc (Appendix E; liberal sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,10,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_concordant,4,4,,0.5,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,treatment,positive,media_literacy_video,"identical to those of Study 1, except that those in the priming-video condition watched one of the two 2.5 min video clips randomly assigned to them, which emphasized the harms of fake news and the importance of media literacy (see Appendix A for the script; Appendix E for descriptive statistics)",,,,100,4.15,1.24,3.98,1.19,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 2, values taken from supplemental doc (Appendix E; liberal sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,11,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_discordant,3,4,,0.5,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,treatment,positive,priming_question_recall_fake,"in the priming-question condition were asked if they had seen or heard “fake news,” and if so, through which channel",,,,100,3.55,1.28,3.42,1.22,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 2, values taken from supplemental doc (Appendix E; liberal sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,11,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_concordant,4,4,,0.5,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,treatment,positive,priming_question_recall_fake,"in the priming-question condition were asked if they had seen or heard “fake news,” and if so, through which channel",,,,100,4.21,1.28,4.04,1.27,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 2, values taken from supplemental doc (Appendix E; liberal sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,12,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_discordant,3,4,,0.5,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,control,,,,,,,100,3.75,1.2,3.97,1.26,paper,no
41,"Eun-Ju Lee & Jeong-woo Jang (2023): How Political Identity and Misinformation Priming Affect Truth Judgments and Sharing Intention of Partisan News, Digital Journalism, DOI: 10.1080/21670811.2022.2163413",Eun-Ju 2023,yes,,"data corresponds to study 2, values taken from supplemental doc (Appendix E; liberal sample);
Regarding news family: The table show anti_gov and pro_gov news. From the article, we know that we should could anti_gov = concordant for conservatives/discordant for democrats (and vice versa for pro_gov):
""Such a partisan divide was also evident in a recent national survey where 74% of liberals agreed that the Korean government effectively responded to the COVID-19 pandemic, with only 30% of conservatives reporting the same (Gallup 2022). Therefore, H1a-b were proposed to test if partisan identity biases individuals’ trust in partisan news in a controlled experiment. H1a-b Individuals rate partisan information to be more truthful that is congruent rather than incongruent with their political identity. That is, (a) liberals judge partisan news to be more truthful that is favorable (vs. unfavorable) to the liberal government, but (b) conservatives exhibit the opposite tendency.""
Regarding share of true news: Across the whole set of news (n = 10), the share of true news is 0.4. However, we look at pro (n = 5) and anti (n = 5) government news seperately. We don't know the share within those. Hence, we just code 0.4.",yes,12,South Korea,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_concordant,4,4,,0.5,title,no_source,accuracy,"participants rated how accurate (1 = not accurate at all, 7 = accurate) and believable (1 = not believable at all, 7 = very believable)",1,0,7,control,,,,,,,100,4.66,1.2,4.36,1.19,paper,no
42,"Baptista, J. P., Correia, E., Gradim, A., & Piñeiro-Naval, V. (2021). The Influence of Political Ideology on Fake News Belief: The Portuguese Case. Publications, 9(2), 23. https://doi.org/10.3390/publications9020023",Baptista 2021,,,"data correspond to left-wing respondents, pro-left news items; values taken from table 2",yes,1,Portugal,within,yes,no,,original,,researchers,fact_checking,NA,politically_concordant,1,10,,0.5,title_picture,source,credibility,"“According to your knowledge, how do you rate the following headline? on a 5point scale (1—not credible; 2—somehow credible; 3—quite credible; 4—credible; 5—very credible).""",0,0,5,control,,,,,,,339,1.99,0.73,2.5,0.71,paper,no
42,"Baptista, J. P., Correia, E., Gradim, A., & Piñeiro-Naval, V. (2021). The Influence of Political Ideology on Fake News Belief: The Portuguese Case. Publications, 9(2), 23. https://doi.org/10.3390/publications9020023",Baptista 2021,,,"data correspond to left-wing respondents, pro-right news items; values taken from table 2",yes,1,Portugal,within,yes,no,,original,,researchers,fact_checking,NA,politically_discordant,2,10,,0.5,title_picture,source,credibility,"“According to your knowledge, how do you rate the following headline? on a 5point scale (1—not credible; 2—somehow credible; 3—quite credible; 4—credible; 5—very credible).""",0,0,5,control,,,,,,,339,1.5,0.59,2.44,0.66,paper,no
42,"Baptista, J. P., Correia, E., Gradim, A., & Piñeiro-Naval, V. (2021). The Influence of Political Ideology on Fake News Belief: The Portuguese Case. Publications, 9(2), 23. https://doi.org/10.3390/publications9020023",Baptista 2021,,,"data correspond to right-wing respondents, pro-right news items; values taken from table 2",yes,2,Portugal,within,yes,no,,original,,researchers,fact_checking,NA,politically_concordant,2,10,,0.5,title_picture,source,credibility,"“According to your knowledge, how do you rate the following headline? on a 5point scale (1—not credible; 2—somehow credible; 3—quite credible; 4—credible; 5—very credible).""",0,0,5,control,,,,,,,162,2.01,0.71,2.86,0.79,paper,no
42,"Baptista, J. P., Correia, E., Gradim, A., & Piñeiro-Naval, V. (2021). The Influence of Political Ideology on Fake News Belief: The Portuguese Case. Publications, 9(2), 23. https://doi.org/10.3390/publications9020023",Baptista 2021,,,"data correspond to right-wing respondents, pro-left news items; values taken from table 2",yes,2,Portugal,within,yes,no,,original,,researchers,fact_checking,NA,politically_discordant,1,10,,0.5,title_picture,source,credibility,"“According to your knowledge, how do you rate the following headline? on a 5point scale (1—not credible; 2—somehow credible; 3—quite credible; 4—credible; 5—very credible).""",0,0,5,control,,,,,,,162,2.22,0.75,2.45,0.65,paper,no
42,"Baptista, J. P., Correia, E., Gradim, A., & Piñeiro-Naval, V. (2021). The Influence of Political Ideology on Fake News Belief: The Portuguese Case. Publications, 9(2), 23. https://doi.org/10.3390/publications9020023",Baptista 2021,,,"data correspond to center respondents, pro-left news items; values taken from table 2",yes,3,Portugal,within,yes,no,,original,,researchers,fact_checking,NA,politically_pro-left,1,10,,0.5,title_picture,source,credibility,"“According to your knowledge, how do you rate the following headline? on a 5point scale (1—not credible; 2—somehow credible; 3—quite credible; 4—credible; 5—very credible).""",0,0,5,control,,,,,,,211,2.09,0.74,2.45,0.67,paper,no
42,"Baptista, J. P., Correia, E., Gradim, A., & Piñeiro-Naval, V. (2021). The Influence of Political Ideology on Fake News Belief: The Portuguese Case. Publications, 9(2), 23. https://doi.org/10.3390/publications9020023",Baptista 2021,,,"data correspond to center respondents, pro-right news items; values taken from table 2",yes,3,Portugal,within,yes,no,,original,,researchers,fact_checking,NA,politically_pro-right,2,10,,0.5,title_picture,source,credibility,"“According to your knowledge, how do you rate the following headline? on a 5point scale (1—not credible; 2—somehow credible; 3—quite credible; 4—credible; 5—very credible).""",0,0,5,control,,,,,,,211,1.79,0.72,2.6,0.74,paper,no
44,"Kirill Bryanov, Reinhold Kliegl, Olessia Koltsova, Tetyana Lokot, Alex Miltsov, Sergei Pashakhin, Alexander Porshnev, Yadviga Sinyavskaya, Maksim Terpilovskii & Victoria Vziatysheva (2023) What Drives Perceptions of Foreign News Coverage Credibility? A Cross- National Experiment Including Kazakhstan, Russia, and Ukraine, Political Communication, 40:2, 115-146, DOI: 10.1080/10584609.2023.2172492",Bryanov 2023,,,"Here it's Russian news in russian; they manipulated the source (but no effect) and whether the news was in accordance with dominant/alternative narrative. But because they did it for both true & false, i don't think it's a problem to include it",yes,1,Kazakhstan,within,yes,no,,original,,researchers,created by a journalist,mainstream,political,1,8,24,0.5,title,source,credibility,Participants were asked to evaluate each news item’s credibility on a six-point Likert scale ranging from “True” to “Fake.”,1,1,6,control,,,,,,,1817,3.05,2.051,3.473,2.09,paper,no
44,"Kirill Bryanov, Reinhold Kliegl, Olessia Koltsova, Tetyana Lokot, Alex Miltsov, Sergei Pashakhin, Alexander Porshnev, Yadviga Sinyavskaya, Maksim Terpilovskii & Victoria Vziatysheva (2023) What Drives Perceptions of Foreign News Coverage Credibility? A Cross- National Experiment Including Kazakhstan, Russia, and Ukraine, Political Communication, 40:2, 115-146, DOI: 10.1080/10584609.2023.2172492",Bryanov 2023,,,"Here it's KZ news in russian; they note that: ""in our experiment fakes were experimentally constructed to be very difficult to discriminate from true news""",yes,2,Russia,within,yes,no,,original,,researchers,created by a journalist,mainstream,political,2,8,24,0.5,title,source,credibility,Participants were asked to evaluate each news item’s credibility on a six-point Likert scale ranging from “True” to “Fake.”,1,1,6,control,,,,,,,1836,3.116,2.009,3.782,2.015,paper,no
44,"Kirill Bryanov, Reinhold Kliegl, Olessia Koltsova, Tetyana Lokot, Alex Miltsov, Sergei Pashakhin, Alexander Porshnev, Yadviga Sinyavskaya, Maksim Terpilovskii & Victoria Vziatysheva (2023) What Drives Perceptions of Foreign News Coverage Credibility? A Cross- National Experiment Including Kazakhstan, Russia, and Ukraine, Political Communication, 40:2, 115-146, DOI: 10.1080/10584609.2023.2172492",Bryanov 2023,,,Here it's KZ news in russian,yes,3,Russia,within,yes,no,,original,,researchers,created by a journalist,mainstream,political,3,8,24,0.5,title,source,credibility,Participants were asked to evaluate each news item’s credibility on a six-point Likert scale ranging from “True” to “Fake.”,1,1,6,control,,,,,,,2050,3.056,1.993,3.929,1.991,paper,no
44,"Kirill Bryanov, Reinhold Kliegl, Olessia Koltsova, Tetyana Lokot, Alex Miltsov, Sergei Pashakhin, Alexander Porshnev, Yadviga Sinyavskaya, Maksim Terpilovskii & Victoria Vziatysheva (2023) What Drives Perceptions of Foreign News Coverage Credibility? A Cross- National Experiment Including Kazakhstan, Russia, and Ukraine, Political Communication, 40:2, 115-146, DOI: 10.1080/10584609.2023.2172492",Bryanov 2023,,,"Here it's Russian news in russian; they manipulated the source (but no effect) and whether the news was in accordance with dominant/alternative narrative. But because they did it for both true & false, i don't think it's a problem to include it",yes,4,Ukraine,within,yes,no,,original,,researchers,created by a journalist,mainstream,political,1,8,24,0.5,title,source,credibility,Participants were asked to evaluate each news item’s credibility on a six-point Likert scale ranging from “True” to “Fake.”,1,1,6,control,,,,,,,1731,3.124,2.073,3.777,2.071,paper,no
44,"Kirill Bryanov, Reinhold Kliegl, Olessia Koltsova, Tetyana Lokot, Alex Miltsov, Sergei Pashakhin, Alexander Porshnev, Yadviga Sinyavskaya, Maksim Terpilovskii & Victoria Vziatysheva (2023) What Drives Perceptions of Foreign News Coverage Credibility? A Cross- National Experiment Including Kazakhstan, Russia, and Ukraine, Political Communication, 40:2, 115-146, DOI: 10.1080/10584609.2023.2172492",Bryanov 2023,,,"Here it's Russian news in russian; they manipulated the source (but no effect) and whether the news was in accordance with dominant/alternative narrative. But because they did it for both true & false, i don't think it's a problem to include it",yes,5,Ukraine,within,yes,no,,original,,researchers,created by a journalist,mainstream,political,4,8,24,0.5,title,source,credibility,Participants were asked to evaluate each news item’s credibility on a six-point Likert scale ranging from “True” to “Fake.”,1,1,6,control,,,,,,,1125,3.26,2.119,3.922,2.069,paper,no
45,"Smelter, T. J., & Calvillo, D. P. (2020). Pictures and repeated exposure increase perceived accuracy of news headlines. Applied Cognitive Psychology, 34(5), 1061–1071. https://doi.org/10.1002/acp.3684",Smelter 2020,yes,,"data correspond to study 1, picture condition; values from own calculations based on their data;
note that we code both picture and no picture as control conditions (we treat them as differences in appearence that vary across studies)",yes,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,non_political,1,14,,0.5,title_picture_pitch,no_source,accuracy,"""The dependent variable was perceived accuracy, which was measured on a 1 (not at all accurate)to 4(very accurate) scale.""",1,0,4,control,,,,,,,211,2.53,1.03,2.62,0.963,raw data,no
45,"Smelter, T. J., & Calvillo, D. P. (2020). Pictures and repeated exposure increase perceived accuracy of news headlines. Applied Cognitive Psychology, 34(5), 1061–1071. https://doi.org/10.1002/acp.3684",Smelter 2020,yes,,"data correspond to study 1, NOpicture condition; values from own calculations based on their data;
note that we code both picture and no picture as control conditions (we treat them as differences in appearence that vary across studies)",yes,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,non_political,2,14,,0.5,title_pitch,no_source,accuracy,"""The dependent variable was perceived accuracy, which was measured on a 1 (not at all accurate)to 4(very accurate) scale.""",1,0,4,control,,,,,,,211,2.41,0.972,2.52,0.946,raw data,no
45,"Smelter, T. J., & Calvillo, D. P. (2020). Pictures and repeated exposure increase perceived accuracy of news headlines. Applied Cognitive Psychology, 34(5), 1061–1071. https://doi.org/10.1002/acp.3684",Smelter 2020,yes,,"data correspond to study 2a, fluent condition; values from own calculations based on their data;
note that we code the fluent condition as a control condition since that's what all other control conditions are; we code the disfluent condition as negative treatment, as the authors hypothesized it to reduce accuracy ratings. ",yes,2,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,non_political,3,10,,0.5,title_picture_pitch,no_source,accuracy,"""The dependent variable was perceived accuracy, which was measured on a 1 (not at all accurate)to 4(very accurate) scale.""",1,0,4,control,,,,,,,120,2.14,0.491,2.6,0.382,raw data,no
45,"Smelter, T. J., & Calvillo, D. P. (2020). Pictures and repeated exposure increase perceived accuracy of news headlines. Applied Cognitive Psychology, 34(5), 1061–1071. https://doi.org/10.1002/acp.3684",Smelter 2020,yes,,"data correspond to study 2a, disfluent condition; values from own calculations based on their data;
note that we code the fluent condition as a control condition since that's what all other control conditions are; we code the disfluent condition as negative treatment, as the authors hypothesized it to reduce accuracy ratings. ",yes,2,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,non_political,4,10,,0.5,title_picture_pitch,no_source,accuracy,"""The dependent variable was perceived accuracy, which was measured on a 1 (not at all accurate)to 4(very accurate) scale.""",1,0,4,treatment,negative,blurred,"Half of the headlines they saw were presented in a perceptually clear manner (five true and five false) and half were in a perceptually degraded manner (five true and five false);
All headlines were accompanied by a picture. The perceptually clear headlines had unaltered pictures and the perceptually degraded headlines had the same pictures but were run through a blur filter.",,,,120,2.29,0.539,2.76,0.435,raw data,no
45,"Smelter, T. J., & Calvillo, D. P. (2020). Pictures and repeated exposure increase perceived accuracy of news headlines. Applied Cognitive Psychology, 34(5), 1061–1071. https://doi.org/10.1002/acp.3684",Smelter 2020,yes,,"data correspond to study 2b, fluent condition; values from own calculations based on their data;
note that we code the fluent condition as a control condition since that's what all other control conditions are; we code the disfluent condition as negative treatment, as the authors hypothesized it to reduce accuracy ratings;
we coded newsID as ""NA"" since the headlines were the same as in study 2a, but a combination of newsID = 3 and 4. We want to avoid to count these twice when checking unique headlines ",yes,3,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,non_political,NA,20,,0.5,title_picture_pitch,no_source,accuracy,"""The dependent variable was perceived accuracy, which was measured on a 1 (not at all accurate)to 4(very accurate) scale.""",1,0,4,control,,,,,,,63,2.01,0.425,3.02,0.302,raw data,no
45,"Smelter, T. J., & Calvillo, D. P. (2020). Pictures and repeated exposure increase perceived accuracy of news headlines. Applied Cognitive Psychology, 34(5), 1061–1071. https://doi.org/10.1002/acp.3684",Smelter 2020,yes,,"data correspond to study 2b, disfluent condition; values from own calculations based on their data;
note that we code the fluent condition as a control condition since that's what all other control conditions are; we code the disfluent condition as negative treatment, as the authors hypothesized it to reduce accuracy ratings;
we coded newsID as ""NA"" since the headlines were the same as in study 2a, but a combination of newsID = 3 and 4. We want to avoid to count these twice when checking unique headlines ",yes,4,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,non_political,NA,20,,0.5,title_picture_pitch,no_source,accuracy,"""The dependent variable was perceived accuracy, which was measured on a 1 (not at all accurate)to 4(very accurate) scale.""",1,0,4,treatment,negative,blurred,"Half of the headlines they saw were presented in a perceptually clear manner (five true and five false) and half were in a perceptually degraded manner (five true and five false);
All headlines were accompanied by a picture. The perceptually clear headlines had unaltered pictures and the perceptually degraded headlines had the same pictures but were run through a blur filter.",,,,65,2.12,0.517,2.97,0.376,raw data,no
45,"Smelter, T. J., & Calvillo, D. P. (2020). Pictures and repeated exposure increase perceived accuracy of news headlines. Applied Cognitive Psychology, 34(5), 1061–1071. https://doi.org/10.1002/acp.3684",Smelter 2020,yes,,"data correspond to study 3, no prior condition; values from own calculations based on their data;
note that we code the fluent condition as a control condition since that's what all other control conditions are; we code the disfluent condition as negative treatment, as the authors hypothesized it to reduce accuracy ratings;
we coded newsID as ""NA"" since the headlines were the same as in studies 1 and 2. We want to avoid to count these twice when checking unique headlines ",yes,5,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,non_political,NA,24,,0.5,title_picture_pitch,no_source,accuracy,"""The dependent variable was perceived accuracy, which was measured on a 1 (not at all accurate)to 4(very accurate) scale.""",1,0,4,control,,,,,,,200,2.09,0.529,2.7,0.399,raw data,no
45,"Smelter, T. J., & Calvillo, D. P. (2020). Pictures and repeated exposure increase perceived accuracy of news headlines. Applied Cognitive Psychology, 34(5), 1061–1071. https://doi.org/10.1002/acp.3684",Smelter 2020,yes,,"data correspond to study 3, prior condition; values from own calculations based on their data;
note that we code the fluent condition as a control condition since that's what all other control conditions are; we code the disfluent condition as negative treatment, as the authors hypothesized it to reduce accuracy ratings;
we coded newsID as ""NA"" since the headlines were the same as in studies 1 and 2. We want to avoid to count these twice when checking unique headlines ",yes,5,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,non_political,NA,24,,0.5,title_picture_pitch,no_source,accuracy,"""The dependent variable was perceived accuracy, which was measured on a 1 (not at all accurate)to 4(very accurate) scale.""",1,0,4,treatment,negative,familiarization,"We had participants rate some true and false headlines for humor, complete a CRT, and then had them rate their perceived accuracy for a larger set of headlines that included those they had previously rated for humor and some they had not. Thus, we manipulated prior exposure.",,,,200,2.26,0.495,2.82,0.389,raw data,no
46,"Ross, B., Heisel, J., Jung, A.-K., & Stieglitz, S. (2018). Fake News on Social Media: The (In)Effectiveness of Warning Messages.",Ross 2018,yes,,"data correspond to control condition (no warning); values taken from paper (results section, first paragraph);
the authors coded correct vs. non correct responses. While for true news, hits correspond to accurate vs. not accurate, for fake news, we code accuracy score as 1 - hits (or misses). SD's remain the same in both cases.;
lack of transparency about the sample, all we know from one section is that "" Since many participants were recruited in Germany, a summary in German was displayed alongside the post."", which is why we coded Germany.",no,1,Germany,within,yes,yes,"In order to ensure that the fake and real news stories were otherwise comparable, six topics were chosen (‘health’, ‘sex’, ‘nature’, ‘Trump’, ‘Syria’ and ‘crime’).
A pretest with thirteen participants was carried out to confirm that the selected news stories were appropriate. Ideally, the stories should not be familiar to the participants, and participants’ responses to the stories should vary. It would pose difficulties for the statistical analysis if most of the stories were considered manipulated by almost all or by almost none of the participants, as this could lead to a highly skewed or truncated distribution in the dependent variable. As a result of the pretest, one of the stories was replaced, since two participants were familiar with it. The remaining stories were only known to one participant (in two cases) or none at all (in all other cases). The number of hits and false alarms was determined for each participant and showed enough variation to be suitable for statistical analysis. The remaining stories were therefore kept.",original,,researchers,fact_checking,fact_checking,mixed_health_sex_trump_nature_syria_crime,1,12,,0.5,title_picture_pitch,no_source,manipulation,"This story seems to be manipulated or fake. (yes/no)
(note that our summary stats reverse the answers, to be coherent with the coding of other studies)",1,1,binary,control,,,,,,,53,0.36,0.21,0.5,0.19,paper,no
46,"Ross, B., Heisel, J., Jung, A.-K., & Stieglitz, S. (2018). Fake News on Social Media: The (In)Effectiveness of Warning Messages.",Ross 2018,yes,,"data correspond to treatment condition (simple warning); values taken from paper (results section, first paragraph);
the authors coded correct vs. non correct responses. While for true news, hits correspond to accurate vs. not accurate, for fake news, we code accuracy score as 1 - hits (or misses). SD's remain the same in both cases.;
lack of transparency about the sample, all we know from one section is that "" Since many participants were recruited in Germany, a summary in German was displayed alongside the post."", which is why we coded Germany.",no,2,Germany,within,yes,yes,"In order to ensure that the fake and real news stories were otherwise comparable, six topics were chosen (‘health’, ‘sex’, ‘nature’, ‘Trump’, ‘Syria’ and ‘crime’).
A pretest with thirteen participants was carried out to confirm that the selected news stories were appropriate. Ideally, the stories should not be familiar to the participants, and participants’ responses to the stories should vary. It would pose difficulties for the statistical analysis if most of the stories were considered manipulated by almost all or by almost none of the participants, as this could lead to a highly skewed or truncated distribution in the dependent variable. As a result of the pretest, one of the stories was replaced, since two participants were familiar with it. The remaining stories were only known to one participant (in two cases) or none at all (in all other cases). The number of hits and false alarms was determined for each participant and showed enough variation to be suitable for statistical analysis. The remaining stories were therefore kept.",original,,researchers,fact_checking,fact_checking,mixed_health_sex_trump_nature_syria_crime,1,12,,0.5,title_picture_pitch,no_source,manipulation,"This story seems to be manipulated or fake. (yes/no)
(note that our summary stats reverse the answers, to be coherent with the coding of other studies)",1,1,binary,treatment,positive,warning,"Participants in the first condition were shown all twelve news items without any warning messages. Participants in conditions 2 and 3 were shown six news items (three fake, three real) with a warning message and the remaining six items without one. Conditions 2 and 3 differed in the warning message that was shown.
The design of the simple warning was identical to the one presented by Facebook in their original announcement of their work on flagging news stories: “Disputed by 3rd party Fact-Checkers. Learn why this is disputed”.
The design of the warning with advice was based on the work by Xiao and Benbasat (2015). By displaying a warning message that contains advice alongside the post, participants should be provided with the right information in order to distinguish fake news from real news. The following message was used: “Disputed by 3rd party Fact-Checkers. Research shows that users who fail to verify the story’s correctness have an increased risk of being misled by fake news.”",,,,50,0.38,0.24,0.5,0.25,paper,no
46,"Ross, B., Heisel, J., Jung, A.-K., & Stieglitz, S. (2018). Fake News on Social Media: The (In)Effectiveness of Warning Messages.",Ross 2018,yes,,"data correspond to treatment condition (simple warning); values taken from paper (results section, first paragraph);
the authors coded correct vs. non correct responses. While for true news, hits correspond to accurate vs. not accurate, for fake news, we code accuracy score as 1 - hits (or misses). SD's remain the same in both cases.;
lack of transparency about the sample, all we know from one section is that "" Since many participants were recruited in Germany, a summary in German was displayed alongside the post."", which is why we coded Germany.",no,3,Germany,within,yes,yes,"In order to ensure that the fake and real news stories were otherwise comparable, six topics were chosen (‘health’, ‘sex’, ‘nature’, ‘Trump’, ‘Syria’ and ‘crime’).
A pretest with thirteen participants was carried out to confirm that the selected news stories were appropriate. Ideally, the stories should not be familiar to the participants, and participants’ responses to the stories should vary. It would pose difficulties for the statistical analysis if most of the stories were considered manipulated by almost all or by almost none of the participants, as this could lead to a highly skewed or truncated distribution in the dependent variable. As a result of the pretest, one of the stories was replaced, since two participants were familiar with it. The remaining stories were only known to one participant (in two cases) or none at all (in all other cases). The number of hits and false alarms was determined for each participant and showed enough variation to be suitable for statistical analysis. The remaining stories were therefore kept.",original,,researchers,fact_checking,fact_checking,mixed_health_sex_trump_nature_syria_crime,1,12,,0.5,title_picture_pitch,no_source,manipulation,"This story seems to be manipulated or fake. (yes/no)
(note that our summary stats reverse the answers, to be coherent with the coding of other studies)",1,1,binary,treatment,positive,warning,"Participants in the first condition were shown all twelve news items without any warning messages. Participants in conditions 2 and 3 were shown six news items (three fake, three real) with a warning message and the remaining six items without one. Conditions 2 and 3 differed in the warning message that was shown.
The design of the simple warning was identical to the one presented by Facebook in their original announcement of their work on flagging news stories: “Disputed by 3rd party Fact-Checkers. Learn why this is disputed”.
The design of the warning with advice was based on the work by Xiao and Benbasat (2015). By displaying a warning message that contains advice alongside the post, participants should be provided with the right information in order to distinguish fake news from real news. The following message was used: “Disputed by 3rd party Fact-Checkers. Research shows that users who fail to verify the story’s correctness have an increased risk of being misled by fake news.”",,,,48,0.32,0.2,0.41,0.24,paper,no
47,"Lühring, J., Shetty, A., Koschmieder, C., Garcia, D., Waldherr, A., & Metzler, H. (2023). Emotions in misinformation studies: Distinguishing affective state from emotional response and misinformation recognition from acceptance. PsyArXiv. https://doi.org/10.31234/osf.io/udqms",Luhring 2023,,,,no,1,Austria,within,yes,yes,"We decided to reduce it by removing unclear items based on student feedback, and excluding items with discriminatory power or reliability below the following thresholds. Overall, we ensured that the posterior reliability of items was above .75. For news items, we set a somewhat lower than usual minimal threshold for discriminatory power at >.25, due to the small sample size in the pilot study. Like this, we excluded 3 fake news stimuli and 4 real news stimuli. For COVID-19 belief statements, we removed 4 real items with discriminatory power <.30. The number of items for the final data collection was 24 news items and 9 statements with acceptable internal consistencies (>.75).",original,,researchers,fact_checking,mainstream,COVID,1,24,,0.5,title_picture_pitch,source,accuracy,"“To the best of your knowledge and belief, how accurate is this news?”. Answers could be given on a 0-100% sliding scale (in increments of 10%; initial cursor was set at 50%)",1,1,100,control,,,,,,,422,22.97,16.24,67.04,15.29,paper,no
43,"Fazio, L., Rand, D., Lewandowsky, S., Susmann, M., Berinsky, A. J., Guess, A., Kendeou, P., Lyons, B., Miller, J., Newman, E., Pennycook, G., & Swire-Thompson, B. (2024). Combating misinformation: A megastudy of nine interventions designed to reduce the sharing of and belief in false and misleading headlines. OSF. https://doi.org/10.31234/osf.io/uyjha",Fazio_2024,,,it's a pre-test,no,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,political,1,31,255,0.5,title_picture,source,accuracy,"To the best of your knowledge, is the above headline accurate? (6-point scale)",1,0,6,control,,,,,,,1617,2.908,0.5,3.92,0.37,authors,no
43,"Fazio, L., Rand, D., Lewandowsky, S., Susmann, M., Berinsky, A. J., Guess, A., Kendeou, P., Lyons, B., Miller, J., Newman, E., Pennycook, G., & Swire-Thompson, B. (2024). Combating misinformation: A megastudy of nine interventions designed to reduce the sharing of and belief in false and misleading headlines. OSF. https://doi.org/10.31234/osf.io/uyjha",Fazio_2024,,,it's a pre-test,no,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,medical,2,31,115,0.5,title_picture,source,accuracy,"To the best of your knowledge, is the above headline accurate? (6-point scale)",1,0,6,control,,,,,,,704,2.88,0.44,4.04,0.35,authors,no
48,"Clemm von Hohenberg, B. (2023). Truth and Bias, Left and Right: Testing Ideological Asymmetries with a Realistic News Supply. Public Opinion Quarterly, nfad013.",Hohenberg 2023,,,"automatically scrapped the true headlines from google news, and automatically scrapped the false from fact-check websites;
note that we coded scale as '7', because all other continuous scales have the low point of 1, not 0. Accordingly, we added '+1' to the mean scores.",yes,1,United States,within,yes,no,,original,,automated,fact_checking,mainstream,political,1,8,80,0.5,title_picture_pitch,source,accuracy,"To the best of your knowledge, how accurate is the information in the above item? 0 means not at all, 6 means completely",1,1,7,control,,,,,,,1393,3.55749,1.97475,4.44751,1.66467,authors,no
49,"Modirrousta-Galian, A., Higham, P. A., & Seabrooke, T. (2024). Wordless wisdom: The dominant role of tacit knowledge in true and fake news discrimination. Journal of Applied Research in Memory and Cognition.",Modirrousta-Galian 2023,,,,no,1,United States,within,yes,yes,"we randomly sampled 25 true and 25 fake news headlines with average partisanship ratings between 3 and 3.5, and an additional 25 true and 25 fake news headlines with average partisanship ratings between 3.5 and 4. We removed two true news headlines, one for being outdated and the other for being ambiguously worded, and three fake news headlines, two for the same reasons as the true news headlines, and one for eliciting near-floor veracity ratings in Chen et al. (2022)",recycled,"Chen, C. X., Pennycook, G., & Rand, D. G. (2021). What Makes News Sharable on Social Media? [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/gzqcd",researchers,fact_checking,mainstream,political,1,40,95,0.5,title_picture_pitch,no_source,accuracy,"(1 = high confidence false, 2 = medium confidence false, 3 = low confidence false, 4 = low confidence true, 5 = medium confidence true, 6 = high confidence true",1,1,6,control,,,,,,,327,2.38,1.46,3.81,1.34,authors,no
50,"Peren Arin, K., Mazrekaj, D., & Thum, M. (2023). Ability of detecting and willingness to share fake news. Scientific Reports, 13(1), 7298.",Peren 2023,,,"They used a 5pts scale from 0 to 4, BUT they sent me the summ of scores across true vs false items, so it becomes a 21pts scales (from 0 to 20).  ""we used one large scale for all ten headlines with a maximum of 40. Nonetheless, I now made separate variables for fake news and true news detection (scale out of 20, higher is better detection)"" --> For false news I just reverse coded it (so that it become fake as true) ;
note that we coded scale as '21', because all other continuous scales have the low point of 1, not 0. Accordingly, we added '+1' to the mean scores that the authors shared with us.",yes,1,Germany,within,yes,yes,We pretested the headlines among Ph.D. students to ensure sufficient variation in response.,original,,researchers,fact_checking,mainstream,political,1,10,,0.5,title,no_source,accuracy,"“To the best of your knowledge, how likely is it that the claim in each of the headlines is correct?” with five answer possibilities: (a) extremely unlikely, (b) somewhat unlikely, (c) neither likely nor unlikely, (d) somewhat likely, and (e) extremely likely",1,1,21,control,,,,,,,1223,6.559,3.393,10.222,3.189,authors,no
50,"Peren Arin, K., Mazrekaj, D., & Thum, M. (2023). Ability of detecting and willingness to share fake news. Scientific Reports, 13(1), 7298.",Peren 2023,,,"“To the best of your knowledge, how likely is it that the claim in each of the headlines is correct?” with five answer possibilities: (a) extremely unlikely, (b) somewhat unlikely, (c) neither likely nor unlikely, (d) somewhat likely, and (e) extremely likely",yes,2,UK,within,yes,yes,We pretested the headlines among Ph.D. students to ensure sufficient variation in response.,original,,researchers,fact_checking,mainstream,political,1,10,,0.5,title,no_source,accuracy,"“To the best of your knowledge, how likely is it that the claim in each of the headlines is correct?” with five answer possibilities: (a) extremely unlikely, (b) somewhat unlikely, (c) neither likely nor unlikely, (d) somewhat likely, and (e) extremely likely",1,1,21,control,,,,,,,1156,7.831,3.684,10.666,3.246,authors,no
51,Emma Hoes et al. (2023) Prominent Misinformation Interventions Reduce Misperceptions but Increase Skepticism,Hoes 2023,,,,no,1,United States,within,yes,yes,"a pre-tested pool of claims that were rated as similarly easy to read, interesting, easy to understand, likely to be true(false), (un)believable, and equally plausible among Democrats and Republicans.",original,,researchers,researchers_generated,mainstream,political,1,5,,0.6,title_picture_pitch,source,accuracy,"1 (not at all accurate)to 4(very accurate) scale.""",1,0,4,control,,,,,,,269,2.45,0.85,2.99,0.78,authors,no
51,Emma Hoes et al. (2023) Prominent Misinformation Interventions Reduce Misperceptions but Increase Skepticism,Hoes 2023,,,,no,1,Poland,within,yes,yes,"a pre-tested pool of claims that were rated as similarly easy to read, interesting, easy to understand, likely to be true(false), (un)believable, and equally plausible among Democrats and Republicans.",original,,researchers,researchers_generated,mainstream,political,1,5,,0.6,title_picture_pitch,source,accuracy,"1 (not at all accurate)to 4(very accurate) scale.""",1,0,4,control,,,,,,,303,2.065,0.84,2.87,0.77,authors,no
51,Emma Hoes et al. (2023) Prominent Misinformation Interventions Reduce Misperceptions but Increase Skepticism,Hoes 2023,,,,no,1,Hong Kong,within,yes,yes,"a pre-tested pool of claims that were rated as similarly easy to read, interesting, easy to understand, likely to be true(false), (un)believable, and equally plausible among Democrats and Republicans.",original,,researchers,researchers_generated,mainstream,political,1,5,,0.6,title_picture_pitch,source,accuracy,"1 (not at all accurate)to 4(very accurate) scale.""",1,0,4,control,,,,,,,240,2.395,0.775,2.74,0.74,authors,no
52,"Altay, S., De Angelis, A., & Hoes, E. (2024). Media literacy tips promoting reliable news improve discernment and enhance trust in traditional media. Communications Psychology, 2(1), 1–9. https://doi.org/10.1038/s44271-024-00121-5",Hoes.Altay_2023,yes,,"In this study, they manipulated the ratio of true news among all news items that participants saw (within each of the other experimental conditions). Therefore, for each (other) experimental condition, there are three lines with differing news ratios. ",no,1,United States,within,yes,no,,recycled,Mega_Study,researchers,fact_checking,mainstream,political,1,12,40,0.25,title_picture_pitch,source,accuracy,"Certainly false  (1), Probably false  (2), Possibly false  (3), Possibly true  (4), Probably true  (5), Certainly true  (6) ",1,1,6,control,,,,,,,319,1.64,1.2,3.17,1.72,raw data,no
52,"Altay, S., De Angelis, A., & Hoes, E. (2024). Media literacy tips promoting reliable news improve discernment and enhance trust in traditional media. Communications Psychology, 2(1), 1–9. https://doi.org/10.1038/s44271-024-00121-5",Hoes.Altay_2023,yes,,"In this study, they manipulated the ratio of true news among all news items that participants saw (within each of the other experimental conditions). Therefore, for each (other) experimental condition, there are three lines with differing news ratios. ",no,2,United States,within,yes,no,,recycled,Mega_Study,researchers,fact_checking,mainstream,political,1,12,40,0.5,title_picture_pitch,source,accuracy,"Certainly false  (1), Probably false  (2), Possibly false  (3), Possibly true  (4), Probably true  (5), Certainly true  (6) ",1,1,6,control,,,,,,,344,1.65,1.12,3.05,1.63,raw data,no
52,"Altay, S., De Angelis, A., & Hoes, E. (2024). Media literacy tips promoting reliable news improve discernment and enhance trust in traditional media. Communications Psychology, 2(1), 1–9. https://doi.org/10.1038/s44271-024-00121-5",Hoes.Altay_2023,yes,,"In this study, they manipulated the ratio of true news among all news items that participants saw (within each of the other experimental conditions). Therefore, for each (other) experimental condition, there are three lines with differing news ratios. ",no,3,United States,within,yes,no,,recycled,Mega_Study,researchers,fact_checking,mainstream,political,1,12,40,0.75,title_picture_pitch,source,accuracy,"Certainly false  (1), Probably false  (2), Possibly false  (3), Possibly true  (4), Probably true  (5), Certainly true  (6) ",1,1,6,control,,,,,,,321,1.64,1.13,3.04,1.69,raw data,no
52,"Altay, S., De Angelis, A., & Hoes, E. (2024). Media literacy tips promoting reliable news improve discernment and enhance trust in traditional media. Communications Psychology, 2(1), 1–9. https://doi.org/10.1038/s44271-024-00121-5",Hoes.Altay_2023,yes,,"In this study, they manipulated the ratio of true news among all news items that participants saw (within each of the other experimental conditions). Therefore, for each (other) experimental condition, there are three lines with differing news ratios. ",no,4,United States,within,yes,no,,recycled,Mega_Study,researchers,fact_checking,mainstream,political,1,12,40,0.25,title_picture_pitch,source,accuracy,"Certainly false  (1), Probably false  (2), Possibly false  (3), Possibly true  (4), Probably true  (5), Certainly true  (6) ",1,1,6,treatment,positive,mixed,literacy,,,,348,1.59,1.08,3.27,1.66,raw data,no
52,"Altay, S., De Angelis, A., & Hoes, E. (2024). Media literacy tips promoting reliable news improve discernment and enhance trust in traditional media. Communications Psychology, 2(1), 1–9. https://doi.org/10.1038/s44271-024-00121-5",Hoes.Altay_2023,yes,,"In this study, they manipulated the ratio of true news among all news items that participants saw (within each of the other experimental conditions). Therefore, for each (other) experimental condition, there are three lines with differing news ratios. ",no,5,United States,within,yes,no,,recycled,Mega_Study,researchers,fact_checking,mainstream,political,1,12,40,0.5,title_picture_pitch,source,accuracy,"Certainly false  (1), Probably false  (2), Possibly false  (3), Possibly true  (4), Probably true  (5), Certainly true  (6) ",1,1,6,treatment,positive,mixed,literacy,,,,295,1.61,1.1,3.22,1.67,raw data,no
52,"Altay, S., De Angelis, A., & Hoes, E. (2024). Media literacy tips promoting reliable news improve discernment and enhance trust in traditional media. Communications Psychology, 2(1), 1–9. https://doi.org/10.1038/s44271-024-00121-5",Hoes.Altay_2023,yes,,"In this study, they manipulated the ratio of true news among all news items that participants saw (within each of the other experimental conditions). Therefore, for each (other) experimental condition, there are three lines with differing news ratios. ",no,6,United States,within,yes,no,,recycled,Mega_Study,researchers,fact_checking,mainstream,political,1,12,40,0.75,title_picture_pitch,source,accuracy,"Certainly false  (1), Probably false  (2), Possibly false  (3), Possibly true  (4), Probably true  (5), Certainly true  (6) ",1,1,6,treatment,positive,mixed,literacy,,,,326,1.49,0.951,3.22,1.64,raw data,no
52,"Altay, S., De Angelis, A., & Hoes, E. (2024). Media literacy tips promoting reliable news improve discernment and enhance trust in traditional media. Communications Psychology, 2(1), 1–9. https://doi.org/10.1038/s44271-024-00121-5",Hoes.Altay_2023,yes,,"In this study, they manipulated the ratio of true news among all news items that participants saw (within each of the other experimental conditions). Therefore, for each (other) experimental condition, there are three lines with differing news ratios. ",no,7,United States,within,yes,no,,recycled,Mega_Study,researchers,fact_checking,mainstream,political,1,12,40,0.25,title_picture_pitch,source,accuracy,"Certainly false  (1), Probably false  (2), Possibly false  (3), Possibly true  (4), Probably true  (5), Certainly true  (6) ",1,1,6,treatment,positive,skepticism,literacy,,,,325,1.58,1.06,3.19,1.64,raw data,no
52,"Altay, S., De Angelis, A., & Hoes, E. (2024). Media literacy tips promoting reliable news improve discernment and enhance trust in traditional media. Communications Psychology, 2(1), 1–9. https://doi.org/10.1038/s44271-024-00121-5",Hoes.Altay_2023,yes,,"In this study, they manipulated the ratio of true news among all news items that participants saw (within each of the other experimental conditions). Therefore, for each (other) experimental condition, there are three lines with differing news ratios. ",no,8,United States,within,yes,no,,recycled,Mega_Study,researchers,fact_checking,mainstream,political,1,12,40,0.5,title_picture_pitch,source,accuracy,"Certainly false  (1), Probably false  (2), Possibly false  (3), Possibly true  (4), Probably true  (5), Certainly true  (6) ",1,1,6,treatment,positive,skepticism,literacy,,,,358,1.54,1.07,3.24,1.65,raw data,no
52,"Altay, S., De Angelis, A., & Hoes, E. (2024). Media literacy tips promoting reliable news improve discernment and enhance trust in traditional media. Communications Psychology, 2(1), 1–9. https://doi.org/10.1038/s44271-024-00121-5",Hoes.Altay_2023,yes,,"In this study, they manipulated the ratio of true news among all news items that participants saw (within each of the other experimental conditions). Therefore, for each (other) experimental condition, there are three lines with differing news ratios. ",no,9,United States,within,yes,no,,recycled,Mega_Study,researchers,fact_checking,mainstream,political,1,12,40,0.75,title_picture_pitch,source,accuracy,"Certainly false  (1), Probably false  (2), Possibly false  (3), Possibly true  (4), Probably true  (5), Certainly true  (6) ",1,1,6,treatment,positive,skepticism,literacy,,,,302,1.52,1.03,3.09,1.67,raw data,no
52,"Altay, S., De Angelis, A., & Hoes, E. (2024). Media literacy tips promoting reliable news improve discernment and enhance trust in traditional media. Communications Psychology, 2(1), 1–9. https://doi.org/10.1038/s44271-024-00121-5",Hoes.Altay_2023,yes,,"In this study, they manipulated the ratio of true news among all news items that participants saw (within each of the other experimental conditions). Therefore, for each (other) experimental condition, there are three lines with differing news ratios. ",no,10,United States,within,yes,no,,recycled,Mega_Study,researchers,fact_checking,mainstream,political,1,12,40,0.25,title_picture_pitch,source,accuracy,"Certainly false  (1), Probably false  (2), Possibly false  (3), Possibly true  (4), Probably true  (5), Certainly true  (6) ",1,1,6,treatment,positive,trust,literacy,,,,313,1.61,1.09,3.34,1.64,raw data,no
52,"Altay, S., De Angelis, A., & Hoes, E. (2024). Media literacy tips promoting reliable news improve discernment and enhance trust in traditional media. Communications Psychology, 2(1), 1–9. https://doi.org/10.1038/s44271-024-00121-5",Hoes.Altay_2023,yes,,"In this study, they manipulated the ratio of true news among all news items that participants saw (within each of the other experimental conditions). Therefore, for each (other) experimental condition, there are three lines with differing news ratios. ",no,11,United States,within,yes,no,,recycled,Mega_Study,researchers,fact_checking,mainstream,political,1,12,40,0.5,title_picture_pitch,source,accuracy,"Certainly false  (1), Probably false  (2), Possibly false  (3), Possibly true  (4), Probably true  (5), Certainly true  (6) ",1,1,6,treatment,positive,trust,literacy,,,,310,1.6,1.09,3.34,1.63,raw data,no
52,"Altay, S., De Angelis, A., & Hoes, E. (2024). Media literacy tips promoting reliable news improve discernment and enhance trust in traditional media. Communications Psychology, 2(1), 1–9. https://doi.org/10.1038/s44271-024-00121-5",Hoes.Altay_2023,yes,,"In this study, they manipulated the ratio of true news among all news items that participants saw (within each of the other experimental conditions). Therefore, for each (other) experimental condition, there are three lines with differing news ratios. ",no,12,United States,within,yes,no,,recycled,Mega_Study,researchers,fact_checking,mainstream,political,1,12,40,0.75,title_picture_pitch,source,accuracy,"Certainly false  (1), Probably false  (2), Possibly false  (3), Possibly true  (4), Probably true  (5), Certainly true  (6) ",1,1,6,treatment,positive,trust,literacy,,,,353,1.59,1.07,3.08,1.64,raw data,no
53,"Altay, S., & Gilardi, F. (2023). People Are Skeptical of Headlines Labeled as AI-Generated, Even if True or Human-Made, Because They Assume Full AI Automation. OSF. https://doi.org/10.31234/osf.io/83k9r",Altay.Gilardi_2023,yes,study 1,Note that we excluded some of the treatment conditions since they were not relevant here,no,1,United States,within,yes,no,,original,,researchers and AI,fact_checking and chatGPT,mainstream,general,1,16,32,0.5,title_picture_pitch,no_source,accuracy,"Certainly false  (1), Probably false  (2), Possibly false  (3), Possibly true  (4), Probably true  (5), Certainly true  (6) ",1,1,6,control,,,,,,,198,2.92,1.42,4.24,1.03,raw data,no
53,"Altay, S., & Gilardi, F. (2023). People Are Skeptical of Headlines Labeled as AI-Generated, Even if True or Human-Made, Because They Assume Full AI Automation. OSF. https://doi.org/10.31234/osf.io/83k9r",Altay.Gilardi_2023,yes,study 1,Note that we excluded some of the treatment conditions since they were not relevant here,no,2,United States,within,yes,no,,original,,researchers and chatGPT,fact_checking and chatGPT,mainstream,general,1,16,32,0.5,title_picture_pitch,no_source,accuracy,"Certainly false  (1), Probably false  (2), Possibly false  (3), Possibly true  (4), Probably true  (5), Certainly true  (6) ",1,1,6,treatment,positive,FalseLabel,Label,,,,198,2.35,1.39,4.36,1.04,raw data,no
54,"Espina Mairal, S., Bustos, F., Solovey, G., & Navajas, J. (2023). Interactive crowdsourcing to fact-check politicians. Journal of Experimental Psychology: Applied. https://doi.org/10.1037/xap0000492",Mairal_2023,,,"Data for Study 1; Our outcome is `answer_1`, i.e. the news rating before any manipulation happens. Since participant's initial rating happened under the same (unmanipulated) circumstances for all their experimental conditions, we consider them all as control here, and pool across them. ",yes,1,Argentina,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_concordant,1,10,,0.5,title,source,accuracy,"""For example, the information displayed would read: Alberto Fernández, the president of Argentina, said: “we have started the largest vaccination campaign in Argentinian history”. He said this in March, 2021. ¿Is what he said true or false?""",1,1,binary,control,,,,,,,180,0.593,0.491,0.771,0.42,raw data,no
54,"Espina Mairal, S., Bustos, F., Solovey, G., & Navajas, J. (2023). Interactive crowdsourcing to fact-check politicians. Journal of Experimental Psychology: Applied. https://doi.org/10.1037/xap0000492",Mairal_2023,,,"Data for Study 1;  Our outcome is `answer_1`, i.e. the news rating before any manipulation happens. Since participant's initial rating happened under the same (unmanipulated) circumstances for all their experimental conditions, we consider them all as control here, and pool across them. ",yes,1,Argentina,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_discordant,2,10,,0.5,title,source,accuracy,"""For example, the information displayed would read: Alberto Fernández, the president of Argentina, said: “we have started the largest vaccination campaign in Argentinian history”. He said this in March, 2021. ¿Is what he said true or false?""",1,1,binary,control,,,,,,,180,0.28,0.449,0.486,0.5,raw data,no
54,"Espina Mairal, S., Bustos, F., Solovey, G., & Navajas, J. (2023). Interactive crowdsourcing to fact-check politicians. Journal of Experimental Psychology: Applied. https://doi.org/10.1037/xap0000492",Mairal_2023,,,"Data for Study 2; Our outcome is `answer_1`, i.e. the news rating before any manipulation happens. Since participant's initial rating happened under the same (unmanipulated) circumstances for all their experimental conditions, we consider them all as control here, and pool across them. ",yes,2,Argentina,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_concordant,1,10,,0.5,title,source,accuracy,"""For example, the information displayed would read: Alberto Fernández, the president of Argentina, said: “we have started the largest vaccination campaign in Argentinian history”. He said this in March, 2021. ¿Is what he said true or false?""",1,1,binary,control,,,,,,,240,0.597,0.491,0.79,0.407,raw data,no
54,"Espina Mairal, S., Bustos, F., Solovey, G., & Navajas, J. (2023). Interactive crowdsourcing to fact-check politicians. Journal of Experimental Psychology: Applied. https://doi.org/10.1037/xap0000492",Mairal_2023,,,"Data for Study 2; Our outcome is `answer_1`, i.e. the news rating before any manipulation happens. Since participant's initial rating happened under the same (unmanipulated) circumstances for all their experimental conditions, we consider them all as control here, and pool across them. ",yes,2,Argentina,within,yes,no,,original,,researchers,fact_checking,fact_checking,politically_discordant,2,10,,0.5,title,source,accuracy,"""For example, the information displayed would read: Alberto Fernández, the president of Argentina, said: “we have started the largest vaccination campaign in Argentinian history”. He said this in March, 2021. ¿Is what he said true or false?""",1,1,binary,control,,,,,,,240,0.21,0.407,0.503,0.5,raw data,no
55,"Gawronski, B., Ng, N. L., & Luke, D. M. (2023). Truth sensitivity and partisan bias in responses to misinformation. Journal of Experimental Psychology: General, 152(8), 2205–2236. https://doi.org/10.1037/xge0001381",Gawronski_2023,,,"Data for Experiment 1; note that we leave out 7 participants who did not provide information on their political identity; 
We leave out Experiment 2, because no clear control: ""half of the participants was asked to report their initial reaction to each headline and given 7 seconds to do so (low-reflection condition); the remaining half was asked to read the headline carefully and take a moment to think about their answer without time limits (high-reflection condition)."";
We also leave out Experiment 3, also no clear control: ""The procedures, materials, and measures were identical to Experiment 2 with three exceptions. First, we replaced the manipulation of cognitive reflection with a manipulation of self-affirmation versus selfthreat""",yes,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_concordant,1,30,,0.5,title,no_source,accuracy,"""In the veracity-judgment condition, headlines were presented one at a time together with the question To the best of your knowledge, is the claim in this headline true or false? and the response options true and false.""",1,1,binary,control,,,,,,,186,0.52,0.5,0.716,0.451,raw data,no
55,"Gawronski, B., Ng, N. L., & Luke, D. M. (2023). Truth sensitivity and partisan bias in responses to misinformation. Journal of Experimental Psychology: General, 152(8), 2205–2236. https://doi.org/10.1037/xge0001381",Gawronski_2023,,,"Data for Experiment 1; note that we leave out 7 participants who did not provide information on their political identity; 
We leave out Experiment 2, because no clear control: ""half of the participants was asked to report their initial reaction to each headline and given 7 seconds to do so (low-reflection condition); the remaining half was asked to read the headline carefully and take a moment to think about their answer without time limits (high-reflection condition).""",yes,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_discordant,2,30,,0.5,title,no_source,accuracy,"""In the veracity-judgment condition, headlines were presented one at a time together with the question To the best of your knowledge, is the claim in this headline true or false? and the response options true and false.""",1,1,binary,control,,,,,,,186,0.236,0.425,0.431,0.495,raw data,no
55,"Gawronski, B., Ng, N. L., & Luke, D. M. (2023). Truth sensitivity and partisan bias in responses to misinformation. Journal of Experimental Psychology: General, 152(8), 2205–2236. https://doi.org/10.1037/xge0001381",Gawronski_2023,,,"Data for Experiment 4; note that we considered only participants assigne to the truth prime condition; we also leave out 2 participants who did not provide information on their political identity; 
We leave out Experiment 2, because no clear control: ""half of the participants was asked to report their initial reaction to each headline and given 7 seconds to do so (low-reflection condition); the remaining half was asked to read the headline carefully and take a moment to think about their answer without time limits (high-reflection condition)."";
We also leave out Experiment 3, also no clear control: ""The procedures, materials, and measures were identical to Experiment 2 with three exceptions. First, we replaced the manipulation of cognitive reflection with a manipulation of self-affirmation versus selfthreat""",yes,2,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_concordant,1,30,,0.5,title,no_source,accuracy,"""In the veracity-judgment condition, headlines were presented one at a time together with the question To the best of your knowledge, is the claim in this headline true or false? and the response options true and false.""",1,1,binary,control,,,,,,,295,0.481,0.5,0.666,0.472,raw data,no
55,"Gawronski, B., Ng, N. L., & Luke, D. M. (2023). Truth sensitivity and partisan bias in responses to misinformation. Journal of Experimental Psychology: General, 152(8), 2205–2236. https://doi.org/10.1037/xge0001381",Gawronski_2023,,,"Data for Experiment 4; note that we considered only participants assigne to the truth prime condition; we also leave out 2 participants who did not provide information on their political identity; 
We leave out Experiment 2, because no clear control: ""half of the participants was asked to report their initial reaction to each headline and given 7 seconds to do so (low-reflection condition); the remaining half was asked to read the headline carefully and take a moment to think about their answer without time limits (high-reflection condition)."";
We also leave out Experiment 3, also no clear control: ""The procedures, materials, and measures were identical to Experiment 2 with three exceptions. First, we replaced the manipulation of cognitive reflection with a manipulation of self-affirmation versus selfthreat""",yes,2,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_discordant,2,30,,0.5,title,no_source,accuracy,"""In the veracity-judgment condition, headlines were presented one at a time together with the question To the best of your knowledge, is the claim in this headline true or false? and the response options true and false.""",1,1,binary,control,,,,,,,295,0.246,0.431,0.403,0.491,raw data,no
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 1; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_concordant,1,7,,0.4,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,732,2.58,0.806,2.97,0.763,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 1; note that we coded `politically_neutral` for news headlines that were neutral; note furthe that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_discordant,2,7,,0.4,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,732,2.24,0.829,2.6,0.856,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 1; note that we coded `politically_neutral` for news headlines that were neutral; note furthe that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_neutral,3,5,,0.8,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,732,2.38,0.835,2.82,0.826,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 2; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_concordant,4,4,,0.5555555556,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,553,2.79,0.772,2.9,0.831,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 2; note that we coded `politically_neutral` for news headlines that were neutral; note furthe that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_discordant,5,4,,0.5555555556,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,553,2.17,0.855,2.75,0.868,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 2; note that we coded `politically_neutral` for news headlines that were neutral; note furthe that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_neutral,6,11,,0.4545454545,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,553,2.23,0.868,2.89,0.795,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 3; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_concordant,5,6,,0.5384615385,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,496,2.64,0.79,3.15,0.73,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 3; note that we coded `politically_neutral` for news headlines that were neutral; note furthe that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_discordant,6,6,,0.5384615385,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,496,2.31,0.818,2.92,0.79,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 3; note that we coded `politically_neutral` for news headlines that were neutral; note furthe that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_neutral,7,7,,0.4285714286,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,496,2.3,0.839,3.2,0.75,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 4; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_concordant,8,7,,0.4666666667,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,503,2.69,0.827,3.21,0.739,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 4; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_discordant,9,7,,0.4666666667,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,503,2.09,0.841,2.96,0.865,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 4; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_neutral,10,5,,0.4285714286,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,503,2.45,0.953,3.37,0.763,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 5; since there are only fake news as neutral news in this wave, we didn't code neutral; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_concordant,11,8,,0.5882352941,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,527,2.51,0.831,3.17,0.763,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 5; since there are only fake news as neutral news in this wave, we didn't code neutral; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_discordant,12,8,,0.5882352941,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,527,2.07,0.772,2.86,0.84,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 6; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_concordant,13,6,,0.6153846154,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,498,2.64,0.789,3.19,0.72,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 6; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_discordant,14,6,,0.6153846154,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,498,2.22,0.786,3.13,0.775,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 6; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_neutral,15,7,,0.2857142857,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,498,2.42,0.842,3.15,0.711,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 7; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_concordant,16,7,,0.5714285714,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,243.5,2.74,0.758,3.21,0.742,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 7; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_discordant,17,7,,0.5714285714,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,243.5,2.24,0.787,2.91,0.822,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 7; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_neutral,18,6,,0.3333333333,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,487,2.49,0.791,3.1,0.716,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 8; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_concordant,19,8,,0.4375,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,495,2.64,0.725,3.09,0.758,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 8; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_discordant,20,8,,0.4375,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,495,2.46,0.709,2.92,0.805,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 8; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_neutral,21,4,,0.75,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,495,2.6,0.718,2.91,0.69,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 9; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_concordant,22,8,,0.5,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,498,2.43,0.861,3.14,0.716,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 9; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_discordant,23,8,,0.5,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,498,2.14,0.807,2.7,0.751,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 9; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_neutral,24,4,,0.5,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,498,2.61,0.86,2.8,0.784,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 10; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_concordant,25,8,,0.5,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,383,2.57,0.791,3.05,0.745,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 10; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_discordant,26,8,,0.5,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,383,2.09,0.831,2.9,0.78,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 10; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_neutral,27,4,,0.5,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,492,2.41,0.822,2.68,0.735,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 11; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_concordant,28,6,,0.6153846154,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,255.5,2.67,0.84,3.27,0.81,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 11; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_discordant,29,6,,0.6153846154,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,255.5,1.95,0.86,2.95,0.818,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 11; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_neutral,30,7,,0.2857142857,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,511,2.67,0.767,3.33,0.677,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 12; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_concordant,31,8,,0.5,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,489,2.64,0.764,3.25,0.697,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 12; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_discordant,32,8,,0.5,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,489,2.08,0.804,2.85,0.817,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 12; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,1,United States,within,yes,no,,original,,automated,automated,automated,politically_neutral,33,4,,0.5,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,489,2.69,0.789,2.91,0.605,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 1, for the sample of participants that identified neither as democrats nor republicans; to not count the news headlines as distinct to the ones for the political sample, we coded ""recycled"" in the `recycled_news`column; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,2,United States,within,yes,no,,recycled,,automated,automated,automated,political,1,20,,0.5,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,472,2.4,0.796,2.74,0.827,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 2, for the sample of participants that identified neither as democrats nor republicans; to not count the news headlines as distinct to the ones for the political sample, we coded ""recycled"" in the `recycled_news`column; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,2,United States,within,yes,no,,recycled,,automated,automated,automated,political,2,20,,0.5,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,355,2.31,0.815,2.82,0.804,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 3, for the sample of participants that identified neither as democrats nor republicans; to not count the news headlines as distinct to the ones for the political sample, we coded ""recycled"" in the `recycled_news`column; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,2,United States,within,yes,no,,recycled,,automated,automated,automated,political,3,20,,0.5,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,305,2.41,0.787,3.02,0.768,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 4, for the sample of participants that identified neither as democrats nor republicans; to not count the news headlines as distinct to the ones for the political sample, we coded ""recycled"" in the `recycled_news`column; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,2,United States,within,yes,no,,recycled,,automated,automated,automated,political,4,20,,0.5,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,333,2.44,0.835,3.1,0.798,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 5, for the sample of participants that identified neither as democrats nor republicans; to not count the news headlines as distinct to the ones for the political sample, we coded ""recycled"" in the `recycled_news`column; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,2,United States,within,yes,no,,recycled,,automated,automated,automated,political,5,20,,0.5,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,337,2.35,0.817,2.94,0.795,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 6, for the sample of participants that identified neither as democrats nor republicans; to not count the news headlines as distinct to the ones for the political sample, we coded ""recycled"" in the `recycled_news`column; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,2,United States,within,yes,no,,recycled,,automated,automated,automated,political,6,20,,0.5,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,334,2.45,0.789,3.13,0.714,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 7, for the sample of participants that identified neither as democrats nor republicans; to not count the news headlines as distinct to the ones for the political sample, we coded ""recycled"" in the `recycled_news`column; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,2,United States,within,yes,no,,recycled,,automated,automated,automated,political,7,20,,0.5,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,335,2.51,0.765,3.03,0.768,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 8, for the sample of participants that identified neither as democrats nor republicans; to not count the news headlines as distinct to the ones for the political sample, we coded ""recycled"" in the `recycled_news`column; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,2,United States,within,yes,no,,recycled,,automated,automated,automated,political,8,20,,0.5,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,323,2.54,0.689,2.93,0.739,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 9, for the sample of participants that identified neither as democrats nor republicans; to not count the news headlines as distinct to the ones for the political sample, we coded ""recycled"" in the `recycled_news`column; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,2,United States,within,yes,no,,recycled,,automated,automated,automated,political,9,20,,0.5,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,322,2.36,0.835,2.85,0.766,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 10, for the sample of participants that identified neither as democrats nor republicans; to not count the news headlines as distinct to the ones for the political sample, we coded ""recycled"" in the `recycled_news`column; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,2,United States,within,yes,no,,recycled,,automated,automated,automated,political,10,20,,0.5,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,321,2.38,0.813,2.88,0.759,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 11, for the sample of participants that identified neither as democrats nor republicans; to not count the news headlines as distinct to the ones for the political sample, we coded ""recycled"" in the `recycled_news`column; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,2,United States,within,yes,no,,recycled,,automated,automated,automated,political,11,20,,0.5,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,328,2.45,0.84,3.09,0.811,raw data,yes
56,"Garrett, R. K., & Bond, R. M. (2021). Conservatives’ susceptibility to political misperceptions. Science Advances, 7(23), eabf1234. https://doi.org/10.1126/sciadv.abf1234",Garrett_2021,,,"Data correspond to wave 12 for the sample of participants that identified neither as democrats nor republicans; to not count the news headlines as distinct to the ones for the political sample, we coded ""recycled"" in the `recycled_news`column; note that we coded `politically_neutral` for news headlines that were neutral; note further that we split the sample into participants identifying as democrat or republican, and those who don't. For the former, we distinguish between concordant, discordant and neutral. For the latter, we simply code 'political' as news family. We divide the number of headlines by two between concordant and discordant
To establish veracity of news, they did this: ""We established story veracity using several indicators, including source domain, other news coverage, published assessments by fact checkers, and assessments by scholars with relevant expertise""",yes,2,United States,within,yes,no,,recycled,,automated,automated,automated,political,12,20,,0.5,title,no_source,accuracy,"""we asked survey respondents to indicate the veracity of the 20 belief statements on a four-point scale, anchored by “definitely true” and “definitely false.”"" (1. Definitely True 2. Probably True 3. Probable False 4. Definitely False)",1,1,4,control,,,,,,,321,2.4,0.805,2.98,0.75,raw data,yes
57,"Hameleers, M., Tulin, M., De Vreese, C., Aalberg, T., Van Aelst, P., Cardenal, A. S., Corbu, N., Van Erkel, P., Esser, F., Gehle, L., Halagiera, D., Hopmann, D., Koc‐Michalska, K., Matthes, J., Meltzer, C., Mihelj, S., Schemer, C., Sheafer, T., Splendore, S., … Zoizner, A. (2023). Mistakenly misinformed or intentionally deceived? Mis‐ and Disinformation perceptions on the Russian War in Ukraine among citizens in 19 countries. European Journal of Political Research, 1475-6765.12646. https://doi.org/10.1111/1475-6765.12646",Hameleers_2023,,,"Data from the authors: ""These were claims that were actually circulated, and we selected the items ourselves. The reason we chose these statements is that they were fact-checked by professional fact-checkers, so we could be certain of their veracity. The other criterion that guided our selection was that we wanted to achieve a reasonable balance of pro-Russian vs. pro-Ukrainian as well as true and false statements.""; 
""These are pre-intervention ratings."";
""Did each participant see all 6 true and all 3 false news items? Yes"" ",yes,1,Austria,within,yes,no,,original,,researchers,fact_checking,fact_checking,political,1,9,,0.6666666667,title,no_source,truthfulness,"""Could you rate the truthfulness of the sestatements? Please give us your best guess .A guess is just as good as the “right” answer."" 
(1)Very certain it’s false (2) Somewhat certain it’s false (3)Uncertain whether it’s true or false (4) Somewhat certain it’s true (5) Very certain it’s true",1,1,5,control,,,,,,,1000,2.39,0.81,3.15,0.44,authors,no
57,"Hameleers, M., Tulin, M., De Vreese, C., Aalberg, T., Van Aelst, P., Cardenal, A. S., Corbu, N., Van Erkel, P., Esser, F., Gehle, L., Halagiera, D., Hopmann, D., Koc‐Michalska, K., Matthes, J., Meltzer, C., Mihelj, S., Schemer, C., Sheafer, T., Splendore, S., … Zoizner, A. (2023). Mistakenly misinformed or intentionally deceived? Mis‐ and Disinformation perceptions on the Russian War in Ukraine among citizens in 19 countries. European Journal of Political Research, 1475-6765.12646. https://doi.org/10.1111/1475-6765.12646",Hameleers_2023,,,"Data from the authors: ""These were claims that were actually circulated, and we selected the items ourselves. The reason we chose these statements is that they were fact-checked by professional fact-checkers, so we could be certain of their veracity. The other criterion that guided our selection was that we wanted to achieve a reasonable balance of pro-Russian vs. pro-Ukrainian as well as true and false statements.""; 
""These are pre-intervention ratings."";
""Did each participant see all 6 true and all 3 false news items? Yes"" ",yes,2,Belgium,within,yes,no,,original,,researchers,fact_checking,fact_checking,political,1,9,,0.6666666667,title,no_source,truthfulness,"""Could you rate the truthfulness of the sestatements? Please give us your best guess .A guess is just as good as the “right” answer."" 
(1)Very certain it’s false (2) Somewhat certain it’s false (3)Uncertain whether it’s true or false (4) Somewhat certain it’s true (5) Very certain it’s true",1,1,5,control,,,,,,,1000,2.47,0.78,3.19,0.5,authors,no
57,"Hameleers, M., Tulin, M., De Vreese, C., Aalberg, T., Van Aelst, P., Cardenal, A. S., Corbu, N., Van Erkel, P., Esser, F., Gehle, L., Halagiera, D., Hopmann, D., Koc‐Michalska, K., Matthes, J., Meltzer, C., Mihelj, S., Schemer, C., Sheafer, T., Splendore, S., … Zoizner, A. (2023). Mistakenly misinformed or intentionally deceived? Mis‐ and Disinformation perceptions on the Russian War in Ukraine among citizens in 19 countries. European Journal of Political Research, 1475-6765.12646. https://doi.org/10.1111/1475-6765.12646",Hameleers_2023,,,"Data from the authors: ""These were claims that were actually circulated, and we selected the items ourselves. The reason we chose these statements is that they were fact-checked by professional fact-checkers, so we could be certain of their veracity. The other criterion that guided our selection was that we wanted to achieve a reasonable balance of pro-Russian vs. pro-Ukrainian as well as true and false statements.""; 
""These are pre-intervention ratings."";
""Did each participant see all 6 true and all 3 false news items? Yes"" ",yes,3,Brazil,within,yes,no,,original,,researchers,fact_checking,fact_checking,political,1,9,,0.6666666667,title,no_source,truthfulness,"""Could you rate the truthfulness of the sestatements? Please give us your best guess .A guess is just as good as the “right” answer."" 
(1)Very certain it’s false (2) Somewhat certain it’s false (3)Uncertain whether it’s true or false (4) Somewhat certain it’s true (5) Very certain it’s true",1,1,5,control,,,,,,,1001,2.7,0.78,3.24,0.52,authors,no
57,"Hameleers, M., Tulin, M., De Vreese, C., Aalberg, T., Van Aelst, P., Cardenal, A. S., Corbu, N., Van Erkel, P., Esser, F., Gehle, L., Halagiera, D., Hopmann, D., Koc‐Michalska, K., Matthes, J., Meltzer, C., Mihelj, S., Schemer, C., Sheafer, T., Splendore, S., … Zoizner, A. (2023). Mistakenly misinformed or intentionally deceived? Mis‐ and Disinformation perceptions on the Russian War in Ukraine among citizens in 19 countries. European Journal of Political Research, 1475-6765.12646. https://doi.org/10.1111/1475-6765.12646",Hameleers_2023,,,"Data from the authors: ""These were claims that were actually circulated, and we selected the items ourselves. The reason we chose these statements is that they were fact-checked by professional fact-checkers, so we could be certain of their veracity. The other criterion that guided our selection was that we wanted to achieve a reasonable balance of pro-Russian vs. pro-Ukrainian as well as true and false statements.""; 
""These are pre-intervention ratings."";
""Did each participant see all 6 true and all 3 false news items? Yes"" ",yes,4,Switzerland,within,yes,no,,original,,researchers,fact_checking,fact_checking,political,1,9,,0.6666666667,title,no_source,truthfulness,"""Could you rate the truthfulness of the sestatements? Please give us your best guess .A guess is just as good as the “right” answer."" 
(1)Very certain it’s false (2) Somewhat certain it’s false (3)Uncertain whether it’s true or false (4) Somewhat certain it’s true (5) Very certain it’s true",1,1,5,control,,,,,,,1003,2.42,0.84,3.22,0.46,authors,no
57,"Hameleers, M., Tulin, M., De Vreese, C., Aalberg, T., Van Aelst, P., Cardenal, A. S., Corbu, N., Van Erkel, P., Esser, F., Gehle, L., Halagiera, D., Hopmann, D., Koc‐Michalska, K., Matthes, J., Meltzer, C., Mihelj, S., Schemer, C., Sheafer, T., Splendore, S., … Zoizner, A. (2023). Mistakenly misinformed or intentionally deceived? Mis‐ and Disinformation perceptions on the Russian War in Ukraine among citizens in 19 countries. European Journal of Political Research, 1475-6765.12646. https://doi.org/10.1111/1475-6765.12646",Hameleers_2023,,,"Data from the authors: ""These were claims that were actually circulated, and we selected the items ourselves. The reason we chose these statements is that they were fact-checked by professional fact-checkers, so we could be certain of their veracity. The other criterion that guided our selection was that we wanted to achieve a reasonable balance of pro-Russian vs. pro-Ukrainian as well as true and false statements.""; 
""These are pre-intervention ratings."";
""Did each participant see all 6 true and all 3 false news items? Yes"" ",yes,5,Czech Republic,within,yes,no,,original,,researchers,fact_checking,fact_checking,political,1,9,,0.6666666667,title,no_source,truthfulness,"""Could you rate the truthfulness of the sestatements? Please give us your best guess .A guess is just as good as the “right” answer."" 
(1)Very certain it’s false (2) Somewhat certain it’s false (3)Uncertain whether it’s true or false (4) Somewhat certain it’s true (5) Very certain it’s true",1,1,5,control,,,,,,,1000,2.7,0.86,3.22,0.49,authors,no
57,"Hameleers, M., Tulin, M., De Vreese, C., Aalberg, T., Van Aelst, P., Cardenal, A. S., Corbu, N., Van Erkel, P., Esser, F., Gehle, L., Halagiera, D., Hopmann, D., Koc‐Michalska, K., Matthes, J., Meltzer, C., Mihelj, S., Schemer, C., Sheafer, T., Splendore, S., … Zoizner, A. (2023). Mistakenly misinformed or intentionally deceived? Mis‐ and Disinformation perceptions on the Russian War in Ukraine among citizens in 19 countries. European Journal of Political Research, 1475-6765.12646. https://doi.org/10.1111/1475-6765.12646",Hameleers_2023,,,"Data from the authors: ""These were claims that were actually circulated, and we selected the items ourselves. The reason we chose these statements is that they were fact-checked by professional fact-checkers, so we could be certain of their veracity. The other criterion that guided our selection was that we wanted to achieve a reasonable balance of pro-Russian vs. pro-Ukrainian as well as true and false statements.""; 
""These are pre-intervention ratings."";
""Did each participant see all 6 true and all 3 false news items? Yes"" ",yes,6,Germany,within,yes,no,,original,,researchers,fact_checking,fact_checking,political,1,9,,0.6666666667,title,no_source,truthfulness,"""Could you rate the truthfulness of the sestatements? Please give us your best guess .A guess is just as good as the “right” answer."" 
(1)Very certain it’s false (2) Somewhat certain it’s false (3)Uncertain whether it’s true or false (4) Somewhat certain it’s true (5) Very certain it’s true",1,1,5,control,,,,,,,1000,2.26,0.86,3.15,0.45,authors,no
57,"Hameleers, M., Tulin, M., De Vreese, C., Aalberg, T., Van Aelst, P., Cardenal, A. S., Corbu, N., Van Erkel, P., Esser, F., Gehle, L., Halagiera, D., Hopmann, D., Koc‐Michalska, K., Matthes, J., Meltzer, C., Mihelj, S., Schemer, C., Sheafer, T., Splendore, S., … Zoizner, A. (2023). Mistakenly misinformed or intentionally deceived? Mis‐ and Disinformation perceptions on the Russian War in Ukraine among citizens in 19 countries. European Journal of Political Research, 1475-6765.12646. https://doi.org/10.1111/1475-6765.12646",Hameleers_2023,,,"Data from the authors: ""These were claims that were actually circulated, and we selected the items ourselves. The reason we chose these statements is that they were fact-checked by professional fact-checkers, so we could be certain of their veracity. The other criterion that guided our selection was that we wanted to achieve a reasonable balance of pro-Russian vs. pro-Ukrainian as well as true and false statements.""; 
""These are pre-intervention ratings."";
""Did each participant see all 6 true and all 3 false news items? Yes"" ",yes,7,Denmark,within,yes,no,,original,,researchers,fact_checking,fact_checking,political,1,9,,0.6666666667,title,no_source,truthfulness,"""Could you rate the truthfulness of the sestatements? Please give us your best guess .A guess is just as good as the “right” answer."" 
(1)Very certain it’s false (2) Somewhat certain it’s false (3)Uncertain whether it’s true or false (4) Somewhat certain it’s true (5) Very certain it’s true",1,1,5,control,,,,,,,1001,2.21,0.84,3.19,0.5,authors,no
57,"Hameleers, M., Tulin, M., De Vreese, C., Aalberg, T., Van Aelst, P., Cardenal, A. S., Corbu, N., Van Erkel, P., Esser, F., Gehle, L., Halagiera, D., Hopmann, D., Koc‐Michalska, K., Matthes, J., Meltzer, C., Mihelj, S., Schemer, C., Sheafer, T., Splendore, S., … Zoizner, A. (2023). Mistakenly misinformed or intentionally deceived? Mis‐ and Disinformation perceptions on the Russian War in Ukraine among citizens in 19 countries. European Journal of Political Research, 1475-6765.12646. https://doi.org/10.1111/1475-6765.12646",Hameleers_2023,,,"Data from the authors: ""These were claims that were actually circulated, and we selected the items ourselves. The reason we chose these statements is that they were fact-checked by professional fact-checkers, so we could be certain of their veracity. The other criterion that guided our selection was that we wanted to achieve a reasonable balance of pro-Russian vs. pro-Ukrainian as well as true and false statements.""; 
""These are pre-intervention ratings."";
""Did each participant see all 6 true and all 3 false news items? Yes"" ",yes,8,Spain,within,yes,no,,original,,researchers,fact_checking,fact_checking,political,1,9,,0.6666666667,title,no_source,truthfulness,"""Could you rate the truthfulness of the sestatements? Please give us your best guess .A guess is just as good as the “right” answer."" 
(1)Very certain it’s false (2) Somewhat certain it’s false (3)Uncertain whether it’s true or false (4) Somewhat certain it’s true (5) Very certain it’s true",1,1,5,control,,,,,,,1001,2.42,0.81,3.22,0.47,authors,no
57,"Hameleers, M., Tulin, M., De Vreese, C., Aalberg, T., Van Aelst, P., Cardenal, A. S., Corbu, N., Van Erkel, P., Esser, F., Gehle, L., Halagiera, D., Hopmann, D., Koc‐Michalska, K., Matthes, J., Meltzer, C., Mihelj, S., Schemer, C., Sheafer, T., Splendore, S., … Zoizner, A. (2023). Mistakenly misinformed or intentionally deceived? Mis‐ and Disinformation perceptions on the Russian War in Ukraine among citizens in 19 countries. European Journal of Political Research, 1475-6765.12646. https://doi.org/10.1111/1475-6765.12646",Hameleers_2023,,,"Data from the authors: ""These were claims that were actually circulated, and we selected the items ourselves. The reason we chose these statements is that they were fact-checked by professional fact-checkers, so we could be certain of their veracity. The other criterion that guided our selection was that we wanted to achieve a reasonable balance of pro-Russian vs. pro-Ukrainian as well as true and false statements.""; 
""These are pre-intervention ratings."";
""Did each participant see all 6 true and all 3 false news items? Yes"" ",yes,9,France,within,yes,no,,original,,researchers,fact_checking,fact_checking,political,1,9,,0.6666666667,title,no_source,truthfulness,"""Could you rate the truthfulness of the sestatements? Please give us your best guess .A guess is just as good as the “right” answer."" 
(1)Very certain it’s false (2) Somewhat certain it’s false (3)Uncertain whether it’s true or false (4) Somewhat certain it’s true (5) Very certain it’s true",1,1,5,control,,,,,,,1003,2.38,0.81,3.22,0.47,authors,no
57,"Hameleers, M., Tulin, M., De Vreese, C., Aalberg, T., Van Aelst, P., Cardenal, A. S., Corbu, N., Van Erkel, P., Esser, F., Gehle, L., Halagiera, D., Hopmann, D., Koc‐Michalska, K., Matthes, J., Meltzer, C., Mihelj, S., Schemer, C., Sheafer, T., Splendore, S., … Zoizner, A. (2023). Mistakenly misinformed or intentionally deceived? Mis‐ and Disinformation perceptions on the Russian War in Ukraine among citizens in 19 countries. European Journal of Political Research, 1475-6765.12646. https://doi.org/10.1111/1475-6765.12646",Hameleers_2023,,,"Data from the authors: ""These were claims that were actually circulated, and we selected the items ourselves. The reason we chose these statements is that they were fact-checked by professional fact-checkers, so we could be certain of their veracity. The other criterion that guided our selection was that we wanted to achieve a reasonable balance of pro-Russian vs. pro-Ukrainian as well as true and false statements.""; 
""These are pre-intervention ratings."";
""Did each participant see all 6 true and all 3 false news items? Yes"" ",yes,10,Great Britain,within,yes,no,,original,,researchers,fact_checking,fact_checking,political,1,9,,0.6666666667,title,no_source,truthfulness,"""Could you rate the truthfulness of the sestatements? Please give us your best guess .A guess is just as good as the “right” answer."" 
(1)Very certain it’s false (2) Somewhat certain it’s false (3)Uncertain whether it’s true or false (4) Somewhat certain it’s true (5) Very certain it’s true",1,1,5,control,,,,,,,1004,2.28,0.85,3.14,0.44,authors,no
57,"Hameleers, M., Tulin, M., De Vreese, C., Aalberg, T., Van Aelst, P., Cardenal, A. S., Corbu, N., Van Erkel, P., Esser, F., Gehle, L., Halagiera, D., Hopmann, D., Koc‐Michalska, K., Matthes, J., Meltzer, C., Mihelj, S., Schemer, C., Sheafer, T., Splendore, S., … Zoizner, A. (2023). Mistakenly misinformed or intentionally deceived? Mis‐ and Disinformation perceptions on the Russian War in Ukraine among citizens in 19 countries. European Journal of Political Research, 1475-6765.12646. https://doi.org/10.1111/1475-6765.12646",Hameleers_2023,,,"Data from the authors: ""These were claims that were actually circulated, and we selected the items ourselves. The reason we chose these statements is that they were fact-checked by professional fact-checkers, so we could be certain of their veracity. The other criterion that guided our selection was that we wanted to achieve a reasonable balance of pro-Russian vs. pro-Ukrainian as well as true and false statements.""; 
""These are pre-intervention ratings."";
""Did each participant see all 6 true and all 3 false news items? Yes"" ",yes,11,Greece,within,yes,no,,original,,researchers,fact_checking,fact_checking,political,1,9,,0.6666666667,title,no_source,truthfulness,"""Could you rate the truthfulness of the sestatements? Please give us your best guess .A guess is just as good as the “right” answer."" 
(1)Very certain it’s false (2) Somewhat certain it’s false (3)Uncertain whether it’s true or false (4) Somewhat certain it’s true (5) Very certain it’s true",1,1,5,control,,,,,,,1005,2.98,0.73,3.2,0.44,authors,no
57,"Hameleers, M., Tulin, M., De Vreese, C., Aalberg, T., Van Aelst, P., Cardenal, A. S., Corbu, N., Van Erkel, P., Esser, F., Gehle, L., Halagiera, D., Hopmann, D., Koc‐Michalska, K., Matthes, J., Meltzer, C., Mihelj, S., Schemer, C., Sheafer, T., Splendore, S., … Zoizner, A. (2023). Mistakenly misinformed or intentionally deceived? Mis‐ and Disinformation perceptions on the Russian War in Ukraine among citizens in 19 countries. European Journal of Political Research, 1475-6765.12646. https://doi.org/10.1111/1475-6765.12646",Hameleers_2023,,,"Data from the authors: ""These were claims that were actually circulated, and we selected the items ourselves. The reason we chose these statements is that they were fact-checked by professional fact-checkers, so we could be certain of their veracity. The other criterion that guided our selection was that we wanted to achieve a reasonable balance of pro-Russian vs. pro-Ukrainian as well as true and false statements.""; 
""These are pre-intervention ratings."";
""Did each participant see all 6 true and all 3 false news items? Yes"" ",yes,12,Hungary,within,yes,no,,original,,researchers,fact_checking,fact_checking,political,1,9,,0.6666666667,title,no_source,truthfulness,"""Could you rate the truthfulness of the sestatements? Please give us your best guess .A guess is just as good as the “right” answer."" 
(1)Very certain it’s false (2) Somewhat certain it’s false (3)Uncertain whether it’s true or false (4) Somewhat certain it’s true (5) Very certain it’s true",1,1,5,control,,,,,,,1000,2.83,0.81,3.26,0.5,authors,no
57,"Hameleers, M., Tulin, M., De Vreese, C., Aalberg, T., Van Aelst, P., Cardenal, A. S., Corbu, N., Van Erkel, P., Esser, F., Gehle, L., Halagiera, D., Hopmann, D., Koc‐Michalska, K., Matthes, J., Meltzer, C., Mihelj, S., Schemer, C., Sheafer, T., Splendore, S., … Zoizner, A. (2023). Mistakenly misinformed or intentionally deceived? Mis‐ and Disinformation perceptions on the Russian War in Ukraine among citizens in 19 countries. European Journal of Political Research, 1475-6765.12646. https://doi.org/10.1111/1475-6765.12646",Hameleers_2023,,,"Data from the authors: ""These were claims that were actually circulated, and we selected the items ourselves. The reason we chose these statements is that they were fact-checked by professional fact-checkers, so we could be certain of their veracity. The other criterion that guided our selection was that we wanted to achieve a reasonable balance of pro-Russian vs. pro-Ukrainian as well as true and false statements.""; 
""These are pre-intervention ratings."";
""Did each participant see all 6 true and all 3 false news items? Yes"" ",yes,13,Italy,within,yes,no,,original,,researchers,fact_checking,fact_checking,political,1,9,,0.6666666667,title,no_source,truthfulness,"""Could you rate the truthfulness of the sestatements? Please give us your best guess .A guess is just as good as the “right” answer."" 
(1)Very certain it’s false (2) Somewhat certain it’s false (3)Uncertain whether it’s true or false (4) Somewhat certain it’s true (5) Very certain it’s true",1,1,5,control,,,,,,,1001,2.62,0.76,3.23,0.42,authors,no
57,"Hameleers, M., Tulin, M., De Vreese, C., Aalberg, T., Van Aelst, P., Cardenal, A. S., Corbu, N., Van Erkel, P., Esser, F., Gehle, L., Halagiera, D., Hopmann, D., Koc‐Michalska, K., Matthes, J., Meltzer, C., Mihelj, S., Schemer, C., Sheafer, T., Splendore, S., … Zoizner, A. (2023). Mistakenly misinformed or intentionally deceived? Mis‐ and Disinformation perceptions on the Russian War in Ukraine among citizens in 19 countries. European Journal of Political Research, 1475-6765.12646. https://doi.org/10.1111/1475-6765.12646",Hameleers_2023,,,"Data from the authors: ""These were claims that were actually circulated, and we selected the items ourselves. The reason we chose these statements is that they were fact-checked by professional fact-checkers, so we could be certain of their veracity. The other criterion that guided our selection was that we wanted to achieve a reasonable balance of pro-Russian vs. pro-Ukrainian as well as true and false statements.""; 
""These are pre-intervention ratings."";
""Did each participant see all 6 true and all 3 false news items? Yes"" ",yes,14,Netherlands,within,yes,no,,original,,researchers,fact_checking,fact_checking,political,1,9,,0.6666666667,title,no_source,truthfulness,"""Could you rate the truthfulness of the sestatements? Please give us your best guess .A guess is just as good as the “right” answer."" 
(1)Very certain it’s false (2) Somewhat certain it’s false (3)Uncertain whether it’s true or false (4) Somewhat certain it’s true (5) Very certain it’s true",1,1,5,control,,,,,,,1003,2.42,0.73,3.2,0.44,authors,no
57,"Hameleers, M., Tulin, M., De Vreese, C., Aalberg, T., Van Aelst, P., Cardenal, A. S., Corbu, N., Van Erkel, P., Esser, F., Gehle, L., Halagiera, D., Hopmann, D., Koc‐Michalska, K., Matthes, J., Meltzer, C., Mihelj, S., Schemer, C., Sheafer, T., Splendore, S., … Zoizner, A. (2023). Mistakenly misinformed or intentionally deceived? Mis‐ and Disinformation perceptions on the Russian War in Ukraine among citizens in 19 countries. European Journal of Political Research, 1475-6765.12646. https://doi.org/10.1111/1475-6765.12646",Hameleers_2023,,,"Data from the authors: ""These were claims that were actually circulated, and we selected the items ourselves. The reason we chose these statements is that they were fact-checked by professional fact-checkers, so we could be certain of their veracity. The other criterion that guided our selection was that we wanted to achieve a reasonable balance of pro-Russian vs. pro-Ukrainian as well as true and false statements.""; 
""These are pre-intervention ratings."";
""Did each participant see all 6 true and all 3 false news items? Yes"" ",yes,15,Poland,within,yes,no,,original,,researchers,fact_checking,fact_checking,political,1,9,,0.6666666667,title,no_source,truthfulness,"""Could you rate the truthfulness of the sestatements? Please give us your best guess .A guess is just as good as the “right” answer."" 
(1)Very certain it’s false (2) Somewhat certain it’s false (3)Uncertain whether it’s true or false (4) Somewhat certain it’s true (5) Very certain it’s true",1,1,5,control,,,,,,,1004,2.21,0.85,3.22,0.45,authors,no
57,"Hameleers, M., Tulin, M., De Vreese, C., Aalberg, T., Van Aelst, P., Cardenal, A. S., Corbu, N., Van Erkel, P., Esser, F., Gehle, L., Halagiera, D., Hopmann, D., Koc‐Michalska, K., Matthes, J., Meltzer, C., Mihelj, S., Schemer, C., Sheafer, T., Splendore, S., … Zoizner, A. (2023). Mistakenly misinformed or intentionally deceived? Mis‐ and Disinformation perceptions on the Russian War in Ukraine among citizens in 19 countries. European Journal of Political Research, 1475-6765.12646. https://doi.org/10.1111/1475-6765.12646",Hameleers_2023,,,"Data from the authors: ""These were claims that were actually circulated, and we selected the items ourselves. The reason we chose these statements is that they were fact-checked by professional fact-checkers, so we could be certain of their veracity. The other criterion that guided our selection was that we wanted to achieve a reasonable balance of pro-Russian vs. pro-Ukrainian as well as true and false statements.""; 
""These are pre-intervention ratings."";
""Did each participant see all 6 true and all 3 false news items? Yes"" ",yes,16,Romania,within,yes,no,,original,,researchers,fact_checking,fact_checking,political,1,9,,0.6666666667,title,no_source,truthfulness,"""Could you rate the truthfulness of the sestatements? Please give us your best guess .A guess is just as good as the “right” answer."" 
(1)Very certain it’s false (2) Somewhat certain it’s false (3)Uncertain whether it’s true or false (4) Somewhat certain it’s true (5) Very certain it’s true",1,1,5,control,,,,,,,1006,2.59,0.89,3.34,0.51,authors,no
57,"Hameleers, M., Tulin, M., De Vreese, C., Aalberg, T., Van Aelst, P., Cardenal, A. S., Corbu, N., Van Erkel, P., Esser, F., Gehle, L., Halagiera, D., Hopmann, D., Koc‐Michalska, K., Matthes, J., Meltzer, C., Mihelj, S., Schemer, C., Sheafer, T., Splendore, S., … Zoizner, A. (2023). Mistakenly misinformed or intentionally deceived? Mis‐ and Disinformation perceptions on the Russian War in Ukraine among citizens in 19 countries. European Journal of Political Research, 1475-6765.12646. https://doi.org/10.1111/1475-6765.12646",Hameleers_2023,,,"Data from the authors: ""These were claims that were actually circulated, and we selected the items ourselves. The reason we chose these statements is that they were fact-checked by professional fact-checkers, so we could be certain of their veracity. The other criterion that guided our selection was that we wanted to achieve a reasonable balance of pro-Russian vs. pro-Ukrainian as well as true and false statements.""; 
""These are pre-intervention ratings."";
""Did each participant see all 6 true and all 3 false news items? Yes"" ",yes,17,Serbia,within,yes,no,,original,,researchers,fact_checking,fact_checking,political,1,9,,0.6666666667,title,no_source,truthfulness,"""Could you rate the truthfulness of the sestatements? Please give us your best guess .A guess is just as good as the “right” answer."" 
(1)Very certain it’s false (2) Somewhat certain it’s false (3)Uncertain whether it’s true or false (4) Somewhat certain it’s true (5) Very certain it’s true",1,1,5,control,,,,,,,1000,3.14,0.7,3.15,0.49,authors,no
57,"Hameleers, M., Tulin, M., De Vreese, C., Aalberg, T., Van Aelst, P., Cardenal, A. S., Corbu, N., Van Erkel, P., Esser, F., Gehle, L., Halagiera, D., Hopmann, D., Koc‐Michalska, K., Matthes, J., Meltzer, C., Mihelj, S., Schemer, C., Sheafer, T., Splendore, S., … Zoizner, A. (2023). Mistakenly misinformed or intentionally deceived? Mis‐ and Disinformation perceptions on the Russian War in Ukraine among citizens in 19 countries. European Journal of Political Research, 1475-6765.12646. https://doi.org/10.1111/1475-6765.12646",Hameleers_2023,,,"Data from the authors: ""These were claims that were actually circulated, and we selected the items ourselves. The reason we chose these statements is that they were fact-checked by professional fact-checkers, so we could be certain of their veracity. The other criterion that guided our selection was that we wanted to achieve a reasonable balance of pro-Russian vs. pro-Ukrainian as well as true and false statements.""; 
""These are pre-intervention ratings."";
""Did each participant see all 6 true and all 3 false news items? Yes"" ",yes,18,Sweden,within,yes,no,,original,,researchers,fact_checking,fact_checking,political,1,9,,0.6666666667,title,no_source,truthfulness,"""Could you rate the truthfulness of the sestatements? Please give us your best guess .A guess is just as good as the “right” answer."" 
(1)Very certain it’s false (2) Somewhat certain it’s false (3)Uncertain whether it’s true or false (4) Somewhat certain it’s true (5) Very certain it’s true",1,1,5,control,,,,,,,1001,2.15,0.76,3.11,0.42,authors,no
57,"Hameleers, M., Tulin, M., De Vreese, C., Aalberg, T., Van Aelst, P., Cardenal, A. S., Corbu, N., Van Erkel, P., Esser, F., Gehle, L., Halagiera, D., Hopmann, D., Koc‐Michalska, K., Matthes, J., Meltzer, C., Mihelj, S., Schemer, C., Sheafer, T., Splendore, S., … Zoizner, A. (2023). Mistakenly misinformed or intentionally deceived? Mis‐ and Disinformation perceptions on the Russian War in Ukraine among citizens in 19 countries. European Journal of Political Research, 1475-6765.12646. https://doi.org/10.1111/1475-6765.12646",Hameleers_2023,,,"Data from the authors: ""These were claims that were actually circulated, and we selected the items ourselves. The reason we chose these statements is that they were fact-checked by professional fact-checkers, so we could be certain of their veracity. The other criterion that guided our selection was that we wanted to achieve a reasonable balance of pro-Russian vs. pro-Ukrainian as well as true and false statements.""; 
""These are pre-intervention ratings."";
""Did each participant see all 6 true and all 3 false news items? Yes"" ",yes,19,United States,within,yes,no,,original,,researchers,fact_checking,fact_checking,political,1,9,,0.6666666667,title,no_source,truthfulness,"""Could you rate the truthfulness of the sestatements? Please give us your best guess .A guess is just as good as the “right” answer."" 
(1)Very certain it’s false (2) Somewhat certain it’s false (3)Uncertain whether it’s true or false (4) Somewhat certain it’s true (5) Very certain it’s true",1,1,5,control,,,,,,,1004,2.34,0.91,3.16,0.47,authors,no
58,"Lyons, B., Modirrousta-Galian, A., Altay, S., & Salovich, N. A. (2024). Reduce blind spots to improve news discernment? Performance feedback reduces overconfidence but does not improve subsequent discernment. https://doi.org/10.31219/osf.io/kgfrb",Lyons_2024,yes,,"""2 (headline accuracy: true or false) x 2 (headline congeniality: congenial or uncongenial) x 2 (feedback type: relative feedback or no feedback) x 3 (study phase: 1 [immediately before feedback or lack thereof], 2 [immediately after feedback or lack thereof], or 3 [1 week after feedback or lack thereof]) mixed design."";
data corresponds to control group, post-treatment ratings",no ,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_concordant,1,6,,0.6666666667,title_picture,source,accuracy,"""Accuracy judgments were made on a 4-point scale from “Not at all accurate” to “Very accurate”.""",1,0,4,control,,,,,,,798,2.55,1.07,2.93,1,raw data,yes
58,"Lyons, B., Modirrousta-Galian, A., Altay, S., & Salovich, N. A. (2024). Reduce blind spots to improve news discernment? Performance feedback reduces overconfidence but does not improve subsequent discernment. https://doi.org/10.31219/osf.io/kgfrb",Lyons_2024,yes,,"""2 (headline accuracy: true or false) x 2 (headline congeniality: congenial or uncongenial) x 2 (feedback type: relative feedback or no feedback) x 3 (study phase: 1 [immediately before feedback or lack thereof], 2 [immediately after feedback or lack thereof], or 3 [1 week after feedback or lack thereof]) mixed design."";
data corresponds to control group, post-treatment ratings",no ,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_discordant,2,6,,0.6666666667,title_picture,source,accuracy,"""Accuracy judgments were made on a 4-point scale from “Not at all accurate” to “Very accurate”.""",1,0,4,control,,,,,,,798,2.16,1.1,2.54,1.06,raw data,yes
58,"Lyons, B., Modirrousta-Galian, A., Altay, S., & Salovich, N. A. (2024). Reduce blind spots to improve news discernment? Performance feedback reduces overconfidence but does not improve subsequent discernment. https://doi.org/10.31219/osf.io/kgfrb",Lyons_2024,yes,,"""2 (headline accuracy: true or false) x 2 (headline congeniality: congenial or uncongenial) x 2 (feedback type: relative feedback or no feedback) x 3 (study phase: 1 [immediately before feedback or lack thereof], 2 [immediately after feedback or lack thereof], or 3 [1 week after feedback or lack thereof]) mixed design."";
data corresponds to control group, post-treatment ratings, participants with a political party identifier coded as ""independent/other""",no ,2,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,political,1,12,,0.6666666667,title_picture,source,accuracy,"""Accuracy judgments were made on a 4-point scale from “Not at all accurate” to “Very accurate”.""",1,0,4,control,,,,,,,274,2.18,1,2.62,0.987,raw data,yes
58,"Lyons, B., Modirrousta-Galian, A., Altay, S., & Salovich, N. A. (2024). Reduce blind spots to improve news discernment? Performance feedback reduces overconfidence but does not improve subsequent discernment. https://doi.org/10.31219/osf.io/kgfrb",Lyons_2024,yes,,"""2 (headline accuracy: true or false) x 2 (headline congeniality: congenial or uncongenial) x 2 (feedback type: relative feedback or no feedback) x 3 (study phase: 1 [immediately before feedback or lack thereof], 2 [immediately after feedback or lack thereof], or 3 [1 week after feedback or lack thereof]) mixed design."";
data corresponds to control group, pre-treatment ratings",no ,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_concordant,3,6,,0.6666666667,title_picture,source,accuracy,"""Accuracy judgments were made on a 4-point scale from “Not at all accurate” to “Very accurate”.""",1,0,4,control,,,,,,,807,2.54,1.08,2.87,1.03,raw data,yes
58,"Lyons, B., Modirrousta-Galian, A., Altay, S., & Salovich, N. A. (2024). Reduce blind spots to improve news discernment? Performance feedback reduces overconfidence but does not improve subsequent discernment. https://doi.org/10.31219/osf.io/kgfrb",Lyons_2024,yes,,"""2 (headline accuracy: true or false) x 2 (headline congeniality: congenial or uncongenial) x 2 (feedback type: relative feedback or no feedback) x 3 (study phase: 1 [immediately before feedback or lack thereof], 2 [immediately after feedback or lack thereof], or 3 [1 week after feedback or lack thereof]) mixed design."";
data corresponds to control group, pre-treatment ratings",no ,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_discordant,4,6,,0.6666666667,title_picture,source,accuracy,"""Accuracy judgments were made on a 4-point scale from “Not at all accurate” to “Very accurate”.""",1,0,4,control,,,,,,,808,2.2,1.11,2.51,1.07,raw data,yes
58,"Lyons, B., Modirrousta-Galian, A., Altay, S., & Salovich, N. A. (2024). Reduce blind spots to improve news discernment? Performance feedback reduces overconfidence but does not improve subsequent discernment. https://doi.org/10.31219/osf.io/kgfrb",Lyons_2024,yes,,"""2 (headline accuracy: true or false) x 2 (headline congeniality: congenial or uncongenial) x 2 (feedback type: relative feedback or no feedback) x 3 (study phase: 1 [immediately before feedback or lack thereof], 2 [immediately after feedback or lack thereof], or 3 [1 week after feedback or lack thereof]) mixed design."";
data corresponds to control group, pre-treatment ratings, participants with a political party identifier coded as ""independent/other""",no ,2,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,political,3,12,,0.6666666667,title_picture,source,accuracy,"""Accuracy judgments were made on a 4-point scale from “Not at all accurate” to “Very accurate”.""",1,0,4,control,,,,,,,285,2.13,1.02,2.55,1.02,raw data,yes
58,"Lyons, B., Modirrousta-Galian, A., Altay, S., & Salovich, N. A. (2024). Reduce blind spots to improve news discernment? Performance feedback reduces overconfidence but does not improve subsequent discernment. https://doi.org/10.31219/osf.io/kgfrb",Lyons_2024,yes,,"""2 (headline accuracy: true or false) x 2 (headline congeniality: congenial or uncongenial) x 2 (feedback type: relative feedback or no feedback) x 3 (study phase: 1 [immediately before feedback or lack thereof], 2 [immediately after feedback or lack thereof], or 3 [1 week after feedback or lack thereof]) mixed design."";
data corresponds to control group, one week after-treatment ratings",no ,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_concordant,5,6,,0.6666666667,title_picture,source,accuracy,"""Accuracy judgments were made on a 4-point scale from “Not at all accurate” to “Very accurate”.""",1,0,4,control,,,,,,,275.5,2.24,1.06,3.04,0.992,raw data,yes
58,"Lyons, B., Modirrousta-Galian, A., Altay, S., & Salovich, N. A. (2024). Reduce blind spots to improve news discernment? Performance feedback reduces overconfidence but does not improve subsequent discernment. https://doi.org/10.31219/osf.io/kgfrb",Lyons_2024,yes,,"""2 (headline accuracy: true or false) x 2 (headline congeniality: congenial or uncongenial) x 2 (feedback type: relative feedback or no feedback) x 3 (study phase: 1 [immediately before feedback or lack thereof], 2 [immediately after feedback or lack thereof], or 3 [1 week after feedback or lack thereof]) mixed design."";
data corresponds to control group, one week after-treatment ratings",no ,1,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_discordant,6,6,,0.6666666667,title_picture,source,accuracy,"""Accuracy judgments were made on a 4-point scale from “Not at all accurate” to “Very accurate”.""",1,0,4,control,,,,,,,276,1.78,0.952,2.43,1.05,raw data,yes
58,"Lyons, B., Modirrousta-Galian, A., Altay, S., & Salovich, N. A. (2024). Reduce blind spots to improve news discernment? Performance feedback reduces overconfidence but does not improve subsequent discernment. https://doi.org/10.31219/osf.io/kgfrb",Lyons_2024,yes,,"""2 (headline accuracy: true or false) x 2 (headline congeniality: congenial or uncongenial) x 2 (feedback type: relative feedback or no feedback) x 3 (study phase: 1 [immediately before feedback or lack thereof], 2 [immediately after feedback or lack thereof], or 3 [1 week after feedback or lack thereof]) mixed design."";
data corresponds to control group, one week after-treatment ratings, participants with a political party identifier coded as ""independent/other""",no ,2,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,political,5,12,,0.6666666667,title_picture,source,accuracy,"""Accuracy judgments were made on a 4-point scale from “Not at all accurate” to “Very accurate”.""",1,0,4,control,,,,,,,121.5,2.04,1.01,2.69,1.05,raw data,yes
58,"Lyons, B., Modirrousta-Galian, A., Altay, S., & Salovich, N. A. (2024). Reduce blind spots to improve news discernment? Performance feedback reduces overconfidence but does not improve subsequent discernment. https://doi.org/10.31219/osf.io/kgfrb",Lyons_2024,yes,,"""2 (headline accuracy: true or false) x 2 (headline congeniality: congenial or uncongenial) x 2 (feedback type: relative feedback or no feedback) x 3 (study phase: 1 [immediately before feedback or lack thereof], 2 [immediately after feedback or lack thereof], or 3 [1 week after feedback or lack thereof]) mixed design."";
data corresponds to treatment group, pre-treatment ratings",no ,3,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_concordant,3,6,,0.6666666667,title_picture,source,accuracy,"""Accuracy judgments were made on a 4-point scale from “Not at all accurate” to “Very accurate”.""",1,0,4,control,,,,,,,782,2.56,1.05,2.9,0.994,raw data,yes
58,"Lyons, B., Modirrousta-Galian, A., Altay, S., & Salovich, N. A. (2024). Reduce blind spots to improve news discernment? Performance feedback reduces overconfidence but does not improve subsequent discernment. https://doi.org/10.31219/osf.io/kgfrb",Lyons_2024,yes,,"""2 (headline accuracy: true or false) x 2 (headline congeniality: congenial or uncongenial) x 2 (feedback type: relative feedback or no feedback) x 3 (study phase: 1 [immediately before feedback or lack thereof], 2 [immediately after feedback or lack thereof], or 3 [1 week after feedback or lack thereof]) mixed design."";
data corresponds to treatment group, pre-treatment ratings",no ,3,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,politically_discordant,4,6,,0.6666666667,title_picture,source,accuracy,"""Accuracy judgments were made on a 4-point scale from “Not at all accurate” to “Very accurate”.""",1,0,4,control,,,,,,,783.5,2.23,1.12,2.57,1.04,raw data,yes
58,"Lyons, B., Modirrousta-Galian, A., Altay, S., & Salovich, N. A. (2024). Reduce blind spots to improve news discernment? Performance feedback reduces overconfidence but does not improve subsequent discernment. https://doi.org/10.31219/osf.io/kgfrb",Lyons_2024,yes,,"""2 (headline accuracy: true or false) x 2 (headline congeniality: congenial or uncongenial) x 2 (feedback type: relative feedback or no feedback) x 3 (study phase: 1 [immediately before feedback or lack thereof], 2 [immediately after feedback or lack thereof], or 3 [1 week after feedback or lack thereof]) mixed design."";
data corresponds to treatment group, pre-treatment ratings, participants with a political party identifier coded as ""independent/other""",no ,4,United States,within,yes,no,,original,,researchers,fact_checking,mainstream,political,3,12,,0.6666666667,title_picture,source,accuracy,"""Accuracy judgments were made on a 4-point scale from “Not at all accurate” to “Very accurate”.""",1,0,4,control,,,,,,,318,2.09,0.977,2.55,0.994,raw data,yes
59,"Pereira, F. B., Bueno, N. S., Nunes, F., & Pavão, N. (2023). Inoculation Reduces Misinformation: Experimental Evidence from Multidimensional Interventions in Brazil. Journal of Experimental Political Science, 1–12. https://doi.org/10.1017/XPS.2023.11",Pereira_2023,yes,,"All first wave results can be considered control: ""After completing the first wave questionnaire, respondents were randomly assigned, via simple randomization, to one of two conditions. After the first wave of the survey and before the second, the treatment group (n = 575) received the main experimental stimuli comprised of a multidimensional intervention seeking to reduce rumor acceptance.""; 
For the second wave, we distinguish between control and treatment group; 
In order to be consistent in the sample id's, we nevertheless split the the first wave results into two samples, one for the control and one for the treatment group; 
For the second wave, they repeated some headlines of the first wave and added other new ones - we only consider the new ones; 
data corresponds to control group, wave 1",yes,1,Brazil,within,yes,no,,original,,researchers,fact_checking,,political,1,10,,0.3,title_picture_pitch,source,accuracy,"""In what follows, you will see a few pieces of news. Please, indicate whether you believe them to be true or false. (True/False)""",1,1,binary,control,,,,,,,516,0.305,0.46,0.486,0.5,raw data,yes
59,"Pereira, F. B., Bueno, N. S., Nunes, F., & Pavão, N. (2023). Inoculation Reduces Misinformation: Experimental Evidence from Multidimensional Interventions in Brazil. Journal of Experimental Political Science, 1–12. https://doi.org/10.1017/XPS.2023.11",Pereira_2023,yes,,"All first wave results can be considered control: ""After completing the first wave questionnaire, respondents were randomly assigned, via simple randomization, to one of two conditions. After the first wave of the survey and before the second, the treatment group (n = 575) received the main experimental stimuli comprised of a multidimensional intervention seeking to reduce rumor acceptance.""; 
For the second wave, we distinguish between control and treatment group; 
In order to be consistent in the sample id's, we nevertheless split the the first wave results into two samples, one for the control and one for the treatment group; 
For the second wave, they repeated some headlines of the first wave and added other new ones - we only consider the new ones; 
data corresponds to treatment group, wave 1",yes,2,Brazil,within,yes,no,,original,,researchers,fact_checking,,political,1,10,,0.3,title_picture_pitch,source,accuracy,"""In what follows, you will see a few pieces of news. Please, indicate whether you believe them to be true or false. (True/False)""",1,1,binary,control,,,,,,,521,0.299,0.458,0.491,0.5,raw data,yes
59,"Pereira, F. B., Bueno, N. S., Nunes, F., & Pavão, N. (2023). Inoculation Reduces Misinformation: Experimental Evidence from Multidimensional Interventions in Brazil. Journal of Experimental Political Science, 1–12. https://doi.org/10.1017/XPS.2023.11",Pereira_2023,yes,,"All first wave results can be considered control: ""After completing the first wave questionnaire, respondents were randomly assigned, via simple randomization, to one of two conditions. After the first wave of the survey and before the second, the treatment group (n = 575) received the main experimental stimuli comprised of a multidimensional intervention seeking to reduce rumor acceptance.""; 
For the second wave, we distinguish between control and treatment group; 
In order to be consistent in the sample id's, we nevertheless split the the first wave results into two samples, one for the control and one for the treatment group; 
For the second wave, they repeated some headlines of the first wave and added other new ones - we only consider the new ones; 
data corresponds to control group, wave 2; sample size is averaged between true and false ratings",yes,1,Brazil,within,yes,no,,original,,researchers,fact_checking,,political,2,6,,0.3333333333,title_picture_pitch,source,accuracy,"""In what follows, you will see a few pieces of news. Please, indicate whether you believe them to be true or false. (True/False)""",1,1,binary,control,,,,,,,335,0.261,0.439,0.599,0.491,raw data,yes
59,"Pereira, F. B., Bueno, N. S., Nunes, F., & Pavão, N. (2023). Inoculation Reduces Misinformation: Experimental Evidence from Multidimensional Interventions in Brazil. Journal of Experimental Political Science, 1–12. https://doi.org/10.1017/XPS.2023.11",Pereira_2023,yes,,"All first wave results can be considered control: ""After completing the first wave questionnaire, respondents were randomly assigned, via simple randomization, to one of two conditions. After the first wave of the survey and before the second, the treatment group (n = 575) received the main experimental stimuli comprised of a multidimensional intervention seeking to reduce rumor acceptance.""; 
For the second wave, we distinguish between control and treatment group; 
In order to be consistent in the sample id's, we nevertheless split the the first wave results into two samples, one for the control and one for the treatment group; 
For the second wave, they repeated some headlines of the first wave and added other new ones - we only consider the new ones; 
data corresponds to treatment group, wave 2; sample size is averaged between true and false ratings",yes,2,Brazil,within,yes,no,,original,,researchers,fact_checking,,political,2,6,,0.3333333333,title_picture_pitch,source,accuracy,"""In what follows, you will see a few pieces of news. Please, indicate whether you believe them to be true or false. (True/False)""",1,1,binary,treatment,positive,literacy,"""in Study 2, the treatment group received only the email used as part of the treatment in the first study,"";
""A week after the first survey wave (December 1), the treatment group also received an email from the survey company containing a message about the spread of fake news during the election. The message included a link to a news piece from Folha de São Paulo that described the newspaper’s fact-checking tools available for respondents. The email also included a list of eight steps for spotting fake news. The email sought to foster both motivation and ability to reject misinformation, since the warning message encouraged respondents to be careful with online content and the 8-step recommendations""",,,,342.5,0.231,0.422,0.623,0.485,raw data,yes
60,"Winter, S., Valenzuela, S., Santos, M., Schreyer, T., Iwertowski, L., & Rothmund, T. (2024). (Don’t) Stop Believing: A Signal Detection Approach to Risk and Protective Factors for Engagement with Politicized (Mis)Information in Social Media.",Winter_2024,,,"""a final set of 16 news posts used in the main study"" from the table we know its 8 false and 8 true; 
we needed to exclude 3 false news items because they were made up/modified by the researchers; 
from mail correspondence: ""I have now calculated the 
mean value for the perceived credibility of the circulating fake news 
stories (all-right wing stories plus the Greta story, excluding all 
other left-wing false stories with made-up or modified content). It is M
 = 2.9530, SD = 1.12941 compared to M = 3.9165, SD = 0.79198 for the 
eight true news stories (N= 992, on a 6-point scale).""",no,1,Germany,within,yes,yes,"""we created 20 news headlines, 
with 10 reflecting true events and 10 based on false news. Among these, 5
 each supported a political right-wing and 5 a political left-wing 
perspective. To keep the materials as realistic as possible, the 
majority of false content was taken from fact-checking websites such as correctiv.org."";
""In the pilot study, a total of 102 participants (average age: M = 46.47, SD =
 13.20; 48 female) evaluated each post in terms of perceived credibility
 and invoked interest (both on a Likert scale ranging from 1 to 5). 
Additionally, participants were asked to assess whether each post 
supported a left-wing or right-wing political view (5-point scale). 
Based on the results, four news posts were excluded from the main study,
 and one post was modified. """,original,,researchers,fact_checking,,political,1,13,,0.6153846154,,,credibility,"""participants indicated how credible they perceived the headline to be (not credible at all – very credible) on 6-point scales.""",1,0,6,control,,,,,,,992,2.953,1.12941,3.9165,0.79198,authors,no
61,"Epstein, Z., Sirlin, N., Arechar, A., Pennycook, G., & Rand, D. (2023). The social media context interferes with truth discernment. Science Advances, 9(9), eabo6169. https://doi.org/10.1126/sciadv.abo6169",Epstein_2023,,,"the study fails to state where their news headlines come from;
data correspond to accuracy first, then sharing condition",yes ,1,United States,within,yes,no,,,,,,,covid,1,25,,0.4,title,no_source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” (yes/no)",1,1,binary,control,,,,,,,181.5,0.22,0.414,0.539,0.499,raw data,no
61,"Epstein, Z., Sirlin, N., Arechar, A., Pennycook, G., & Rand, D. (2023). The social media context interferes with truth discernment. Science Advances, 9(9), eabo6169. https://doi.org/10.1126/sciadv.abo6169",Epstein_2023,,,"the study fails to state where their news headlines come from;
data correspond to accuracy only condition",yes ,2,United States,within,yes,no,,,,,,,covid,1,25,,0.4,title,no_source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” (yes/no)",1,1,binary,control,,,,,,,203.5,0.219,0.414,0.608,0.488,raw data,no
61,"Epstein, Z., Sirlin, N., Arechar, A., Pennycook, G., & Rand, D. (2023). The social media context interferes with truth discernment. Science Advances, 9(9), eabo6169. https://doi.org/10.1126/sciadv.abo6169",Epstein_2023,,,"the study fails to state where their news headlines come from; also no indication of how many true and false for political news items;
data correspond to accuracy first, then sharing condition",yes ,3,United States,within,yes,no,,,,,,,politically_concordant,2,24,30,,title_picture_pitch,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” (yes/no)",1,1,binary,control,,,,,,,481.5,0.325,0.469,0.552,0.497,raw data,no
61,"Epstein, Z., Sirlin, N., Arechar, A., Pennycook, G., & Rand, D. (2023). The social media context interferes with truth discernment. Science Advances, 9(9), eabo6169. https://doi.org/10.1126/sciadv.abo6169",Epstein_2023,,,"the study fails to state where their news headlines come from; also no indication of how many true and false for political news items;
data correspond to accuracy first, then sharing condition",yes ,3,United States,within,yes,no,,,,,,,politically_discordant,3,24,30,,title_picture_pitch,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” (yes/no)",1,1,binary,control,,,,,,,482,0.273,0.446,0.483,0.5,raw data,no
61,"Epstein, Z., Sirlin, N., Arechar, A., Pennycook, G., & Rand, D. (2023). The social media context interferes with truth discernment. Science Advances, 9(9), eabo6169. https://doi.org/10.1126/sciadv.abo6169",Epstein_2023,,,"the study fails to state where their news headlines come from; also no indication of how many true and false for political news items;
data correspond to accuracy first, then sharing condition; those ratings that could not be identified as concordant or discordant",yes ,4,United States,within,yes,no,,,,,,,political,2,24,60,,title_picture_pitch,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” (yes/no)",1,1,binary,control,,,,,,,98,0.336,0.473,0.435,0.496,raw data,no
61,"Epstein, Z., Sirlin, N., Arechar, A., Pennycook, G., & Rand, D. (2023). The social media context interferes with truth discernment. Science Advances, 9(9), eabo6169. https://doi.org/10.1126/sciadv.abo6169",Epstein_2023,,,"the study fails to state where their news headlines come from; also no indication of how many true and false for political news items;
data correspond to accuracy only condition",yes ,5,United States,within,yes,no,,,,,,,politically_concordant,2,24,30,,title_picture_pitch,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” (yes/no)",1,1,binary,control,,,,,,,457,0.31,0.463,0.541,0.498,raw data,no
61,"Epstein, Z., Sirlin, N., Arechar, A., Pennycook, G., & Rand, D. (2023). The social media context interferes with truth discernment. Science Advances, 9(9), eabo6169. https://doi.org/10.1126/sciadv.abo6169",Epstein_2023,,,"the study fails to state where their news headlines come from; also no indication of how many true and false for political news items;
data correspond to accuracy only condition",yes ,5,United States,within,yes,no,,,,,,,politically_discordant,3,24,30,,title_picture_pitch,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” (yes/no)",1,1,binary,control,,,,,,,457,0.257,0.437,0.511,0.5,raw data,no
61,"Epstein, Z., Sirlin, N., Arechar, A., Pennycook, G., & Rand, D. (2023). The social media context interferes with truth discernment. Science Advances, 9(9), eabo6169. https://doi.org/10.1126/sciadv.abo6169",Epstein_2023,,,"the study fails to state where their news headlines come from; also no indication of how many true and false for political news items;
data correspond to accuracy only condition; those ratings that could not be identified as concordant or discordant",yes ,6,United States,within,yes,no,,,,,,,political,2,24,60,,title_picture_pitch,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate?” (yes/no)",1,1,binary,control,,,,,,,110,0.401,0.49,0.509,0.5,raw data,no
62,"Koetke, J., Schumann, K., Porter, T., & Smilo-Morgan, I. (2023). Fallibility Salience Increases Intellectual Humility: Implications for People’s Willingness to Investigate Political Misinformation. Personality and Social Psychology Bulletin, 49(5), 806–820. https://doi.org/10.1177/01461672221080979",Koetke_2023,,,"data corresponds to study 1;
they do not even explicitly say that they recruited an american sample, but it seems pretty clear from their headlines on the US capitol",yes,1,United States,between,yes,no,,,,researchers,fact_checking,fact_checking,political,1,2,,0.5,title_picture_pitch,source,accuracy,"""As our primary outcome of discernment, participants completed an assessment of perceived accuracy (adapted from Pennycook & Rand, 2019). This included three items (e.g., “To the best of your knowledge, how accurate is the claim in the article you were presented with in this study?”) which were measured on a seven-point scale. We averaged all items together to create a composite score""",1,0,7,control,,,,,,,289,2.5,2.07,4.99,1.61,paper,no
63,"Aslett, K., Sanderson, Z., Godel, W., Persily, N., Nagler, J., & Tucker, J. A. (2024). Online searches to evaluate misinformation can increase its perceived veracity. Nature, 625(7995), 548–556. https://doi.org/10.1038/s41586-023-06883-y",Aslett_2024,,,"Data for study 1, control group: There were a bunch of participants who only saw true news. We restrict our data to participants that have presumably seen (because they have entries for) both true and false news.  Note that among these, there are still participants (355 out of 2143) who did not provide a valid answer to either false or true news - in our report, we average the sample size between respondents with valid responses between false and true news; 
It is not clear from the paper how many news headlines each participant rated, and how much of them were true and false;
in our data analysis, we find that the vast majority of participants have 3 valid responses, 2 of which on true news. This is what we code in our summary data;
For news topic, we code political as this was the category for the vast majority of their items in this study (see their ESM, Appendix A) - their data is not fine grained enough to distinguish between different topics;
It's not clear if participants read the full article or not, and whether a source was present or not;  
the size of the news pool is 13 false items + 21 true items (after we filtered the data according to the conditions above, i.e. only participants who responded to both true and false news) = 34  ;
note that true news have been sampled from both low quality sources and mainstream sources. Here, we provide the combined results",yes ,1,United States,within,yes,no,,,,automated,automated,automated,political,1,3,34,0.6666666667,,,accuracy,"""The participants were also asked a seven-point ordinal scale veracity question: “now that you have evaluated the article, we are interested in the strength of your opinion. Please rank the article on the following scale: 1 (definitely not true), 2, 3, 4, 5, 6, 7 (definitely true)”""",1,1,7,control,,,,,,,994,4.02,1.71,4.97,1.65,raw data,no
63,"Aslett, K., Sanderson, Z., Godel, W., Persily, N., Nagler, J., & Tucker, J. A. (2024). Online searches to evaluate misinformation can increase its perceived veracity. Nature, 625(7995), 548–556. https://doi.org/10.1038/s41586-023-06883-y",Aslett_2024,,,"Data for study 2, control group. Regarding veracity, this was a between participants study - all participants only rated one news headline, either false or true:  
For sample size we divided 1054 + 3198 = 4252 by two;
For news topic, we code political as this was the category for the vast majority of their items in this study (see their ESM, Appendix A) - their data is not fine grained enough to distinguish between different topics;
It's not clear if participants read the full article or not, and whether a source was present or not;  
the size of the news pool is 33 false items + 97 true items = 130;
note that true news have been sampled from both low quality sources and mainstream sources. Here, we provide the combined results",yes ,2,United States,between,yes,no,,,,automated,automated,automated,political,2,2,130,0.5,,,accuracy,"""The participants were also asked a seven-point ordinal scale veracity question: “now that you have evaluated the article, we are interested in the strength of your opinion. Please rank the article on the following scale: 1 (definitely not true), 2, 3, 4, 5, 6, 7 (definitely true)”""",1,1,7,control,,,,,,,2126,4.07,1.79,5.16,1.68,raw data,no
63,"Aslett, K., Sanderson, Z., Godel, W., Persily, N., Nagler, J., & Tucker, J. A. (2024). Online searches to evaluate misinformation can increase its perceived veracity. Nature, 625(7995), 548–556. https://doi.org/10.1038/s41586-023-06883-y",Aslett_2024,,,"Data for study 3, control group. Regarding veracity, this was a between participants study - all participants only rated one news headline, either false or true;
This is a replication of study 2, using the same headlines, but a couple of months after; 
For sample size we divided those who saw false news and those who saw true news by two;
For news topic, we code political as this was the category for the vast majority of their items in this study (see their ESM, Appendix A) - their data is not fine grained enough to distinguish between different topics;
It's not clear if participants read the full article or not, and whether a source was present or not;  
the size of the news pool is 33 false items + 97 true items = 130;
note that true news have been sampled from both low quality sources and mainstream sources. Here, we provide the combined results",yes ,3,United States,between,yes,no,,,,automated,automated,automated,political,2,2,130,0.5,,,accuracy,"""The participants were also asked a seven-point ordinal scale veracity question: “now that you have evaluated the article, we are interested in the strength of your opinion. Please rank the article on the following scale: 1 (definitely not true), 2, 3, 4, 5, 6, 7 (definitely true)”""",1,1,7,control,,,,,,,2021,4.11,1.85,5.1,1.66,raw data,no
63,"Aslett, K., Sanderson, Z., Godel, W., Persily, N., Nagler, J., & Tucker, J. A. (2024). Online searches to evaluate misinformation can increase its perceived veracity. Nature, 625(7995), 548–556. https://doi.org/10.1038/s41586-023-06883-y",Aslett_2024,,,"Data for study 4, control group. Regarding veracity, this was a between participants study - all participants only rated one news headline, either false or true:  
This is a replication of study 2 but using covid related headlines (mostly); 
For sample size we divided those who saw false news and those who saw true news by two;
For news topic, we code covid, as this was the category for the vast majority of their items in this study (see their ESM, Appendix A) - their data is not fine grained enough to distinguish between different topics;
It's not clear if participants read the full article or not, and whether a source was present or not;  
the size of the news pool is 13 false items + 25 true items = 38;
note that true news have been sampled from both low quality sources and mainstream sources. Here, we provide the combined results",yes ,4,United States,between,yes,no,,,,automated,automated,automated,covid,3,2,38,0.5,,,accuracy,"""The participants were also asked a seven-point ordinal scale veracity question: “now that you have evaluated the article, we are interested in the strength of your opinion. Please rank the article on the following scale: 1 (definitely not true), 2, 3, 4, 5, 6, 7 (definitely true)”""",1,1,7,control,,,,,,,2126,4.05,1.78,5.15,1.53,raw data,no
63,"Aslett, K., Sanderson, Z., Godel, W., Persily, N., Nagler, J., & Tucker, J. A. (2024). Online searches to evaluate misinformation can increase its perceived veracity. Nature, 625(7995), 548–556. https://doi.org/10.1038/s41586-023-06883-y",Aslett_2024,,,"Data for study 5, control group: There were a bunch of participants who only saw true news. We restrict our data to participants that have seen both true and false news; 
It is not clear from the paper how many news headlines each participant rated, and how much of them were true and false;
in our data analysis, we find that the vast majority of participants have 3 valid responses, 2 of which on true news. However this is 328 out of 571 participants(159 saw 1/3 true headlines,  84 saw 1/2). Since 573 is not a huge majority in this case, we code the average share in in our summary data, which is 0.551 ;
For news topic, we code mixed as there was no clear outstanding category (with political being a slight majority, but many items coded as ""human interest) (see their ESM, Appendix A) - their data is not fine grained enough to distinguish between different topics;
It's not clear if participants read the full article or not, and whether a source was present or not;  
the size of the news pool is 17 false items + 29 true items (after we filtered the data according to the conditions above, i.e. only participants who responded to both true and false news) = 46  ;
note that true news have been sampled from both low quality sources and mainstream sources. Here, we provide the combined results",yes ,5,United States,within,yes,no,,,,automated,automated,automated,mixed,4,3,46,0.551,,,accuracy,"""The participants were also asked a seven-point ordinal scale veracity question: “now that you have evaluated the article, we are interested in the strength of your opinion. Please rank the article on the following scale: 1 (definitely not true), 2, 3, 4, 5, 6, 7 (definitely true)”""",1,1,7,control,,,,,,,571,4.14,1.8,5.44,1.63,raw data,no
64,"Guess, A., McGregor, S., Pennycook, G., & Rand, D. (2024). Unbundling Digital Media Literacy Tips: Results from Two Experiments. OSF. https://doi.org/10.31234/osf.io/u34fp",Guess_2024,yes,,"data correspond to study 1, control condition, politically concordant headlines; 
data provided by the authors upon request;
note that we'll code simply ""political"" as headline subject for those participants who are neither democrat nor republican, as we did for other studies",no,1,United States,within,online ,yes,"""The headlines for Study 1 were selected from a pretest of 100 false and 100 true headlines (N = 1,990), and the headlines for Study 2 (described in further detail below) were selected from a pretest of N = 1,982. The 20 presented headlines were chosen randomly (maintaining an equal proportion of true vs. false headlines, and pro-Democratic vs. pro-Republican headlines) from a set of 40 headlines for Study 1 and 60 headlines for Study 2.""",,,researchers,fact_checking,mainstream,politically_concordant,1,10,20,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate or inaccurate?” with response options ranging from 1 - Extremely inaccurate to 6 Extremely accurate""",1,1,6,control,,,,,,,297,2.53,1.71,3.77,1.63,raw data,no
64,"Guess, A., McGregor, S., Pennycook, G., & Rand, D. (2024). Unbundling Digital Media Literacy Tips: Results from Two Experiments. OSF. https://doi.org/10.31234/osf.io/u34fp",Guess_2024,yes,,"data correspond to study 1, control condition, politically discordant headlines; 
data provided by the authors upon request;
note that we'll code simply ""political"" as headline subject for those participants who are neither democrat nor republican, as we did for other studies",no,1,United States,within,online ,yes,"""The headlines for Study 1 were selected from a pretest of 100 false and 100 true headlines (N = 1,990), and the headlines for Study 2 (described in further detail below) were selected from a pretest of N = 1,982. The 20 presented headlines were chosen randomly (maintaining an equal proportion of true vs. false headlines, and pro-Democratic vs. pro-Republican headlines) from a set of 40 headlines for Study 1 and 60 headlines for Study 2.""",,,researchers,fact_checking,mainstream,politically_discordant,2,10,20,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate or inaccurate?” with response options ranging from 1 - Extremely inaccurate to 6 Extremely accurate""",1,1,6,control,,,,,,,297,2.75,1.73,4.2,1.54,raw data,no
64,"Guess, A., McGregor, S., Pennycook, G., & Rand, D. (2024). Unbundling Digital Media Literacy Tips: Results from Two Experiments. OSF. https://doi.org/10.31234/osf.io/u34fp",Guess_2024,yes,,"data correspond to study 1, control condition, all headlines for participants who identify neither as democrat nor as republican; 
data provided by the authors upon request;
note that we'll code simply ""political"" as headline subject for those participants who are neither democrat nor republican, as we did for other studies",no,2,United States,within,online ,yes,"""The headlines for Study 1 were selected from a pretest of 100 false and 100 true headlines (N = 1,990), and the headlines for Study 2 (described in further detail below) were selected from a pretest of N = 1,982. The 20 presented headlines were chosen randomly (maintaining an equal proportion of true vs. false headlines, and pro-Democratic vs. pro-Republican headlines) from a set of 40 headlines for Study 1 and 60 headlines for Study 2.""",,,researchers,fact_checking,mainstream,political,1,20,40,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate or inaccurate?” with response options ranging from 1 - Extremely inaccurate to 6 Extremely accurate""",1,1,6,control,,,,,,,283,2.48,1.61,3.91,1.58,raw data,no
64,"Guess, A., McGregor, S., Pennycook, G., & Rand, D. (2024). Unbundling Digital Media Literacy Tips: Results from Two Experiments. OSF. https://doi.org/10.31234/osf.io/u34fp",Guess_2024,yes,,"data correspond to study 2, control condition, politically concordant headlines, less than 60 ratings (with the vast majority of 20 ratings) per participant; 
data provided by the authors upon request;
note that we'll code simply ""political"" as headline subject for those participants who are neither democrat nor republican, as we did for other studies;
for study 2, the manuscript states that participants saw 20 items (out of a pool of 60 items, in study 2). That seems to be the case for the vast majority of participants (N = 2310), but there are 191 participants who have valid (i.e. non-NA) responses for all 60 news items. We will treat participants who gave 60 answers as a separate sample. ",no,3,United States,within,online ,yes,"""The headlines for Study 1 were selected from a pretest of 100 false and 100 true headlines (N = 1,990), and the headlines for Study 2 (described in further detail below) were selected from a pretest of N = 1,982. The 20 presented headlines were chosen randomly (maintaining an equal proportion of true vs. false headlines, and pro-Democratic vs. pro-Republican headlines) from a set of 40 headlines for Study 1 and 60 headlines for Study 2.""",,,researchers,fact_checking,mainstream,politically_concordant,3,10,30,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate or inaccurate?” with response options ranging from 1 - Extremely inaccurate to 6 Extremely accurate""",1,1,6,control,,,,,,,305,2.99,1.72,4.02,1.55,raw data,no
64,"Guess, A., McGregor, S., Pennycook, G., & Rand, D. (2024). Unbundling Digital Media Literacy Tips: Results from Two Experiments. OSF. https://doi.org/10.31234/osf.io/u34fp",Guess_2024,yes,,"data correspond to study 2, control condition, politically discordant headlines, less than 60 ratings (with the vast majority of 20 ratings) per participant; 
data provided by the authors upon request;
note that we'll code simply ""political"" as headline subject for those participants who are neither democrat nor republican, as we did for other studies;
for study 2, the manuscript states that participants saw 20 items (out of a pool of 60 items, in study 2). That seems to be the case for the vast majority of participants (N = 2310), but there are 191 participants who have valid (i.e. non-NA) responses for all 60 news items. We will treat participants who gave 60 answers as a separate sample. ",no,3,United States,within,online ,yes,"""The headlines for Study 1 were selected from a pretest of 100 false and 100 true headlines (N = 1,990), and the headlines for Study 2 (described in further detail below) were selected from a pretest of N = 1,982. The 20 presented headlines were chosen randomly (maintaining an equal proportion of true vs. false headlines, and pro-Democratic vs. pro-Republican headlines) from a set of 40 headlines for Study 1 and 60 headlines for Study 2.""",,,researchers,fact_checking,mainstream,politically_discordant,4,10,30,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate or inaccurate?” with response options ranging from 1 - Extremely inaccurate to 6 Extremely accurate""",1,1,6,control,,,,,,,305,2.56,1.62,3.73,1.61,raw data,no
64,"Guess, A., McGregor, S., Pennycook, G., & Rand, D. (2024). Unbundling Digital Media Literacy Tips: Results from Two Experiments. OSF. https://doi.org/10.31234/osf.io/u34fp",Guess_2024,yes,,"data correspond to study 2, control condition, all headlines for participants who identify neither as democrat nor as republican, less than 60 ratings (with the vast majority of 20 ratings) per participant; 
data provided by the authors upon request;
note that we'll code simply ""political"" as headline subject for those participants who are neither democrat nor republican, as we did for other studies;
for study 2, the manuscript states that participants saw 20 items (out of a pool of 60 items, in study 2). That seems to be the case for the vast majority of participants (N = 2310), but there are 191 participants who have valid (i.e. non-NA) responses for all 60 news items. We will treat participants who gave 60 answers as a separate sample. ",no,4,United States,within,online ,yes,"""The headlines for Study 1 were selected from a pretest of 100 false and 100 true headlines (N = 1,990), and the headlines for Study 2 (described in further detail below) were selected from a pretest of N = 1,982. The 20 presented headlines were chosen randomly (maintaining an equal proportion of true vs. false headlines, and pro-Democratic vs. pro-Republican headlines) from a set of 40 headlines for Study 1 and 60 headlines for Study 2.""",,,researchers,fact_checking,mainstream,political,3,20,60,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate or inaccurate?” with response options ranging from 1 - Extremely inaccurate to 6 Extremely accurate""",1,1,6,control,,,,,,,157,2.84,1.61,3.9,1.45,raw data,no
64,"Guess, A., McGregor, S., Pennycook, G., & Rand, D. (2024). Unbundling Digital Media Literacy Tips: Results from Two Experiments. OSF. https://doi.org/10.31234/osf.io/u34fp",Guess_2024,yes,,"data correspond to study 2, control condition, politically concordant headlines,  60 ratings per participant; 
data provided by the authors upon request;
note that we'll code simply ""political"" as headline subject for those participants who are neither democrat nor republican, as we did for other studies;
for study 2, the manuscript states that participants saw 20 items (out of a pool of 60 items, in study 2). That seems to be the case for the vast majority of participants (N = 2310), but there are 191 participants who have valid (i.e. non-NA) responses for all 60 news items. We will treat participants who gave 60 answers as a separate sample. ",no,5,United States,within,online ,yes,"""The headlines for Study 1 were selected from a pretest of 100 false and 100 true headlines (N = 1,990), and the headlines for Study 2 (described in further detail below) were selected from a pretest of N = 1,982. The 20 presented headlines were chosen randomly (maintaining an equal proportion of true vs. false headlines, and pro-Democratic vs. pro-Republican headlines) from a set of 40 headlines for Study 1 and 60 headlines for Study 2.""",,,researchers,fact_checking,mainstream,politically_concordant,3,30,30,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate or inaccurate?” with response options ranging from 1 - Extremely inaccurate to 6 Extremely accurate""",1,1,6,control,,,,,,,27,3.33,1.59,3.83,1.36,raw data,no
64,"Guess, A., McGregor, S., Pennycook, G., & Rand, D. (2024). Unbundling Digital Media Literacy Tips: Results from Two Experiments. OSF. https://doi.org/10.31234/osf.io/u34fp",Guess_2024,yes,,"data correspond to study 2, control condition, politically discordant headlines,  60 ratings per participant; 
data provided by the authors upon request;
note that we'll code simply ""political"" as headline subject for those participants who are neither democrat nor republican, as we did for other studies;
for study 2, the manuscript states that participants saw 20 items (out of a pool of 60 items, in study 2). That seems to be the case for the vast majority of participants (N = 2310), but there are 191 participants who have valid (i.e. non-NA) responses for all 60 news items. We will treat participants who gave 60 answers as a separate sample. ",no,5,United States,within,online ,yes,"""The headlines for Study 1 were selected from a pretest of 100 false and 100 true headlines (N = 1,990), and the headlines for Study 2 (described in further detail below) were selected from a pretest of N = 1,982. The 20 presented headlines were chosen randomly (maintaining an equal proportion of true vs. false headlines, and pro-Democratic vs. pro-Republican headlines) from a set of 40 headlines for Study 1 and 60 headlines for Study 2.""",,,researchers,fact_checking,mainstream,politically_discordant,4,30,30,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate or inaccurate?” with response options ranging from 1 - Extremely inaccurate to 6 Extremely accurate""",1,1,6,control,,,,,,,27,3.08,1.61,3.63,1.41,raw data,no
64,"Guess, A., McGregor, S., Pennycook, G., & Rand, D. (2024). Unbundling Digital Media Literacy Tips: Results from Two Experiments. OSF. https://doi.org/10.31234/osf.io/u34fp",Guess_2024,yes,,"data correspond to study 2, control condition, all headlines for participants who identify neither as democrat nor as republican,  60 ratings per participant; 
data provided by the authors upon request;
note that we'll code simply ""political"" as headline subject for those participants who are neither democrat nor republican, as we did for other studies;
for study 2, the manuscript states that participants saw 20 items (out of a pool of 60 items, in study 2). That seems to be the case for the vast majority of participants (N = 2310), but there are 191 participants who have valid (i.e. non-NA) responses for all 60 news items. We will treat participants who gave 60 answers as a separate sample. ",no,6,United States,within,online ,yes,"""The headlines for Study 1 were selected from a pretest of 100 false and 100 true headlines (N = 1,990), and the headlines for Study 2 (described in further detail below) were selected from a pretest of N = 1,982. The 20 presented headlines were chosen randomly (maintaining an equal proportion of true vs. false headlines, and pro-Democratic vs. pro-Republican headlines) from a set of 40 headlines for Study 1 and 60 headlines for Study 2.""",,,researchers,fact_checking,mainstream,political,3,60,60,0.5,title_picture,source,accuracy,"“To the best of your knowledge, is the claim in the above headline accurate or inaccurate?” with response options ranging from 1 - Extremely inaccurate to 6 Extremely accurate""",1,1,6,control,,,,,,,19,3.26,1.54,3.75,1.43,raw data,no
65,"Modirrousta-Galian, A., Higham, P. A., & Seabrooke, T. (2023). Effects of inductive learning and gamification on news veracity discernment. Journal of Experimental Psychology: Applied, 29(3), 599–619. https://doi.org/10.1037/xap0000458",Modirrousta-Galian_2023_b,yes,,data correspond to baseline condition,yes,1,United States,within,yes,no,,recycled,"Brashier, N. M., Pennycook, G., Berinsky, A. J., & Rand, D. G. (2021). Timing matters when correcting fake news. Proceedings of the National Academy of Sciences, 118(5), e2020043118. https://doi.org/10.1073/pnas.2020043118",researchers,fact_checking,mainstream,politically_balanced,1,36,,0.5,title_picture,no_source,accuracy,"""required participants to rate the veracity of 36 news headlines by moving a slider on a scale that ranged from 1 (certainly false) to 7 (certainly true; see Figure 2).""",1,1,7,control,,,,,,,72,2.71,1.66,4.61,1.49,raw data,no
66,"Allen, J., Arechar, A. A., Pennycook, G., & Rand, D. G. (2021). Scaling up fact-checking using the wisdom of crowds. Science Advances, 7(36), eabf4393.",Allen_2021,,,"study is about how well professional fact checker accuracy ratings of news items correlate with ratings of laypeople; 
here, we report laypeople accuracy ratings, establishing veracity of the items by relying on the fact checker ratings (fact checkers read the full text and researched each item, wheras participants only rated headlines); 
To do so, we took the average of the three fact-checkers on all accuracy scales used in the paper combined (as do the authors in their analysis); 
Since all scales were ranging from 1 to 7, with 4 as a neutral midpoint, we coded all items with a rating greater than 4 as 'true' (129 items), and lower than 4 as 'false' (77 items), and excluded one item where the professional fact-checker average was exactly 4;
participants saw random samples of the items, so their share of true news varies - we report the average value here;
we report n = 20 because that is the variable that the paper reports participants saw, but not that many participants rated a couple less items than that",yes,1,United States,within,yes,no,,,,automated,automated,automated,mixed,1,20,206,0.624,,,accuracy,"Fromt he survey materials on the OSF: 'Do you think this story is accurate ?' (1-Denfinitely No, 7- Definitely Yes)",1,1,7,control,,,,,,,1128,3.82,2.02,4.74,1.83,raw data,no
67,"Kreps, S. E., & Kriner, D. L. (2023). Assessing misinformation recall and accuracy perceptions: Evidence from the COVID-19 pandemic. Harvard Kennedy School Misinformation Review. https://doi.org/10.37016/mr-2020-123",Kreps_2023,,,"note that in their survey, they asked participants whether they recall a headline, before asking them to rate their accuracy; 
we do not find it plausible that this should alter people's accuracy ratings, and thus include the study here as control",yes,1,United States,within,yes,no,,,,researchers,fact_checking,mainstream,covid,1,8,16,0.5,,,accuracy,"""Just your best guess, is this statement true? (Answer choices: yes, no, or unsure)""",1,1,binary,control,,,,,,,1045,0.229,0.421,0.485,0.5,raw data,no
68,"Stagnaro, M., Pink, S., Rand, D. G., & Willer, R. (2023). Increasing accuracy motivations using moral reframing does not reduce Republicans’ belief in false news. Harvard Kennedy School Misinformation Review. https://doi.org/10.37016/mr-2020-128",Stagnaro_2023,,,data correspond to control group,yes,1,United States,within,yes,no,,,,researchers,fact_checking,fact_checking,politically_balanced,1,20,100,0.5,,,accuracy,"""Participants rated the accuracy of each headline on a 4-point scale from 1 (Not at all accurate) to 4 (Very accurate).""",1,0,4,control,,,,,,,1007,2.38,1.08,2.9,0.894,raw data,no
69,"Shirikov, A. (2024). Fake News for All: How Citizens Discern Disinformation in Autocracies. Political Communication, 41(1), 45–65. https://doi.org/10.1080/10584609.2023.2257618",Shirikov_2024,,,"data correspond to study 1 (2019), participants who rated 16 items; 
from correspondance with author, we know that while most participants evaluated 16 items, some also evaluated 32; 
those with 16 always evaluated the same 16 (minor exceptions in study 2 that we will gloss over); ",yes,1,Russia,within,yes,no,,,,researchers,fact_checking,mainstream,mixed,1,16,,0.688,pitch,,accuracy,"""This study uses a dichotomized (true/false) measure of perceived news veracity""",1,1,binary,control,,,,,,,32134,0.54512,0.49796,0.49716,0.49999,authors,no
69,"Shirikov, A. (2024). Fake News for All: How Citizens Discern Disinformation in Autocracies. Political Communication, 41(1), 45–65. https://doi.org/10.1080/10584609.2023.2257618",Shirikov_2024,,,"data correspond to study 1 (2019), participants who rated 32 items; 
from correspondance with author, we know that while most participants evaluated 16 items, some also evaluated 32; 
those with 16 always evaluated the same 16 (minor exceptions in study 2 that we will gloss over); ",yes,2,Russia,within,yes,no,,,,researchers,fact_checking,mainstream,mixed,1,32,,0.625,pitch,,accuracy,"""This study uses a dichotomized (true/false) measure of perceived news veracity""",1,1,binary,control,,,,,,,2347,0.47077,0.49915,0.49204,0.49994,authors,no
69,"Shirikov, A. (2024). Fake News for All: How Citizens Discern Disinformation in Autocracies. Political Communication, 41(1), 45–65. https://doi.org/10.1080/10584609.2023.2257618",Shirikov_2024,,,"data correspond to study 2 (2020), participants who rated 16 items, politically concordant items; 
from correspondance with author, we know that while most participants evaluated 16 items, some also evaluated 32; 
those with 16 always evaluated the same 16 (minor exceptions in study 2 that we will gloss over); 
we do not know how many neutral/concordant/discordant items each participant saw - to approximate, we calculate the share of neutral and political slant news in the news pool and multiply that share with the number that participants rated; for example: the pool contained 21 neutral news out of 50 total (21/50 = 0.42) so we assume participants who rated 16 items rated (16*0.42=) 6.72 neutral news; and (16*((1-0.42)/2)) = 4.64 concordant/discordant items, respectively",yes,3,Russia,within,yes,no,,,,researchers,fact_checking,mainstream,politically_concordant,2,4.64,14.5,0.62,pitch,,accuracy,"""This study uses a dichotomized (true/false) measure of perceived news veracity""",1,1,binary,control,,,,,,,15707,0.42361,0.49414,0.48788,0.49986,authors,no
69,"Shirikov, A. (2024). Fake News for All: How Citizens Discern Disinformation in Autocracies. Political Communication, 41(1), 45–65. https://doi.org/10.1080/10584609.2023.2257618",Shirikov_2024,,,"data correspond to study 2 (2020), participants who rated 16 items, politically discordant items; 
from correspondance with author, we know that while most participants evaluated 16 items, some also evaluated 32; 
those with 16 always evaluated the same 16 (minor exceptions in study 2 that we will gloss over); 
we do not know how many neutral/concordant/discordant items each participant saw - to approximate, we calculate the share of neutral and political slant news in the news pool and multiply that share with the number that participants rated; for example: the pool contained 21 neutral news out of 50 total (21/50 = 0.42) so we assume participants who rated 16 items rated (16*0.42=) 6.72 neutral news; and (16*((1-0.42)/2)) = 4.64 concordant/discordant items, respectively",yes,3,Russia,within,yes,no,,,,researchers,fact_checking,mainstream,politically_discordant,3,4.64,14.5,0.62,pitch,,accuracy,"""This study uses a dichotomized (true/false) measure of perceived news veracity""",1,1,binary,control,,,,,,,15707,0.29357,0.4554,0.37686,0.48461,authors,no
69,"Shirikov, A. (2024). Fake News for All: How Citizens Discern Disinformation in Autocracies. Political Communication, 41(1), 45–65. https://doi.org/10.1080/10584609.2023.2257618",Shirikov_2024,,,"data correspond to study 2 (2020), participants who rated 16 items, politically neutral items; 
from correspondance with author, we know that while most participants evaluated 16 items, some also evaluated 32; 
those with 16 always evaluated the same 16 (minor exceptions in study 2 that we will gloss over); 
we do not know how many neutral/concordant/discordant items each participant saw - to approximate, we calculate the share of neutral and political slant news in the news pool and multiply that share with the number that participants rated; for example: the pool contained 21 neutral news out of 50 total (21/50 = 0.42) so we assume participants who rated 16 items rated (16*0.42=) 6.72 neutral news; and (16*((1-0.42)/2)) = 4.64 concordant/discordant items, respectively",yes,3,Russia,within,yes,no,,,,researchers,fact_checking,mainstream,politically_neutral ,4,6.72,21,0.62,pitch,,accuracy,"""This study uses a dichotomized (true/false) measure of perceived news veracity""",1,1,binary,control,,,,,,,15707,0.47614,0.49944,0.5399,0.49841,authors,no
69,"Shirikov, A. (2024). Fake News for All: How Citizens Discern Disinformation in Autocracies. Political Communication, 41(1), 45–65. https://doi.org/10.1080/10584609.2023.2257618",Shirikov_2024,,,"data correspond to study 2 (2020), participants who rated 32 items, politically concordant items; 
from correspondance with author, we know that while most participants evaluated 16 items, some also evaluated 32; 
those with 16 always evaluated the same 16 (minor exceptions in study 2 that we will gloss over); 
we do not know how many neutral/concordant/discordant items each participant saw - to approximate, we calculate the share of neutral and political slant news in the news pool and multiply that share with the number that participants rated; for example: the pool contained 21 neutral news out of 50 total (21/50 = 0.42) so we assume participants who rated 16 items rated (16*0.42=) 6.72 neutral news; and (16*((1-0.42)/2)) = 4.64 concordant/discordant items, respectively",yes,4,Russia,within,yes,no,,,,researchers,fact_checking,mainstream,politically_concordant,2,9.28,14.5,0.591,pitch,,accuracy,"""This study uses a dichotomized (true/false) measure of perceived news veracity""",1,1,binary,control,,,,,,,1576,0.42637,0.4946,0.55156,0.49737,authors,no
69,"Shirikov, A. (2024). Fake News for All: How Citizens Discern Disinformation in Autocracies. Political Communication, 41(1), 45–65. https://doi.org/10.1080/10584609.2023.2257618",Shirikov_2024,,,"data correspond to study 2 (2020), participants who rated 32 items, politically discordant items; 
from correspondance with author, we know that while most participants evaluated 16 items, some also evaluated 32; 
those with 16 always evaluated the same 16 (minor exceptions in study 2 that we will gloss over); 
we do not know how many neutral/concordant/discordant items each participant saw - to approximate, we calculate the share of neutral and political slant news in the news pool and multiply that share with the number that participants rated; for example: the pool contained 21 neutral news out of 50 total (21/50 = 0.42) so we assume participants who rated 16 items rated (16*0.42=) 6.72 neutral news; and (16*((1-0.42)/2)) = 4.64 concordant/discordant items, respectively",yes,4,Russia,within,yes,no,,,,researchers,fact_checking,mainstream,politically_discordant,3,9.28,14.5,0.591,pitch,,accuracy,"""This study uses a dichotomized (true/false) measure of perceived news veracity""",1,1,binary,control,,,,,,,1576,0.31495,0.46454,0.41854,0.49335,authors,no
69,"Shirikov, A. (2024). Fake News for All: How Citizens Discern Disinformation in Autocracies. Political Communication, 41(1), 45–65. https://doi.org/10.1080/10584609.2023.2257618",Shirikov_2024,,,"data correspond to study 2 (2020), participants who rated 32 items, politically neutral items; 
from correspondance with author, we know that while most participants evaluated 16 items, some also evaluated 32; 
those with 16 always evaluated the same 16 (minor exceptions in study 2 that we will gloss over); 
we do not know how many neutral/concordant/discordant items each participant saw - to approximate, we calculate the share of neutral and political slant news in the news pool and multiply that share with the number that participants rated; for example: the pool contained 21 neutral news out of 50 total (21/50 = 0.42) so we assume participants who rated 16 items rated (16*0.42=) 6.72 neutral news; and (16*((1-0.42)/2)) = 4.64 concordant/discordant items, respectively",yes,4,Russia,within,yes,no,,,,researchers,fact_checking,mainstream,politically_neutral ,4,13.44,21,0.591,pitch,,accuracy,"""This study uses a dichotomized (true/false) measure of perceived news veracity""",1,1,binary,control,,,,,,,1576,0.32371,0.46793,0.50114,0.50003,authors,no
70,"Lyons, B., King, A. J., & Kaphingst, K. (2024). A health media literacy intervention increases skepticism of both inaccurate and accurate cancer news among U.S. adults. https://doi.org/10.31219/osf.io/hm9ty",Lyons_2024_b,,,data correspond to control group,no,1,United States,within,yes,no,,,,researchers,,,cancer,1,18,60,0.6666666667,title_picture_pitch,source,accuracy,"""4 pt. (“Not at all accurate” (1) to “Very accurate” (4)) To the best of your knowledge, how accurate is the claim in the above headline?""",1,0,4,control,,,,,,,195,1.84,0.938,2.62,0.937,raw data,no
71,"List, J. A., Ramírez, L. M., Seither, J., Unda, J., & Vallejo, B. (2024). Toward an Understanding of the Economics of Misinformation: Evidence from a Demand Side Field Experiment on Critical Thinking (Working Paper 32367). National Bureau of Economic Research. https://doi.org/10.3386/w32367",List_2024,,,"authors do not describe the accuracy evaluation item but point to an article of Roozenbeek and van der Linden, so we assume it's this:
""Participants were asked to rate the reliability of these tweets and headlines on a standard 7-point scale (1 = unreliable, 7 = reliable), both before and after playing.""",no,1,Colombia,within,yes,no,,,,researchers,fact_checking,mainstream,political,1,,,,,,,,,,,,,,,,,,,,,,,authors,no