# Effect sizes {#effect-sizes}

## Preregistered analysis

\FloatBarrier

In the main analysis that we report in the paper, we relied on Cohen's d as a standardized effect measure. However, we had pre-registered relying on standardized mean changes using change score standardization (SMCC) [@gibbons_estimation_1993] for within participant designs, and Hedge's g for the remaining `r descriptives$design$between$n` effect sizes from between participant designs [@hedges_distribution_1981].

As Cohen's d, the SMCC expresses effects in units of (pooled) standard deviations, allowing for comparison across different scales. Also similar to the Cohen's d we calculated, the SMCC relies on a correlation estimate to account for statistical dependencies arising from the within participant design used by most studies. By contrast, the SMCC also uses this correlation coefficient in calculating the pooled standard deviation (and not only the standard error, as with our Cohen's d). As a result, the effect size estimate itself (and not only its certainty) are affected by the imputed correlation value. 

Precisely, the SMCC is calculated as

$$
SMCC = \frac{MD}{SD_d}
$$

with $MD$ being the mean difference/change score (mean true news score minus mean false news score) and $SD_d$ being standard deviation of the difference/change scores, which (assuming equal standard deviations for false and true news) is calculated as: $SD_d = SD_{false/true}\sqrt{2(1-r)}$ [@morris2002].

The SMCC varies with the imputed correlation value $r$, because $SD_d$ varies as a function of $r$. If $r$ is greater than .5, $SD_d$ will be smaller than $SD_{false/true}$, and as a result, the SMCC will be larger than the estimate obtained by a standardized mean difference assuming independence such as Cohen's d. By contrast, when the correlation is less than .5, $SD_d$ will be greater than $SD_{false/true}$, and the SMCC will be smaller [@morris2002]. In our case, the imputated average correlation is `r average_correlation %>% round(digits = 2)`. 

Table \@ref(tab:effects) shows that the SMCC yields slightly smaller effect sizes than the Cohen's d (because the correlation between true and false news is smaller than .5), but all conclusions remain the same. 

In the next section, we show the results of sensitivity analyses for the imputed correlation value when calculating the SMCC.

## Alternative effect sizes

Table \@ref(tab:effects) shows compares different effect size estimators for both both discernment (H1) and skepticism  bias (H2). Besides Cohen's d, the estimator of the main study, and SMCC, the pre-registered estimator, we additionally included the estimates for two alternative estimators: A standardized mean difference assuming independence (SMD), precisely Hedge's g (a version of Cohen's d that corrects for small sample sizes), and a standardized mean change using raw (instead of change) score standardization (SMCR) [@becker1988]. When using raw score standardization, the standardized mean change expresses the effect size in terms of the standard deviation units of the pre-treatment (in our case false news) scores, rather than the standard deviation of the difference scores (involving the correlation) [@becker1988]. Among all estimators, the SMCC is the only one in which the effect size estimate depends on the value of the correlation between the false and true news scores. The interpretation of all these standardized effect measures is similar: all are expressed in terms of standard deviations. Yet, they are different estimators, because they rely on different standard deviations, thereby producing different estimates and standard errors [@morris2002]. Due to the low average correlation between false and true news ratings, the SMCC produces the smallest effect estimates for both discernment and skepticism  bias.

```{r effects, fig.pos='H'}
# main result table
modelsummary::modelsummary(list("Discernment" = robust_model_accuracy, 
                                "Skepticism  bias" = robust_model_error,
                                "Discernment" = SMCC_model_accuracy, 
                                "Skepticism  bias" = SMCC_model_error,
                                "Discernment" = SMCR_model_accuracy, 
                                "Skepticism  bias" = SMCR_model_error,
                                "Discernment" = SMD_model_accuracy, 
                                "Skepticism  bias" = SMD_model_error),
                           title = 'Model results', 
                           stars = TRUE, 
                           coef_rename = c("overall" = "Estimate")
                           ) %>%
  add_header_above(c(" " = 1, "Cohen's d" = 2, "SMCC" = 2, "SMCR" = 2, "SMD" = 2)) %>%
  add_header_above(c(" " = 1, "Main estimator" = 2, "Preregistered estimator" = 2, "Alternative estimators" = 4),
                   line = FALSE, italic = TRUE) %>%
  # make smaller to fit
  kable_styling(latex_options = "scale_down") %>%
  footnote(general = "Comparison of different effect sizes. Cohen's d is the estimator we report in the main analysis. SMCC (Standardized mean change using change score standardization) is the estimator we pre-registered. For reference, we provide the results we obtain when using a standardized mean difference assuming independence for all effect sizes (SMD), precisely Hedge's g, and a standardized change score using raw (instead of change) standardization (SMCR). For effects from studies that used a between participant design, we calculated Hedge's g in the results listed under \"SMCC\" and \"SMCR\"."
           , threeparttable = TRUE)
```

## Effects on original scales

Table \@ref(tab:scales) shows estimates by scale, in the original units of the scale. The table is intended to help interpret the magnitude of the effect sizes reported in the main findings. Note that some scales occur very rarely only (see Tab. \@ref(tab:n-scales)), hence making their meta-analytic estimates less meaningful.

```{r n-scales}
meta_wide %>% group_by(accuracy_scale) %>% summarise(Papers = n_distinct(paperID),
                                                     Samples = n_distinct(unique_sample_id),
                                                     Effects = n_distinct(observation_id)
                                                     ) %>% 
  mutate(accuracy_scale = ifelse(accuracy_scale == "binary", accuracy_scale, 
                                 paste0(accuracy_scale, "-point"))) %>% 
  pivot_longer(-accuracy_scale,
               names_to = "variable",
               values_to = "frequency"
               ) %>% 
  pivot_wider(names_from = accuracy_scale, 
              values_from = frequency) %>% 
  column_to_rownames(var = "variable") %>% 
  apa_table(note = "Frequency table of scales.")
```

```{r, include=FALSE}
# run models by scale
results_by_scale <- models_by_scale()

# # as data frame
# results_by_scale <- models_by_scale(return_as = "data_frame")
```

```{r scales}
# Extract list elements containing "Accuracy" in the name
accuracy_list <- results_by_scale[grep("Accuracy", names(results_by_scale))]

# Extract list elements containing "Error" in the name
error_list <- results_by_scale[grep("Error", names(results_by_scale))]

# Function to extract number or "binary" from name
extract_number <- function(name) {
  if (grepl("binary", name))
    return("binary")
  
  number <- gsub("\\D", "", name)
  if (number != "")
    return(paste0(number, "-point"))
  
  return(name)
}

# Modify names in accuracy_list
accuracy_list <- setNames(accuracy_list, sapply(names(accuracy_list), extract_number))

# Modify names in error_list
error_list <- setNames(error_list, sapply(names(error_list), extract_number))

# make list of lists
results <- list("Discernment" = accuracy_list, 
                "Skepticism  bias" = error_list)


# by scale result table
modelsummary::modelsummary(results,
                           title = '(Raw) Mean Differences between true and false news', 
                           stars = TRUE, 
                           coef_rename = c("overall" = "Estimate"),
                           shape = "rbind"
                           ) %>%
  # make smaller to fit
  kable_styling(latex_options = "scale_down") %>%
  footnote(general = "One scale, a 100-point scale, does not appear since there was only one effect size on that scale")

```




